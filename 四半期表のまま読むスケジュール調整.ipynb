{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOMx7jMABHnXrp/G5Xzn5K2",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nanafish/ORS/blob/main/%E5%9B%9B%E5%8D%8A%E6%9C%9F%E8%A1%A8%E3%81%AE%E3%81%BE%E3%81%BE%E8%AA%AD%E3%82%80%E3%82%B9%E3%82%B1%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E8%AA%BF%E6%95%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）\n",
    "# ★重要修正：last_pos方式を廃止し、確定(未来含む)＋提案の「最短距離(min distance)」でスパン判定\n",
    "#   → 豊中(6-4w確定)があるなら、6-2wに豊中/吹田グループは入らない\n",
    "#   → 木更津(市原連動)も同様に「前後の確定」を見て弾く\n",
    "# ============================================\n",
    "\n",
    "!pip -q install fugashi unidic-lite jaconv\n",
    "\n",
    "import os, re, math, random, difflib, bisect\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import jaconv\n",
    "from fugashi import Tagger\n",
    "tagger = Tagger()\n",
    "\n",
    "# ====== 入力 ======\n",
    "UP = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_fix_minDist_groupSpan (1).xlsx\"\n",
    "BASE = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "QUARTER_XLSX = UP if os.path.exists(UP) else BASE\n",
    "\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "STATS_XLSX       = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_fix_minDist_groupSpan_OUT.xlsx\"\n",
    "\n",
    "# ====== 列（0-based）=====\n",
    "COL_WEEK = 0\n",
    "COL_AREA_OR_KIND = 1     # ヘッダ行=東/西/九州、次行=AJ/合同/SA\n",
    "COL_CITY = 2\n",
    "COL_VENUE = 3\n",
    "COL_PREF = 5\n",
    "COL_REASON_BT = 72\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,\n",
    "    \"SAME_WEEK_CITY_PENALTY\": 60.0,   # 同週同グループは強ペナ（禁止にすると詰むのでペナ）\n",
    "\n",
    "    \"FUZZY_CUTOFF\": 0.86,\n",
    "    \"CANON_CUTOFF\": 0.93,\n",
    "\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    \"OVR_CLASS_J_VALUE\": 1,\n",
    "    \"OVR_MIN_POP\": 180000,\n",
    "    \"OVR_OVERFLOW_PENALTY\": 15.0,\n",
    "\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 2.0, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0,\n",
    "              \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 0) alias辞書（CSV）\n",
    "# ======================================================\n",
    "ALIAS_CSV = \"市区分_alias.csv\"\n",
    "\n",
    "def ensure_alias_template(path=ALIAS_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"alias\":\"なんば\",\"canonical\":\"難波\"},\n",
    "        {\"alias\":\"薩摩河内\",\"canonical\":\"薩摩川内\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ aliasテンプレ作成: {path}\")\n",
    "\n",
    "def load_alias_map(path=ALIAS_CSV):\n",
    "    ensure_alias_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"alias\"] = df[\"alias\"].astype(str).str.strip()\n",
    "        df[\"canonical\"] = df[\"canonical\"].astype(str).str.strip()\n",
    "        return {a:c for a,c in zip(df[\"alias\"], df[\"canonical\"]) if a and c}\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ alias読み込み失敗。aliasなしで続行:\", e)\n",
    "        return {}\n",
    "\n",
    "ALIAS_MAP = load_alias_map(ALIAS_CSV)\n",
    "\n",
    "def apply_alias(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    t = str(s).strip()\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    return ALIAS_MAP.get(t, t)\n",
    "\n",
    "# ======================================================\n",
    "# ★連動グループ定義（CSV）\n",
    "# ======================================================\n",
    "GROUP_CSV = \"市区分_group.csv\"\n",
    "\n",
    "def ensure_group_template(path=GROUP_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"city_key\":\"木更津\",\"group_key\":\"木更津_市原\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"市原\",\"group_key\":\"木更津_市原\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"豊中\",\"group_key\":\"豊中_吹田\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"吹田\",\"group_key\":\"豊中_吹田\",\"cap\":\"2\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ groupテンプレ作成: {path}\")\n",
    "\n",
    "def load_group_map(path=GROUP_CSV):\n",
    "    ensure_group_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"city_key\"]  = df[\"city_key\"].astype(str).str.strip()\n",
    "        df[\"group_key\"] = df[\"group_key\"].astype(str).str.strip()\n",
    "        df[\"cap\"] = df[\"cap\"].astype(str).str.strip()\n",
    "        city_to_group = {}\n",
    "        group_cap = {}\n",
    "        for _, r in df.iterrows():\n",
    "            ck = r[\"city_key\"]; gk = r[\"group_key\"]\n",
    "            if ck and gk:\n",
    "                city_to_group[ck] = gk\n",
    "                if r[\"cap\"]:\n",
    "                    try:\n",
    "                        group_cap[gk] = int(float(r[\"cap\"]))\n",
    "                    except:\n",
    "                        pass\n",
    "        return city_to_group, group_cap\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ group読み込み失敗。groupなしで続行:\", e)\n",
    "        return {}, {}\n",
    "\n",
    "CITY_TO_GROUP, GROUP_CAP = load_group_map(GROUP_CSV)\n",
    "\n",
    "def group_of_citykey(ck: str) -> str:\n",
    "    if not ck:\n",
    "        return \"\"\n",
    "    return CITY_TO_GROUP.get(ck, ck)\n",
    "\n",
    "# ======================================================\n",
    "# 1) 正規化・読みキー・誤字ゆれ生成\n",
    "# ======================================================\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def muni_base(name: str) -> str:\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r\"(都|道|府|県)$\", \"\", s)\n",
    "    s = re.sub(r\"(市|区|町|村)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def to_katakana_reading(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = re.sub(r\"[ \\t\\r\\n\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "\n",
    "    if re.search(r\"[ぁ-んァ-ン]\", s2):\n",
    "        s2 = jaconv.normalize(jaconv.hira2kata(s2))\n",
    "        s2 = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", s2)\n",
    "        return s2\n",
    "\n",
    "    yomi_parts = []\n",
    "    for w in tagger(s2):\n",
    "        feat = w.feature\n",
    "        reading = None\n",
    "        for k in [\"reading\", \"kana\", \"pron\"]:\n",
    "            if hasattr(feat, k):\n",
    "                reading = getattr(feat, k)\n",
    "                break\n",
    "        if not reading or reading == \"*\":\n",
    "            reading = w.surface\n",
    "        yomi_parts.append(reading)\n",
    "\n",
    "    yomi = \"\".join(yomi_parts)\n",
    "    yomi = jaconv.normalize(jaconv.hira2kata(yomi))\n",
    "    yomi = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", yomi)\n",
    "    return yomi\n",
    "\n",
    "CONFUSION = {\n",
    "    \"川\": [\"河\"], \"河\": [\"川\"],\n",
    "    \"崎\": [\"﨑\"], \"﨑\": [\"崎\"],\n",
    "    \"ヶ\": [\"ケ\"], \"ケ\": [\"ヶ\"],\n",
    "    \"斉\": [\"齋\", \"斎\"], \"齋\": [\"斉\", \"斎\"], \"斎\": [\"斉\", \"齋\"],\n",
    "    \"邊\": [\"辺\", \"邉\"], \"邉\": [\"辺\", \"邊\"], \"辺\": [\"邊\", \"邉\"],\n",
    "}\n",
    "\n",
    "def gen_variants(s: str, limit=12):\n",
    "    if s is None:\n",
    "        return [\"\"]\n",
    "    s = str(s)\n",
    "    vars_ = {s}\n",
    "    for a, bs in CONFUSION.items():\n",
    "        if a in s:\n",
    "            new_set = set(vars_)\n",
    "            for v in vars_:\n",
    "                for b in bs:\n",
    "                    new_set.add(v.replace(a, b))\n",
    "            vars_ = new_set\n",
    "        if len(vars_) >= limit:\n",
    "            break\n",
    "    return list(vars_)[:limit]\n",
    "\n",
    "def best_ratio(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ======================================================\n",
    "# ★束ね分解 + D列ヒント（ただし実会場のみ）\n",
    "# ======================================================\n",
    "DELIMS = r\"[・／/、,＋+＆&\\s　]+\"\n",
    "\n",
    "def strip_annotations(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    t = str(s)\n",
    "    t = re.split(r\"[（(]\", t, maxsplit=1)[0]\n",
    "    t = re.split(r\"(会場|要検討|検討|確定)\", t, maxsplit=1)[0]\n",
    "    return t.strip()\n",
    "\n",
    "def split_city_tokens(raw: str):\n",
    "    t = strip_annotations(raw)\n",
    "    if not t:\n",
    "        return []\n",
    "    parts = [p.strip() for p in re.split(DELIMS, t) if p and p.strip()]\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p2 = apply_alias(p)\n",
    "        b = muni_base(p2)\n",
    "        if b:\n",
    "            out.append(b)\n",
    "    seen=set(); uniq=[]\n",
    "    for x in out:\n",
    "        if x not in seen:\n",
    "            uniq.append(x); seen.add(x)\n",
    "    return uniq\n",
    "\n",
    "def find_city_tokens_in_text(text: str, candidates_city_keys):\n",
    "    if not text:\n",
    "        return []\n",
    "    tn = norm(text)\n",
    "    if not tn:\n",
    "        return []\n",
    "    hits=[]\n",
    "    for ck in candidates_city_keys:\n",
    "        nk = norm(ck)\n",
    "        if nk and nk in tn:\n",
    "            hits.append(ck)\n",
    "    seen=set(); out=[]\n",
    "    for h in hits:\n",
    "        if h not in seen:\n",
    "            out.append(h); seen.add(h)\n",
    "    return out\n",
    "\n",
    "def is_placeholder_venue(v):\n",
    "    if v is None:\n",
    "        return True\n",
    "    s = str(v).strip()\n",
    "    if s == \"\":\n",
    "        return True\n",
    "    return (\"会場要検討\" in s) or (\"要検討\" in s)\n",
    "\n",
    "EXCLUDE_AJ_BASE_VENUES = (\"AJ日本橋\", \"AJ秋葉原\")\n",
    "EXCLUDE_AJ_COUNT_KEYWORDS = (\"萌え\", \"イラスト\", \"JIF\")\n",
    "\n",
    "def is_excluded_aj_base_venue(venue_raw):\n",
    "    s = \"\" if venue_raw is None else str(venue_raw)\n",
    "    s = re.sub(r\"[\\s　]+\", \"\", s)\n",
    "    for base in EXCLUDE_AJ_BASE_VENUES:\n",
    "        if s == base:\n",
    "            return True\n",
    "        if s.startswith(base):\n",
    "            tail = s[len(base):]\n",
    "            if tail and any(k in tail for k in EXCLUDE_AJ_COUNT_KEYWORDS):\n",
    "                return False\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_fixed_row(city_raw, venue_raw):\n",
    "    # 履歴として数える＝実会場だけ（AJ日本橋/AJ秋葉原の素開催は除外）\n",
    "    if is_placeholder_venue(venue_raw):\n",
    "        return False\n",
    "    if is_excluded_aj_base_venue(venue_raw):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# ======================================================\n",
    "# 2) 東/西/九州 の都道府県範囲（＋北=東）\n",
    "# ======================================================\n",
    "EAST_PREF_NUMS  = set(list(range(1, 17)) + [19,20,21,22,23,24])\n",
    "WEST_PREF_NUMS  = set([17,18] + list(range(25, 34)) + [31,32] + [36,37,38,39])\n",
    "KYUSHU_PREF_NUMS= set([34,35] + list(range(40, 47)))\n",
    "\n",
    "def norm_area_label(x):\n",
    "    s = (str(x).strip() if x is not None else \"\")\n",
    "    if s == \"北\":\n",
    "        return \"東\"\n",
    "    return s\n",
    "\n",
    "def pref_num(pref_code_str: str):\n",
    "    if not pref_code_str:\n",
    "        return None\n",
    "    s = str(pref_code_str).strip()\n",
    "    m = re.match(r\"^(\\d{2})\", s)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def area_allowed(area_label: str, pref_code_str: str) -> bool:\n",
    "    al = norm_area_label(area_label)\n",
    "    pn = pref_num(pref_code_str)\n",
    "    if pn is None:\n",
    "        return True\n",
    "    if al == \"東\":\n",
    "        return pn in EAST_PREF_NUMS\n",
    "    if al == \"西\":\n",
    "        return pn in WEST_PREF_NUMS\n",
    "    if al == \"九州\":\n",
    "        return pn in KYUSHU_PREF_NUMS\n",
    "    return True\n",
    "\n",
    "# ======================================================\n",
    "# 3) 補助関数\n",
    "# ======================================================\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, group_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if group_key and group_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in {1}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"　\",\" \").replace(\" \", \"\")  # 空白吸収（A J対策）\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "\n",
    "        area_label = \"\" if pd.isna(header[COL_AREA_OR_KIND]) else str(header[COL_AREA_OR_KIND]).strip()\n",
    "        kind = kind_norm(detail[COL_AREA_OR_KIND])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"area_label\": area_label,\n",
    "            \"kind\": kind, \"city_raw\": city, \"venue_raw\": venue, \"pref_code\": pref\n",
    "        })\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "# ======================================================\n",
    "# 4) 統計量（例外増枠用 + 正規化基準）\n",
    "# ======================================================\n",
    "stats = pd.read_excel(STATS_XLSX, sheet_name=0)\n",
    "stats.columns = [str(c).strip() for c in stats.columns]\n",
    "muni_col = \"市区町村\" if \"市区町村\" in stats.columns else stats.columns[0]\n",
    "\n",
    "stats_base_list = stats[muni_col].astype(str).map(muni_base).map(str.strip)\n",
    "stats_base_list = stats_base_list[stats_base_list != \"\"].dropna().unique().tolist()\n",
    "\n",
    "stats_norm_to_base = {norm(x): x for x in stats_base_list if x}\n",
    "stats_norms = list(stats_norm_to_base.keys())\n",
    "\n",
    "def canonize_city_key(city_key_raw: str):\n",
    "    if not city_key_raw:\n",
    "        return \"\", 0.0\n",
    "    x = apply_alias(city_key_raw)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in stats_norm_to_base and bn:\n",
    "        return stats_norm_to_base[bn], 1.0\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in stats_norm_to_base and vn:\n",
    "            return stats_norm_to_base[vn], 0.995\n",
    "\n",
    "    best_base, best_r = None, 0.0\n",
    "    for v in [b] + gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        for sn in stats_norms:\n",
    "            r = best_ratio(vn, sn)\n",
    "            if r > best_r:\n",
    "                best_r = r\n",
    "                best_base = stats_norm_to_base[sn]\n",
    "    if best_base and best_r >= CONFIG[\"CANON_CUTOFF\"]:\n",
    "        return best_base, best_r\n",
    "\n",
    "    return b, best_r\n",
    "\n",
    "# ======================================================\n",
    "# 5) 四半期表読み込み\n",
    "# ======================================================\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ======================================================\n",
    "# 6) 地域別回数読み込み → ★束ね表記を分解して候補キーを作る（重要修正）\n",
    "#    - \"木更津・市原\" を [\"木更津\",\"市原\"] に展開して両方を候補に入れる\n",
    "#    - plan_count は二重計上しない（先頭だけ count、残りは 0）\n",
    "# ======================================================\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None, dtype=str)\n",
    "\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()].copy()\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "\n",
    "plan_rows[\"city_key_raw\"] = plan_rows[1].astype(str).str.strip()\n",
    "plan_rows[\"plan_count_raw\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "expanded = []\n",
    "for _, rr in plan_rows.iterrows():\n",
    "    pref_parent = rr[\"pref_parent\"]\n",
    "    raw_city = rr[\"city_key_raw\"]\n",
    "    cnt = int(rr[\"plan_count_raw\"])\n",
    "\n",
    "    # ★束ねを分解（あなたの split_city_tokens を使う）\n",
    "    toks = split_city_tokens(raw_city)\n",
    "    if not toks:\n",
    "        toks = [raw_city.strip()]\n",
    "\n",
    "    # ★canonical化（統計量ベース）\n",
    "    canon_list = []\n",
    "    for t in toks:\n",
    "        ck, _ = canonize_city_key(t)\n",
    "        ck = (ck or \"\").strip()\n",
    "        if ck:\n",
    "            canon_list.append(ck)\n",
    "\n",
    "    if not canon_list:\n",
    "        continue\n",
    "\n",
    "    # ★二重計上防止：先頭だけ cnt、残り 0\n",
    "    for i, ck in enumerate(canon_list):\n",
    "        expanded.append({\n",
    "            \"pref_parent\": pref_parent,\n",
    "            \"city_key\": ck,\n",
    "            \"plan_count\": cnt if i == 0 else 0,\n",
    "            \"city_key_raw\": raw_city\n",
    "        })\n",
    "\n",
    "region_master = pd.DataFrame(expanded)\n",
    "# city_key が同一になるものは集約\n",
    "region_master = region_master.groupby([\"pref_parent\", \"city_key\"], as_index=False)[\"plan_count\"].sum()\n",
    "\n",
    "# 候補キー（＝確定枠から match するためにも必要）\n",
    "PLAN_CITY_KEYS = sorted(region_master[\"city_key\"].dropna().astype(str).str.strip().unique().tolist())\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# ======================================================\n",
    "# ★連動グループで plan_count を組み直す（cap指定があればそれ優先）\n",
    "# ======================================================\n",
    "group_members = {}\n",
    "for ck in PLAN_CITY_KEYS:\n",
    "    gk = group_of_citykey(ck)\n",
    "    group_members.setdefault(gk, []).append(ck)\n",
    "\n",
    "plan_count_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    if gk in GROUP_CAP and GROUP_CAP[gk] > 0:\n",
    "        plan_count_by_group[gk] = GROUP_CAP[gk]\n",
    "    else:\n",
    "        plan_count_by_group[gk] = int(sum(plan_count_by_city.get(m, 0) for m in members))\n",
    "\n",
    "# ======================================================\n",
    "# 8) 都道府県コード推定に使う pref_by_city / pref_by_group\n",
    "# （ここも region_master を使って作り直し）\n",
    "# ======================================================\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "pref_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    pc = \"\"\n",
    "    for mck in members:\n",
    "        pc = pref_by_city.get(mck, \"\")\n",
    "        if pc:\n",
    "            break\n",
    "    pref_by_group[gk] = pc\n",
    "\n",
    "# gap 計算\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "group_gap = {gk: gap_weeks_from_count(int(cnt)) for gk, cnt in plan_count_by_group.items()}\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 7) 候補側の索引（PLAN_CITY_KEYSでマッチ）\n",
    "# ======================================================\n",
    "city_norm_map = {ck: norm(ck) for ck in PLAN_CITY_KEYS}\n",
    "norm_to_city = {}\n",
    "for ck, nk in city_norm_map.items():\n",
    "    if nk:\n",
    "        norm_to_city.setdefault(nk, []).append(ck)\n",
    "\n",
    "reading_to_city = {}\n",
    "for ck in PLAN_CITY_KEYS:\n",
    "    rd = to_katakana_reading(ck)\n",
    "    if rd:\n",
    "        reading_to_city.setdefault(rd, []).append(ck)\n",
    "\n",
    "def choose_best_by_fuzzy(query_base, cands):\n",
    "    qn = norm(query_base)\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in cands:\n",
    "        r = best_ratio(qn, norm(ck))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    return best_ck, best_r\n",
    "\n",
    "def match_city_key(city_name: str):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    x = apply_alias(city_name)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in norm_to_city and bn:\n",
    "        cands = norm_to_city[bn]\n",
    "        if len(cands) == 1:\n",
    "            return cands[0], 1.0\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        return ck, max(0.97, rr)\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in norm_to_city and vn:\n",
    "            cands = norm_to_city[vn]\n",
    "            if len(cands) == 1:\n",
    "                return cands[0], 0.995\n",
    "            ck, rr = choose_best_by_fuzzy(v, cands)\n",
    "            return ck, max(0.95, rr)\n",
    "\n",
    "    rd = to_katakana_reading(b)\n",
    "    cands = reading_to_city.get(rd, [])\n",
    "    if len(cands) == 1:\n",
    "        return cands[0], 0.99\n",
    "    elif len(cands) >= 2:\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        if ck:\n",
    "            return ck, max(0.93, rr)\n",
    "\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in PLAN_CITY_KEYS:\n",
    "        r = best_ratio(bn, city_norm_map.get(ck, \"\"))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    if best_ck and best_r >= CONFIG[\"FUZZY_CUTOFF\"]:\n",
    "        return best_ck, best_r\n",
    "    return None, best_r\n",
    "\n",
    "def match_city_keys_multi(city_raw: str, venue_raw: str = \"\"):\n",
    "    keys = []\n",
    "    tokens = split_city_tokens(city_raw)\n",
    "    for tok in tokens:\n",
    "        ck, _ = match_city_key(tok)\n",
    "        if ck:\n",
    "            keys.append(ck)\n",
    "\n",
    "    # D列ヒントは「実会場」のときだけ\n",
    "    if (not tokens or len(keys) == 0) and venue_raw and (not is_placeholder_venue(venue_raw)):\n",
    "        vtxt = str(venue_raw)\n",
    "        vtxt = vtxt.split(\"（B:\", 1)[0].split(\"(B:\", 1)[0]\n",
    "        hits = find_city_tokens_in_text(vtxt, PLAN_CITY_KEYS)\n",
    "        keys.extend(hits)\n",
    "\n",
    "    seen=set(); uniq=[]\n",
    "    for k in keys:\n",
    "        if k and k not in seen:\n",
    "            uniq.append(k); seen.add(k)\n",
    "    return uniq\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys1, scores = [], []\n",
    "    key_lists = []\n",
    "    group_lists = []\n",
    "    for city_raw, venue_raw in zip(df[\"city_raw\"].tolist(), df[\"venue_raw\"].tolist()):\n",
    "        klist = match_city_keys_multi(city_raw, venue_raw)\n",
    "        key_lists.append(klist)\n",
    "        k0 = klist[0] if klist else None\n",
    "        keys1.append(k0)\n",
    "\n",
    "        glist = []\n",
    "        for ck in klist:\n",
    "            gk = group_of_citykey(ck)\n",
    "            if gk and gk not in glist:\n",
    "                glist.append(gk)\n",
    "        group_lists.append(glist)\n",
    "\n",
    "        if k0:\n",
    "            toks = split_city_tokens(city_raw)\n",
    "            probe = toks[0] if toks else city_raw\n",
    "            _, sc = match_city_key(probe)\n",
    "            scores.append(sc)\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys1\n",
    "    out[\"city_keys\"] = key_lists\n",
    "    out[\"group_keys\"] = group_lists\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "scheduled42_all = add_city_key(b42.copy())\n",
    "scheduled43_all = add_city_key(b43.copy())\n",
    "\n",
    "# 履歴に入れるのは「実会場」だけ\n",
    "scheduled42 = scheduled42_all[scheduled42_all.apply(lambda r: is_fixed_row(r[\"city_raw\"], r[\"venue_raw\"]), axis=1)].copy()\n",
    "scheduled43 = scheduled43_all[scheduled43_all.apply(lambda r: is_fixed_row(r[\"city_raw\"], r[\"venue_raw\"]), axis=1)].copy()\n",
    "\n",
    "# 空きAJ枠：city空 かつ (venue空 or 会場要検討)\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"].apply(is_placeholder_venue))\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ======================================================\n",
    "# 8) 都道府県コード推定\n",
    "# ======================================================\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "pref_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    pc = \"\"\n",
    "    for mck in members:\n",
    "        pc = pref_by_city.get(mck, \"\")\n",
    "        if pc:\n",
    "            break\n",
    "    pref_by_group[gk] = pc\n",
    "\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "group_gap = {gk: gap_weeks_from_count(int(cnt)) for gk, cnt in plan_count_by_group.items()}\n",
    "\n",
    "# ======================================================\n",
    "# 9) ★最短距離(min distance)判定のための「確定開催位置リスト」\n",
    "# ======================================================\n",
    "OFFSET_43 = len(week_order_42)\n",
    "\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "\n",
    "scheduled_all_fixed = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "# ★県/グループごとに「確定開催(abs_pos)」を全部持つ（未来も含む）\n",
    "fixed_pos_pref = {}\n",
    "fixed_pos_group = {}\n",
    "\n",
    "for _, e in scheduled_all_fixed.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = str(e.get(\"pref_code\",\"\") or \"\").strip()\n",
    "    if pc:\n",
    "        fixed_pos_pref.setdefault(pc, []).append(ap)\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if isinstance(glist, list):\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                fixed_pos_group.setdefault(gk, []).append(ap)\n",
    "\n",
    "for k in list(fixed_pos_pref.keys()):\n",
    "    fixed_pos_pref[k] = sorted(set(fixed_pos_pref[k]))\n",
    "for k in list(fixed_pos_group.keys()):\n",
    "    fixed_pos_group[k] = sorted(set(fixed_pos_group[k]))\n",
    "\n",
    "def min_dist(apos: int, sorted_positions: list):\n",
    "    \"\"\"sorted_positionsに対する apos の最短距離（前後どちらも）\"\"\"\n",
    "    if not sorted_positions:\n",
    "        return 999\n",
    "    i = bisect.bisect_left(sorted_positions, apos)\n",
    "    best = 10**9\n",
    "    if i < len(sorted_positions):\n",
    "        best = min(best, abs(sorted_positions[i] - apos))\n",
    "    if i > 0:\n",
    "        best = min(best, abs(sorted_positions[i-1] - apos))\n",
    "    return best if best != 10**9 else 999\n",
    "\n",
    "def insort_unique(lst: list, x: int):\n",
    "    \"\"\"ソート済みに保って重複なく追加\"\"\"\n",
    "    i = bisect.bisect_left(lst, x)\n",
    "    if i < len(lst) and lst[i] == x:\n",
    "        return\n",
    "    lst.insert(i, x)\n",
    "\n",
    "# 43期の「確定分」だけで消化数（グループ）\n",
    "scheduled_counts_43_group = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if isinstance(glist, list):\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                scheduled_counts_43_group[gk] = scheduled_counts_43_group.get(gk, 0) + 1\n",
    "\n",
    "# ======================================================\n",
    "# 10) 例外増枠プール（従来どおり）\n",
    "# ======================================================\n",
    "stats2 = stats.copy()\n",
    "stats2[muni_col] = stats2[muni_col].astype(str).str.strip()\n",
    "\n",
    "class_col = stats2.columns[9] if len(stats2.columns) >= 10 else stats2.columns[-1]\n",
    "stats2[class_col] = pd.to_numeric(stats2[class_col], errors=\"coerce\")\n",
    "\n",
    "pop_col = next((c for c in stats2.columns if \"人口\" in str(c)), None)\n",
    "if pop_col is None:\n",
    "    num_cols=[]\n",
    "    for c in stats2.columns:\n",
    "        s = pd.to_numeric(stats2[c], errors=\"coerce\")\n",
    "        if s.notna().sum() > 0:\n",
    "            num_cols.append((c, float(s.max(skipna=True))))\n",
    "    pop_col = sorted(num_cols, key=lambda x: x[1], reverse=True)[0][0] if num_cols else stats2.columns[-1]\n",
    "stats2[pop_col] = pd.to_numeric(stats2[pop_col], errors=\"coerce\")\n",
    "\n",
    "ovr = stats2[(stats2[class_col] == CONFIG[\"OVR_CLASS_J_VALUE\"]) & (stats2[pop_col] >= CONFIG[\"OVR_MIN_POP\"])].copy()\n",
    "\n",
    "ovr_candidates = {}\n",
    "for name in ovr[muni_col].tolist():\n",
    "    ck, sc = match_city_key(name)\n",
    "    if ck:\n",
    "        pop_val = float(ovr.loc[ovr[muni_col] == name, pop_col].iloc[0])\n",
    "        if ck not in ovr_candidates or sc > ovr_candidates[ck][\"match_score\"]:\n",
    "            ovr_candidates[ck] = {\"name_raw\": name, \"match_score\": sc, \"pop\": pop_val}\n",
    "\n",
    "OVR_POOL = set(ovr_candidates.keys())\n",
    "print(f\"✅ 例外増枠プール: {len(OVR_POOL)}（J列={class_col}==1 & 人口列={pop_col}>=18万）\")\n",
    "\n",
    "# ======================================================\n",
    "# 11) 集客率（あれば）\n",
    "# ======================================================\n",
    "rate_col = next((c for c in stats2.columns if (\"集客率\" in str(c) or \"来場率\" in str(c) or \"動員率\" in str(c))), None)\n",
    "city_rate = {}\n",
    "if rate_col is not None:\n",
    "    tmp = stats2[[muni_col, rate_col]].copy()\n",
    "    tmp[\"rate\"] = pd.to_numeric(tmp[rate_col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"rate\"])\n",
    "    muni_rate_norm = {norm(muni_base(row[muni_col])): float(row[\"rate\"]) for _, row in tmp.iterrows()}\n",
    "    for ck in PLAN_CITY_KEYS:\n",
    "        cn = norm(ck)\n",
    "        if cn in muni_rate_norm:\n",
    "            city_rate[ck] = muni_rate_norm[cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"不明\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"不明\"\n",
    "    return f\"下位{p*100:.0f}%\"\n",
    "\n",
    "# ======================================================\n",
    "# 理由（min distance表示）\n",
    "# ======================================================\n",
    "def build_reason(variant, week_id, area_label, ck, gk, pc,\n",
    "                 need_gap_p, dp, need_gap_g, dg,\n",
    "                 remaining_plan_g, overflow_used, overflow_meta,\n",
    "                 same_week_pref_hit, same_week_group_hit, relax_mode, score):\n",
    "    lines=[]\n",
    "    lines.append(f\"【案{variant}】{week_id}／{area_label} の空きAJ枠に対して選定。\")\n",
    "    lines.append(f\"0) 地域フィルタ：{area_label} の範囲内（県コード={pc}）のみ。\")\n",
    "    lines.append(f\"   連動グループ：{gk}（例：木更津+市原=合計年2回、豊中+吹田=合計年2回）\")\n",
    "\n",
    "    if not overflow_used:\n",
    "        lines.append(f\"1) 計画回数（グループ残）：{gk} 残り {remaining_plan_g} 回 → 計画内で採用（候補={ck}）\")\n",
    "    else:\n",
    "        pop = overflow_meta.get(\"pop\", None)\n",
    "        pop_txt = f\"{int(pop):,}人\" if isinstance(pop, (int,float)) and not math.isnan(pop) else \"不明\"\n",
    "        nm = overflow_meta.get(\"name_raw\",\"\") or ck\n",
    "        lines.append(\"1) 計画内で埋まらず、例外増枠を使用。\")\n",
    "        lines.append(f\"   例外：J列=1 & 人口>=18万 → {nm}（人口={pop_txt}）\")\n",
    "\n",
    "    lines.append(\n",
    "        f\"2) スパン(min距離)：県=必要{need_gap_p}週/最短{dp}週、グループ=必要{need_gap_g}週/最短{dg}週\"\n",
    "        + (f\"（緩和={relax_mode}）\" if relax_mode else \"\")\n",
    "    )\n",
    "\n",
    "    if ck in city_rate:\n",
    "        lines.append(f\"3) 集客率：{fmt_rate(city_rate.get(ck))}（{fmt_pct(city_pct.get(ck))}）\")\n",
    "    else:\n",
    "        lines.append(\"3) 集客率：データ無し → 回数/スパン優先\")\n",
    "\n",
    "    lines.append(\"4) 同週回避：\"\n",
    "                 + (\"同県ペナあり\" if same_week_pref_hit else \"同県OK\")\n",
    "                 + (\" / 同グループペナあり\" if same_week_group_hit else \"\"))\n",
    "\n",
    "    lines.append(f\"【採用】score={score:.2f}\")\n",
    "    return \" / \".join(lines)[:32000]\n",
    "\n",
    "# ======================================================\n",
    "# 週×都道府県 / 週×グループ（43期確定分のみ）\n",
    "# ======================================================\n",
    "week_used_pref_base = {}\n",
    "week_used_group_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]\n",
    "    pc = str(e.get(\"pref_code\",\"\") or \"\").strip()\n",
    "    if w and pc:\n",
    "        week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if w and isinstance(glist, list):\n",
    "        s = week_used_group_base.setdefault(w, set())\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                s.add(gk)\n",
    "\n",
    "# ======================================================\n",
    "# 12) プラン生成（A/B/C）…★min distance方式\n",
    "# ======================================================\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used_in_plan_group = {gk: 0 for gk in plan_count_by_group.keys()}\n",
    "\n",
    "    # ★「確定位置」を初期値に持つ（未来も含む）\n",
    "    pos_pref  = {pc: list(lst) for pc, lst in fixed_pos_pref.items()}\n",
    "    pos_group = {gk: list(lst) for gk, lst in fixed_pos_group.items()}\n",
    "\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "    week_used_group = {w:set(s) for w,s in week_used_group_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow):\n",
    "        gk = group_of_citykey(ck)\n",
    "        pc = pref_by_group.get(gk, \"\") or pref_by_city.get(ck, \"\")\n",
    "\n",
    "        if not area_allowed(area_label, pc):\n",
    "            return None\n",
    "\n",
    "        plan_cnt_g = plan_count_by_group.get(gk, 0)\n",
    "        already_g  = scheduled_counts_43_group.get(gk, 0)\n",
    "        remaining_g = plan_cnt_g - already_g - used_in_plan_group.get(gk, 0)\n",
    "\n",
    "        overflow_used = False\n",
    "        overflow_meta = {}\n",
    "\n",
    "        if remaining_g <= 0:\n",
    "            if not allow_overflow:\n",
    "                return None\n",
    "            if ck not in OVR_POOL:\n",
    "                return None\n",
    "            overflow_used = True\n",
    "            meta = ovr_candidates.get(ck, {})\n",
    "            overflow_meta = {\"name_raw\": meta.get(\"name_raw\",\"\"), \"pop\": meta.get(\"pop\", float(\"nan\"))}\n",
    "\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_g = group_gap.get(gk, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        dp = min_dist(apos, pos_pref.get(pc, [])) if pc else 999\n",
    "        dg = min_dist(apos, pos_group.get(gk, [])) if gk else 999\n",
    "\n",
    "        ok_p = (dp >= need_gap_p)\n",
    "        ok_g = (dg >= need_gap_g)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_g):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        if pc and is_snow_blackout(pc, gk, week_id):\n",
    "            return None\n",
    "\n",
    "        same_week_pref_hit  = (pc and pc in week_used_pref.get(week_id, set()))\n",
    "        same_week_group_hit = (gk and gk in week_used_group.get(week_id, set()))\n",
    "\n",
    "        same_week_pen = (CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0) + \\\n",
    "                        (CONFIG[\"SAME_WEEK_CITY_PENALTY\"] if same_week_group_hit else 0.0)\n",
    "\n",
    "        overflow_pen = CONFIG[\"OVR_OVERFLOW_PENALTY\"] if overflow_used else 0.0\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        slack_p = dp - need_gap_p\n",
    "        slack_g = dg - need_gap_g\n",
    "        need_city = city_need.get(ck, 0.5)\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_g * W[\"city_slack\"] +\n",
    "            max(remaining_g, 0) * W[\"unmet_bonus\"] * 5.0 +\n",
    "            (need_city * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen - same_week_pen - overflow_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        reason = build_reason(\n",
    "            variant, week_id, area_label, ck, gk, pc,\n",
    "            need_gap_p, dp, need_gap_g, dg,\n",
    "            remaining_g,\n",
    "            overflow_used, overflow_meta,\n",
    "            same_week_pref_hit, same_week_group_hit, relax_mode, score\n",
    "        )\n",
    "        return {\"ck\": ck, \"gk\": gk, \"pc\": pc, \"score\": float(score), \"reason\": reason}\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "        area_label = slot.get(\"area_label\", \"\")\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # 計画内\n",
    "        for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "            for ck in PLAN_CITY_KEYS:\n",
    "                cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=False)\n",
    "                if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                    best = cand\n",
    "            if best is not None:\n",
    "                break\n",
    "\n",
    "        # 例外増枠\n",
    "        if best is None:\n",
    "            for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "                for ck in PLAN_CITY_KEYS:\n",
    "                    cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=True)\n",
    "                    if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                        best = cand\n",
    "                if best is not None:\n",
    "                    break\n",
    "\n",
    "        if best is None:\n",
    "            assigns.append({\n",
    "                \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "                \"assign_city_key\": \"\", \"pref_code_guess\": \"\", \"score\": float(\"-inf\"),\n",
    "                \"reason_BT\": f\"案{variant}: 条件により候補なし（地域={area_label}）\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; gk = best[\"gk\"]; pc = best[\"pc\"]\n",
    "\n",
    "        used_in_plan_group[gk] = used_in_plan_group.get(gk, 0) + 1\n",
    "\n",
    "        # ★重要：確定(未来含む)+提案の集合に apos を追加（= 次のスロットで min距離が効く）\n",
    "        if gk:\n",
    "            pos_group.setdefault(gk, [])\n",
    "            insort_unique(pos_group[gk], apos)\n",
    "            week_used_group.setdefault(week_id, set()).add(gk)\n",
    "\n",
    "        if pc:\n",
    "            pos_pref.setdefault(pc, [])\n",
    "            insort_unique(pos_pref[pc], apos)\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck, \"pref_code_guess\": pc, \"score\": best[\"score\"],\n",
    "            \"reason_BT\": best[\"reason\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "def to_map(df, col):\n",
    "    return {int(r[\"row_header\"]): r[col] for _, r in df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ======================================================\n",
    "# 13) 書き戻し（43期の空きAJ枠だけ）\n",
    "# ======================================================\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in {sheet42, sheet43}:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1\n",
    "\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "\n",
    "    if not ((c_val is None or str(c_val).strip()==\"\") and is_placeholder_venue(d_val)):\n",
    "        continue\n",
    "\n",
    "    a = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    ws43.cell(r, COL_CITY+1).value = a\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b if b else '-'} / C:{c if c else '-'}）\"\n",
    "\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    if (ws43.cell(r, COL_PREF+1).value is None) or (str(ws43.cell(r, COL_PREF+1).value).strip()==\"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    ws43.cell(r, COL_REASON_BT+1).value = str(A_reason.get(int(row0), \"案A: 理由生成なし\"))\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "\n",
    "print(\"\\n✅ 入力:\", QUARTER_XLSX)\n",
    "print(\"✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"✅ 43期 空きAJ枠（city空＆会場要検討）:\", len(open43_AJ))\n",
    "print(\"✅ 書込数:\", written)\n",
    "print(\"✅ minDist方式：確定(未来含む)＋提案の最短距離でスパン判定 → 6月に寄る問題を止める\")\n",
    "print(\"✅ グループcap例:\", {k:GROUP_CAP.get(k) for k in sorted(GROUP_CAP)[:20]})\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8KB8P5NXAri",
    "outputId": "e6561d9c-7389-4bc1-b106-51243af4d5ff"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ aliasテンプレ作成: 市区分_alias.csv\n",
      "✅ groupテンプレ作成: 市区分_group.csv\n",
      "✅ 例外増枠プール: 4（J列=Zの4分位（1=赤,2=黄,3=青,4=灰）==1 & 人口列=人口>=18万）\n",
      "\n",
      "✅ 入力: SA+AJ+共有用_四半期表20240303.xlsx\n",
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_fix_minDist_groupSpan_OUT.xlsx\n",
      "✅ 43期 空きAJ枠（city空＆会場要検討）: 131\n",
      "✅ 書込数: 131\n",
      "✅ minDist方式：確定(未来含む)＋提案の最短距離でスパン判定 → 6月に寄る問題を止める\n",
      "✅ グループcap例: {'木更津_市原': 2, '豊中_吹田': 2}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）\n",
    "# ★東/西/九州の都道府県範囲フィルタ\n",
    "# ★alias / 読み / 誤字ゆれ吸収（会場マスタ不使用）\n",
    "# ★束ね対応（木更津・市原など）＝構成市すべて同一エリア扱い（A仕様：両方1消化）\n",
    "# ★連動グループ対応（木更津+市原=合計年2回、豊中+吹田=合計年2回 等）\n",
    "#   → 回数とスパンは group_key 単位で管理（年2回→gap=約26週）\n",
    "# ★重要修正：\n",
    "#   1) 「空きAJ枠」判定：city空 + (venue空 or 会場要検討) を空き扱い\n",
    "#   2) 「開催済み履歴」判定：会場要検討は履歴に入れない（提案は履歴汚染しない）\n",
    "#   3) D列ヒントは「実会場の時だけ」使う（会場要検討(B/C)から拾わない）\n",
    "# ============================================\n",
    "\n",
    "!pip -q install fugashi unidic-lite jaconv\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import jaconv\n",
    "from fugashi import Tagger\n",
    "tagger = Tagger()\n",
    "\n",
    "# ====== 入力 ======\n",
    "UP4 = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT (4).xlsx\"\n",
    "UP3 = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT (2).xlsx\"\n",
    "UP2 = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT (1).xlsx\"\n",
    "BASE = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "\n",
    "# どれを入力にしてもOK（提案は履歴に数えない設計）\n",
    "QUARTER_XLSX = UP4 if os.path.exists(UP4) else (UP3 if os.path.exists(UP3) else (UP2 if os.path.exists(UP2) else BASE))\n",
    "\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "STATS_XLSX       = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\"\n",
    "\n",
    "# ====== 列（0-based）=====\n",
    "COL_WEEK = 0\n",
    "COL_AREA_OR_KIND = 1     # ヘッダ行=東/西/九州、次行=AJ/合同/SA\n",
    "COL_CITY = 2\n",
    "COL_VENUE = 3\n",
    "COL_PREF = 5\n",
    "COL_REASON_BT = 72\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,\n",
    "    \"SAME_WEEK_CITY_PENALTY\": 60.0,   # 同週同「連動グループ」ペナ\n",
    "\n",
    "    \"FUZZY_CUTOFF\": 0.86,\n",
    "    \"CANON_CUTOFF\": 0.93,\n",
    "\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    \"OVR_CLASS_J_VALUE\": 1,\n",
    "    \"OVR_MIN_POP\": 180000,\n",
    "    \"OVR_OVERFLOW_PENALTY\": 15.0,\n",
    "\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 2.0, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0,\n",
    "              \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 0) alias辞書（CSV）\n",
    "# ======================================================\n",
    "ALIAS_CSV = \"市区分_alias.csv\"\n",
    "\n",
    "def ensure_alias_template(path=ALIAS_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"alias\":\"なんば\",\"canonical\":\"難波\"},\n",
    "        {\"alias\":\"薩摩河内\",\"canonical\":\"薩摩川内\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ aliasテンプレ作成: {path}\")\n",
    "\n",
    "def load_alias_map(path=ALIAS_CSV):\n",
    "    ensure_alias_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"alias\"] = df[\"alias\"].astype(str).str.strip()\n",
    "        df[\"canonical\"] = df[\"canonical\"].astype(str).str.strip()\n",
    "        return {a:c for a,c in zip(df[\"alias\"], df[\"canonical\"]) if a and c}\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ alias読み込み失敗。aliasなしで続行:\", e)\n",
    "        return {}\n",
    "\n",
    "ALIAS_MAP = load_alias_map(ALIAS_CSV)\n",
    "\n",
    "def apply_alias(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    t = str(s).strip()\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    return ALIAS_MAP.get(t, t)\n",
    "\n",
    "# ======================================================\n",
    "# ★連動グループ定義（CSV）\n",
    "# ======================================================\n",
    "GROUP_CSV = \"市区分_group.csv\"\n",
    "\n",
    "def ensure_group_template(path=GROUP_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"city_key\":\"木更津\",\"group_key\":\"木更津_市原\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"市原\",\"group_key\":\"木更津_市原\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"豊中\",\"group_key\":\"豊中_吹田\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"吹田\",\"group_key\":\"豊中_吹田\",\"cap\":\"2\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ groupテンプレ作成: {path}\")\n",
    "\n",
    "def load_group_map(path=GROUP_CSV):\n",
    "    ensure_group_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"city_key\"]  = df[\"city_key\"].astype(str).str.strip()\n",
    "        df[\"group_key\"] = df[\"group_key\"].astype(str).str.strip()\n",
    "        df[\"cap\"] = df[\"cap\"].astype(str).str.strip()\n",
    "        city_to_group = {}\n",
    "        group_cap = {}\n",
    "        for _, r in df.iterrows():\n",
    "            ck = r[\"city_key\"]; gk = r[\"group_key\"]\n",
    "            if ck and gk:\n",
    "                city_to_group[ck] = gk\n",
    "                if r[\"cap\"]:\n",
    "                    try:\n",
    "                        group_cap[gk] = int(float(r[\"cap\"]))\n",
    "                    except:\n",
    "                        pass\n",
    "        return city_to_group, group_cap\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ group読み込み失敗。groupなしで続行:\", e)\n",
    "        return {}, {}\n",
    "\n",
    "CITY_TO_GROUP, GROUP_CAP = load_group_map(GROUP_CSV)\n",
    "\n",
    "def group_of_citykey(ck: str) -> str:\n",
    "    if not ck:\n",
    "        return \"\"\n",
    "    return CITY_TO_GROUP.get(ck, ck)\n",
    "\n",
    "# ======================================================\n",
    "# 1) 正規化・読みキー・誤字ゆれ生成\n",
    "# ======================================================\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def muni_base(name: str) -> str:\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r\"(都|道|府|県)$\", \"\", s)\n",
    "    s = re.sub(r\"(市|区|町|村)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def to_katakana_reading(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = re.sub(r\"[ \\t\\r\\n\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "\n",
    "    if re.search(r\"[ぁ-んァ-ン]\", s2):\n",
    "        s2 = jaconv.normalize(jaconv.hira2kata(s2))\n",
    "        s2 = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", s2)\n",
    "        return s2\n",
    "\n",
    "    yomi_parts = []\n",
    "    for w in tagger(s2):\n",
    "        feat = w.feature\n",
    "        reading = None\n",
    "        for k in [\"reading\", \"kana\", \"pron\"]:\n",
    "            if hasattr(feat, k):\n",
    "                reading = getattr(feat, k)\n",
    "                break\n",
    "        if not reading or reading == \"*\":\n",
    "            reading = w.surface\n",
    "        yomi_parts.append(reading)\n",
    "\n",
    "    yomi = \"\".join(yomi_parts)\n",
    "    yomi = jaconv.normalize(jaconv.hira2kata(yomi))\n",
    "    yomi = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", yomi)\n",
    "    return yomi\n",
    "\n",
    "CONFUSION = {\n",
    "    \"川\": [\"河\"], \"河\": [\"川\"],\n",
    "    \"崎\": [\"﨑\"], \"﨑\": [\"崎\"],\n",
    "    \"ヶ\": [\"ケ\"], \"ケ\": [\"ヶ\"],\n",
    "    \"斉\": [\"齋\", \"斎\"], \"齋\": [\"斉\", \"斎\"], \"斎\": [\"斉\", \"齋\"],\n",
    "    \"邊\": [\"辺\", \"邉\"], \"邉\": [\"辺\", \"邊\"], \"辺\": [\"邊\", \"邉\"],\n",
    "}\n",
    "\n",
    "def gen_variants(s: str, limit=12):\n",
    "    if s is None:\n",
    "        return [\"\"]\n",
    "    s = str(s)\n",
    "    vars_ = {s}\n",
    "    for a, bs in CONFUSION.items():\n",
    "        if a in s:\n",
    "            new_set = set(vars_)\n",
    "            for v in vars_:\n",
    "                for b in bs:\n",
    "                    new_set.add(v.replace(a, b))\n",
    "            vars_ = new_set\n",
    "        if len(vars_) >= limit:\n",
    "            break\n",
    "    return list(vars_)[:limit]\n",
    "\n",
    "def best_ratio(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ======================================================\n",
    "# ★束ね分解 + D列ヒント（ただし実会場のみ）\n",
    "# ======================================================\n",
    "DELIMS = r\"[・／/、,＋+＆&\\s　]+\"\n",
    "\n",
    "def strip_annotations(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    t = str(s)\n",
    "    t = re.split(r\"[（(]\", t, maxsplit=1)[0]\n",
    "    t = re.split(r\"(会場|要検討|検討|確定)\", t, maxsplit=1)[0]\n",
    "    return t.strip()\n",
    "\n",
    "def split_city_tokens(raw: str):\n",
    "    t = strip_annotations(raw)\n",
    "    if not t:\n",
    "        return []\n",
    "    parts = [p.strip() for p in re.split(DELIMS, t) if p and p.strip()]\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p2 = apply_alias(p)\n",
    "        b = muni_base(p2)\n",
    "        if b:\n",
    "            out.append(b)\n",
    "    seen=set(); uniq=[]\n",
    "    for x in out:\n",
    "        if x not in seen:\n",
    "            uniq.append(x); seen.add(x)\n",
    "    return uniq\n",
    "\n",
    "def find_city_tokens_in_text(text: str, candidates_city_keys):\n",
    "    if not text:\n",
    "        return []\n",
    "    tn = norm(text)\n",
    "    if not tn:\n",
    "        return []\n",
    "    hits=[]\n",
    "    for ck in candidates_city_keys:\n",
    "        nk = norm(ck)\n",
    "        if nk and nk in tn:\n",
    "            hits.append(ck)\n",
    "    seen=set(); out=[]\n",
    "    for h in hits:\n",
    "        if h not in seen:\n",
    "            out.append(h); seen.add(h)\n",
    "    return out\n",
    "\n",
    "def is_placeholder_venue(v):\n",
    "    \"\"\"会場要検討（B/C併記含む）や空欄は '未確定' 扱い\"\"\"\n",
    "    if v is None:\n",
    "        return True\n",
    "    s = str(v).strip()\n",
    "    if s == \"\":\n",
    "        return True\n",
    "    return (\"会場要検討\" in s) or (\"要検討\" in s)\n",
    "\n",
    "EXCLUDE_AJ_BASE_VENUES = (\"AJ日本橋\", \"AJ秋葉原\")\n",
    "EXCLUDE_AJ_COUNT_KEYWORDS = (\"萌え\", \"イラスト\", \"JIF\")\n",
    "\n",
    "def is_excluded_aj_base_venue(venue_raw):\n",
    "    s = \"\" if venue_raw is None else str(venue_raw)\n",
    "    s = re.sub(r\"[\\s　]+\", \"\", s)\n",
    "    for base in EXCLUDE_AJ_BASE_VENUES:\n",
    "        if s == base:\n",
    "            return True\n",
    "        if s.startswith(base):\n",
    "            tail = s[len(base):]\n",
    "            if tail and any(k in tail for k in EXCLUDE_AJ_COUNT_KEYWORDS):\n",
    "                return False\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_fixed_row(city_raw, venue_raw):\n",
    "    # 履歴として数える＝実会場だけ（AJ日本橋/AJ秋葉原の素開催は除外）\n",
    "    if is_placeholder_venue(venue_raw):\n",
    "        return False\n",
    "    if is_excluded_aj_base_venue(venue_raw):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# ======================================================\n",
    "# 2) 東/西/九州 の都道府県範囲（＋北=東に寄せ）\n",
    "# ======================================================\n",
    "EAST_PREF_NUMS  = set(list(range(1, 17)) + [19,20,21,22,23,24])\n",
    "WEST_PREF_NUMS  = set([17,18] + list(range(25, 34)) + [31,32] + [36,37,38,39])\n",
    "KYUSHU_PREF_NUMS= set([34,35] + list(range(40, 47)))\n",
    "\n",
    "def norm_area_label(x):\n",
    "    s = (str(x).strip() if x is not None else \"\")\n",
    "    if s == \"北\":\n",
    "        return \"東\"\n",
    "    return s\n",
    "\n",
    "def pref_num(pref_code_str: str):\n",
    "    if not pref_code_str:\n",
    "        return None\n",
    "    s = str(pref_code_str).strip()\n",
    "    m = re.match(r\"^(\\d{2})\", s)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def area_allowed(area_label: str, pref_code_str: str) -> bool:\n",
    "    al = norm_area_label(area_label)\n",
    "    pn = pref_num(pref_code_str)\n",
    "    if pn is None:\n",
    "        return True\n",
    "    if al == \"東\":\n",
    "        return pn in EAST_PREF_NUMS\n",
    "    if al == \"西\":\n",
    "        return pn in WEST_PREF_NUMS\n",
    "    if al == \"九州\":\n",
    "        return pn in KYUSHU_PREF_NUMS\n",
    "    return True  # 東西九州以外は落とさない\n",
    "\n",
    "# ======================================================\n",
    "# 3) 補助関数\n",
    "# ======================================================\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, group_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if group_key and group_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in {1}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"　\",\" \").replace(\" \", \"\")  # ★空白吸収（A J対策）\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "\n",
    "        area_label = \"\" if pd.isna(header[COL_AREA_OR_KIND]) else str(header[COL_AREA_OR_KIND]).strip()\n",
    "        kind = kind_norm(detail[COL_AREA_OR_KIND])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"area_label\": area_label,\n",
    "            \"kind\": kind, \"city_raw\": city, \"venue_raw\": venue, \"pref_code\": pref\n",
    "        })\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "# ======================================================\n",
    "# 4) 統計量（例外増枠用 + 正規化基準）\n",
    "# ======================================================\n",
    "stats = pd.read_excel(STATS_XLSX, sheet_name=0)\n",
    "stats.columns = [str(c).strip() for c in stats.columns]\n",
    "muni_col = \"市区町村\" if \"市区町村\" in stats.columns else stats.columns[0]\n",
    "\n",
    "stats_base_list = stats[muni_col].astype(str).map(muni_base).map(str.strip)\n",
    "stats_base_list = stats_base_list[stats_base_list != \"\"].dropna().unique().tolist()\n",
    "\n",
    "stats_norm_to_base = {norm(x): x for x in stats_base_list if x}\n",
    "stats_norms = list(stats_norm_to_base.keys())\n",
    "\n",
    "def canonize_city_key(city_key_raw: str):\n",
    "    if not city_key_raw:\n",
    "        return \"\", 0.0\n",
    "    x = apply_alias(city_key_raw)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in stats_norm_to_base and bn:\n",
    "        return stats_norm_to_base[bn], 1.0\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in stats_norm_to_base and vn:\n",
    "            return stats_norm_to_base[vn], 0.995\n",
    "\n",
    "    best_base, best_r = None, 0.0\n",
    "    for v in [b] + gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        for sn in stats_norms:\n",
    "            r = best_ratio(vn, sn)\n",
    "            if r > best_r:\n",
    "                best_r = r\n",
    "                best_base = stats_norm_to_base[sn]\n",
    "    if best_base and best_r >= CONFIG[\"CANON_CUTOFF\"]:\n",
    "        return best_base, best_r\n",
    "\n",
    "    return b, best_r\n",
    "\n",
    "# ======================================================\n",
    "# 5) 四半期表読み込み\n",
    "# ======================================================\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ======================================================\n",
    "# 6) 地域別回数読み込み → 市区分キー正規化して集約\n",
    "# ======================================================\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None, dtype=str)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()].copy()\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key_raw\"] = plan_rows[1].astype(str).str.strip()\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "plan_rows[\"city_key\"] = [canonize_city_key(x)[0] for x in plan_rows[\"city_key_raw\"].tolist()]\n",
    "region_master = plan_rows.groupby([\"pref_parent\",\"city_key\"], as_index=False)[\"plan_count\"].sum()\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# ===== 連動グループで plan_count を組み直す（cap指定があればそれ優先）=====\n",
    "group_members = {}\n",
    "for ck in city_keys:\n",
    "    gk = group_of_citykey(ck)\n",
    "    group_members.setdefault(gk, []).append(ck)\n",
    "\n",
    "plan_count_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    if gk in GROUP_CAP and GROUP_CAP[gk] > 0:\n",
    "        plan_count_by_group[gk] = GROUP_CAP[gk]\n",
    "    else:\n",
    "        plan_count_by_group[gk] = int(sum(plan_count_by_city.get(m, 0) for m in members))\n",
    "\n",
    "# ======================================================\n",
    "# 7) 候補側の索引（表記norm + 読み）\n",
    "# ======================================================\n",
    "city_norm_map = {ck: norm(ck) for ck in city_keys}\n",
    "norm_to_city = {}\n",
    "for ck, nk in city_norm_map.items():\n",
    "    if nk:\n",
    "        norm_to_city.setdefault(nk, []).append(ck)\n",
    "\n",
    "reading_to_city = {}\n",
    "for ck in city_keys:\n",
    "    rd = to_katakana_reading(ck)\n",
    "    if rd:\n",
    "        reading_to_city.setdefault(rd, []).append(ck)\n",
    "\n",
    "def choose_best_by_fuzzy(query_base, cands):\n",
    "    qn = norm(query_base)\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in cands:\n",
    "        r = best_ratio(qn, norm(ck))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    return best_ck, best_r\n",
    "\n",
    "def match_city_key(city_name: str):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    x = apply_alias(city_name)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in norm_to_city and bn:\n",
    "        cands = norm_to_city[bn]\n",
    "        if len(cands) == 1:\n",
    "            return cands[0], 1.0\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        return ck, max(0.97, rr)\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in norm_to_city and vn:\n",
    "            cands = norm_to_city[vn]\n",
    "            if len(cands) == 1:\n",
    "                return cands[0], 0.995\n",
    "            ck, rr = choose_best_by_fuzzy(v, cands)\n",
    "            return ck, max(0.95, rr)\n",
    "\n",
    "    rd = to_katakana_reading(b)\n",
    "    cands = reading_to_city.get(rd, [])\n",
    "    if len(cands) == 1:\n",
    "        return cands[0], 0.99\n",
    "    elif len(cands) >= 2:\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        if ck:\n",
    "            return ck, max(0.93, rr)\n",
    "\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in city_keys:\n",
    "        r = best_ratio(bn, city_norm_map.get(ck, \"\"))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    if best_ck and best_r >= CONFIG[\"FUZZY_CUTOFF\"]:\n",
    "        return best_ck, best_r\n",
    "    return None, best_r\n",
    "\n",
    "def match_city_keys_multi(city_raw: str, venue_raw: str = \"\"):\n",
    "    keys = []\n",
    "    tokens = split_city_tokens(city_raw)\n",
    "    for tok in tokens:\n",
    "        ck, _ = match_city_key(tok)\n",
    "        if ck:\n",
    "            keys.append(ck)\n",
    "\n",
    "    # ★D列ヒントは「実会場のときだけ」使う（会場要検討(B/C)から拾うと履歴が壊れる）\n",
    "    if (not tokens or len(keys) == 0) and venue_raw and (not is_placeholder_venue(venue_raw)):\n",
    "        # B/C併記みたいなのが混ざるのを避ける：とりあえず \"（B:\" 以降は捨てる\n",
    "        vtxt = str(venue_raw)\n",
    "        vtxt = vtxt.split(\"（B:\", 1)[0].split(\"(B:\", 1)[0]\n",
    "        hits = find_city_tokens_in_text(vtxt, city_keys)\n",
    "        keys.extend(hits)\n",
    "\n",
    "    seen=set(); uniq=[]\n",
    "    for k in keys:\n",
    "        if k and k not in seen:\n",
    "            uniq.append(k); seen.add(k)\n",
    "    return uniq\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys1, scores = [], []\n",
    "    key_lists = []\n",
    "    group_lists = []\n",
    "    for city_raw, venue_raw in zip(df[\"city_raw\"].tolist(), df[\"venue_raw\"].tolist()):\n",
    "        klist = match_city_keys_multi(city_raw, venue_raw)\n",
    "        key_lists.append(klist)\n",
    "        k0 = klist[0] if klist else None\n",
    "        keys1.append(k0)\n",
    "\n",
    "        glist = []\n",
    "        for ck in klist:\n",
    "            gk = group_of_citykey(ck)\n",
    "            if gk and gk not in glist:\n",
    "                glist.append(gk)\n",
    "        group_lists.append(glist)\n",
    "\n",
    "        if k0:\n",
    "            toks = split_city_tokens(city_raw)\n",
    "            probe = toks[0] if toks else city_raw\n",
    "            _, sc = match_city_key(probe)\n",
    "            scores.append(sc)\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys1\n",
    "    out[\"city_keys\"] = key_lists\n",
    "    out[\"group_keys\"] = group_lists\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "scheduled42_all = add_city_key(b42.copy())\n",
    "scheduled43_all = add_city_key(b43.copy())\n",
    "\n",
    "# ★履歴に入れるのは「実会場」だけ（会場要検討は履歴にしない）\n",
    "scheduled42 = scheduled42_all[scheduled42_all.apply(lambda r: is_fixed_row(r[\"city_raw\"], r[\"venue_raw\"]), axis=1)].copy()\n",
    "scheduled43 = scheduled43_all[scheduled43_all.apply(lambda r: is_fixed_row(r[\"city_raw\"], r[\"venue_raw\"]), axis=1)].copy()\n",
    "\n",
    "# ★空きAJ枠：city空 かつ (venue空 or 会場要検討)\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"].apply(is_placeholder_venue))\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ======================================================\n",
    "# 8) 都道府県コード推定\n",
    "# ======================================================\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "pref_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    pc = \"\"\n",
    "    for mck in members:\n",
    "        pc = pref_by_city.get(mck, \"\")\n",
    "        if pc:\n",
    "            break\n",
    "    pref_by_group[gk] = pc\n",
    "\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "group_gap = {gk: gap_weeks_from_count(int(cnt)) for gk, cnt in plan_count_by_group.items()}\n",
    "\n",
    "# ======================================================\n",
    "# 9) スパン履歴（42→43連結）★グループ単位\n",
    "# ======================================================\n",
    "OFFSET_43 = len(week_order_42)\n",
    "\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_group = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if isinstance(glist, list):\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                last_pos_group[gk] = max(last_pos_group.get(gk, -999), ap)\n",
    "\n",
    "# 43期の「確定分」だけで消化数（グループ）\n",
    "scheduled_counts_43_group = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if isinstance(glist, list):\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                scheduled_counts_43_group[gk] = scheduled_counts_43_group.get(gk, 0) + 1\n",
    "\n",
    "# ======================================================\n",
    "# 10) 例外増枠プール\n",
    "# ======================================================\n",
    "stats2 = stats.copy()\n",
    "stats2[muni_col] = stats2[muni_col].astype(str).str.strip()\n",
    "\n",
    "class_col = stats2.columns[9] if len(stats2.columns) >= 10 else stats2.columns[-1]\n",
    "stats2[class_col] = pd.to_numeric(stats2[class_col], errors=\"coerce\")\n",
    "\n",
    "pop_col = next((c for c in stats2.columns if \"人口\" in str(c)), None)\n",
    "if pop_col is None:\n",
    "    num_cols=[]\n",
    "    for c in stats2.columns:\n",
    "        s = pd.to_numeric(stats2[c], errors=\"coerce\")\n",
    "        if s.notna().sum() > 0:\n",
    "            num_cols.append((c, float(s.max(skipna=True))))\n",
    "    pop_col = sorted(num_cols, key=lambda x: x[1], reverse=True)[0][0] if num_cols else stats2.columns[-1]\n",
    "stats2[pop_col] = pd.to_numeric(stats2[pop_col], errors=\"coerce\")\n",
    "\n",
    "ovr = stats2[(stats2[class_col] == CONFIG[\"OVR_CLASS_J_VALUE\"]) & (stats2[pop_col] >= CONFIG[\"OVR_MIN_POP\"])].copy()\n",
    "\n",
    "ovr_candidates = {}\n",
    "for name in ovr[muni_col].tolist():\n",
    "    ck, sc = match_city_key(name)\n",
    "    if ck:\n",
    "        pop_val = float(ovr.loc[ovr[muni_col] == name, pop_col].iloc[0])\n",
    "        if ck not in ovr_candidates or sc > ovr_candidates[ck][\"match_score\"]:\n",
    "            ovr_candidates[ck] = {\"name_raw\": name, \"match_score\": sc, \"pop\": pop_val}\n",
    "\n",
    "OVR_POOL = set(ovr_candidates.keys())\n",
    "print(f\"✅ 例外増枠プール: {len(OVR_POOL)}（J列={class_col}==1 & 人口列={pop_col}>=18万）\")\n",
    "\n",
    "# ======================================================\n",
    "# 11) 集客率（あれば）\n",
    "# ======================================================\n",
    "rate_col = next((c for c in stats2.columns if (\"集客率\" in str(c) or \"来場率\" in str(c) or \"動員率\" in str(c))), None)\n",
    "city_rate = {}\n",
    "if rate_col is not None:\n",
    "    tmp = stats2[[muni_col, rate_col]].copy()\n",
    "    tmp[\"rate\"] = pd.to_numeric(tmp[rate_col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"rate\"])\n",
    "    muni_rate_norm = {norm(muni_base(row[muni_col])): float(row[\"rate\"]) for _, row in tmp.iterrows()}\n",
    "    for ck in city_keys:\n",
    "        cn = norm(ck)\n",
    "        if cn in muni_rate_norm:\n",
    "            city_rate[ck] = muni_rate_norm[cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"不明\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"不明\"\n",
    "    return f\"下位{p*100:.0f}%\"\n",
    "\n",
    "# ======================================================\n",
    "# 理由\n",
    "# ======================================================\n",
    "def build_reason(variant, week_id, area_label, ck, gk, pc,\n",
    "                 need_gap_p, gp, need_gap_g, gg,\n",
    "                 remaining_plan_g, overflow_used, overflow_meta,\n",
    "                 same_week_pref_hit, same_week_group_hit, relax_mode, score):\n",
    "    lines=[]\n",
    "    lines.append(f\"【案{variant}】{week_id}／{area_label} の空きAJ枠に対して選定。\")\n",
    "    lines.append(f\"0) 地域フィルタ：{area_label} の範囲内（県コード={pc}）のみ。\")\n",
    "    lines.append(f\"   連動グループ：{gk}（例：木更津+市原=合計年2回、豊中+吹田=合計年2回）\")\n",
    "    if not overflow_used:\n",
    "        lines.append(f\"1) 計画回数（グループ残）：{gk} 残り {remaining_plan_g} 回 → 計画内で採用（候補={ck}）\")\n",
    "    else:\n",
    "        pop = overflow_meta.get(\"pop\", None)\n",
    "        pop_txt = f\"{int(pop):,}人\" if isinstance(pop, (int,float)) and not math.isnan(pop) else \"不明\"\n",
    "        nm = overflow_meta.get(\"name_raw\",\"\") or ck\n",
    "        lines.append(\"1) 計画内で埋まらず、例外増枠を使用。\")\n",
    "        lines.append(f\"   例外：J列=1 & 人口>=18万 → {nm}（人口={pop_txt}）\")\n",
    "\n",
    "    lines.append(f\"2) スパン：県=必要{need_gap_p}週/実績{gp}週、グループ=必要{need_gap_g}週/実績{gg}週\"\n",
    "                 + (f\"（緩和={relax_mode}）\" if relax_mode else \"\"))\n",
    "\n",
    "    if ck in city_rate:\n",
    "        lines.append(f\"3) 集客率：{fmt_rate(city_rate.get(ck))}（{fmt_pct(city_pct.get(ck))}）\")\n",
    "    else:\n",
    "        lines.append(\"3) 集客率：データ無し → 回数/スパン優先\")\n",
    "\n",
    "    lines.append(\"4) 同週回避：\"\n",
    "                 + (\"同県ペナあり\" if same_week_pref_hit else \"同県OK\")\n",
    "                 + (\" / 同グループペナあり\" if same_week_group_hit else \"\"))\n",
    "\n",
    "    lines.append(f\"【採用】score={score:.2f}\")\n",
    "    return \" / \".join(lines)[:32000]\n",
    "\n",
    "# ======================================================\n",
    "# 週×都道府県 / 週×グループ（43期確定分のみ）\n",
    "# ======================================================\n",
    "week_used_pref_base = {}\n",
    "week_used_group_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]\n",
    "    pc = e[\"pref_code\"]\n",
    "    if w and pc:\n",
    "        week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if w and isinstance(glist, list):\n",
    "        s = week_used_group_base.setdefault(w, set())\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                s.add(gk)\n",
    "\n",
    "# ======================================================\n",
    "# 12) プラン生成（A/B/C）\n",
    "# ======================================================\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used_in_plan_group = {gk: 0 for gk in plan_count_by_group.keys()}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_g = dict(last_pos_group)\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "    week_used_group = {w:set(s) for w,s in week_used_group_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow):\n",
    "        gk = group_of_citykey(ck)\n",
    "        pc = pref_by_group.get(gk, \"\") or pref_by_city.get(ck, \"\")\n",
    "\n",
    "        if not area_allowed(area_label, pc):\n",
    "            return None\n",
    "\n",
    "        plan_cnt_g = plan_count_by_group.get(gk, 0)\n",
    "        already_g  = scheduled_counts_43_group.get(gk, 0)\n",
    "        remaining_g = plan_cnt_g - already_g - used_in_plan_group.get(gk, 0)\n",
    "\n",
    "        overflow_used = False\n",
    "        overflow_meta = {}\n",
    "\n",
    "        if remaining_g <= 0:\n",
    "            if not allow_overflow:\n",
    "                return None\n",
    "            if ck not in OVR_POOL:\n",
    "                return None\n",
    "            overflow_used = True\n",
    "            meta = ovr_candidates.get(ck, {})\n",
    "            overflow_meta = {\"name_raw\": meta.get(\"name_raw\",\"\"), \"pop\": meta.get(\"pop\", float(\"nan\"))}\n",
    "\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_g = group_gap.get(gk, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_g = lp_g.get(gk, None)\n",
    "\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gg = 999 if last_g is None else (apos - last_g)\n",
    "\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_g = (last_g is None) or (gg >= need_gap_g)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_g):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        if pc and is_snow_blackout(pc, gk, week_id):\n",
    "            return None\n",
    "\n",
    "        same_week_pref_hit  = (pc and pc in week_used_pref.get(week_id, set()))\n",
    "        same_week_group_hit = (gk and gk in week_used_group.get(week_id, set()))\n",
    "\n",
    "        same_week_pen = (CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0) + \\\n",
    "                        (CONFIG[\"SAME_WEEK_CITY_PENALTY\"] if same_week_group_hit else 0.0)\n",
    "\n",
    "        overflow_pen = CONFIG[\"OVR_OVERFLOW_PENALTY\"] if overflow_used else 0.0\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_g = gg - need_gap_g\n",
    "        need_city = city_need.get(ck, 0.5)\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_g * W[\"city_slack\"] +\n",
    "            max(remaining_g, 0) * W[\"unmet_bonus\"] * 5.0 +\n",
    "            (need_city * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen - same_week_pen - overflow_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        reason = build_reason(\n",
    "            variant, week_id, area_label, ck, gk, pc,\n",
    "            need_gap_p, gp, need_gap_g, gg,\n",
    "            remaining_g,\n",
    "            overflow_used, overflow_meta,\n",
    "            same_week_pref_hit, same_week_group_hit, relax_mode, score\n",
    "        )\n",
    "        return {\"ck\": ck, \"gk\": gk, \"pc\": pc, \"score\": float(score), \"reason\": reason}\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "        area_label = slot.get(\"area_label\", \"\")\n",
    "\n",
    "        best = None\n",
    "\n",
    "        for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "            for ck in city_keys:\n",
    "                cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=False)\n",
    "                if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                    best = cand\n",
    "            if best is not None:\n",
    "                break\n",
    "\n",
    "        if best is None:\n",
    "            for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "                for ck in city_keys:\n",
    "                    cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=True)\n",
    "                    if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                        best = cand\n",
    "                if best is not None:\n",
    "                    break\n",
    "\n",
    "        if best is None:\n",
    "            assigns.append({\n",
    "                \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "                \"assign_city_key\": \"\", \"pref_code_guess\": \"\", \"score\": float(\"-inf\"),\n",
    "                \"reason_BT\": f\"案{variant}: 条件により候補なし（地域={area_label}）\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; gk = best[\"gk\"]; pc = best[\"pc\"]\n",
    "\n",
    "        used_in_plan_group[gk] = used_in_plan_group.get(gk, 0) + 1\n",
    "        lp_g[gk] = apos\n",
    "        week_used_group.setdefault(week_id, set()).add(gk)\n",
    "\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck, \"pref_code_guess\": pc, \"score\": best[\"score\"],\n",
    "            \"reason_BT\": best[\"reason\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "def to_map(df, col):\n",
    "    return {int(r[\"row_header\"]): r[col] for _, r in df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ======================================================\n",
    "# 13) 書き戻し（43期の空きAJ枠だけに書く）\n",
    "# ======================================================\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in {sheet42, sheet43}:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1\n",
    "\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "\n",
    "    # ★空き判定：city空 かつ (venue空 or 会場要検討) のときだけ上書き\n",
    "    if not ((c_val is None or str(c_val).strip()==\"\") and is_placeholder_venue(d_val)):\n",
    "        continue\n",
    "\n",
    "    a = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    ws43.cell(r, COL_CITY+1).value = a\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b if b else '-'} / C:{c if c else '-'}）\"\n",
    "\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    if (ws43.cell(r, COL_PREF+1).value is None) or (str(ws43.cell(r, COL_PREF+1).value).strip()==\"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    ws43.cell(r, COL_REASON_BT+1).value = str(A_reason.get(int(row0), \"案A: 理由生成なし\"))\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "\n",
    "print(\"\\n✅ 入力:\", QUARTER_XLSX)\n",
    "print(\"✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"✅ 43期 空きAJ枠（city空＆会場要検討）:\", len(open43_AJ))\n",
    "print(\"✅ 書込数:\", written)\n",
    "print(\"✅ グループcap例:\", {k:GROUP_CAP.get(k) for k in sorted(GROUP_CAP)[:20]})\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4mjdwRBGVHd",
    "outputId": "fd784a1d-8bec-49c0-9f78-7c82df03056a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 例外増枠プール: 1（J列=Zの4分位（1=赤,2=黄,3=青,4=灰）==1 & 人口列=人口>=18万）\n",
      "\n",
      "✅ 入力: SA+AJ+共有用_四半期表20240303.xlsx\n",
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\n",
      "✅ 43期 空きAJ枠（city空＆会場要検討）: 137\n",
      "✅ 書込数: 137\n",
      "✅ グループcap例: {'木更津_市原': 2, '豊中_吹田': 2}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）\n",
    "# ★東/西/九州の都道府県範囲フィルタ\n",
    "# ★alias / 読み / 誤字ゆれ吸収（会場マスタ不使用）\n",
    "# ★束ね対応（木更津・市原など）＝構成市すべて同一エリア扱い（A仕様：両方1消化）\n",
    "# ★さらに追加：連動グループ対応（木更津+市原=合計年2回、豊中+吹田=合計年2回 等）\n",
    "#   → 回数とスパンは group_key 単位で管理（年2回→gap=約26週）\n",
    "# ============================================\n",
    "\n",
    "!pip -q install fugashi unidic-lite jaconv\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import jaconv\n",
    "from fugashi import Tagger\n",
    "tagger = Tagger()\n",
    "\n",
    "# ====== 入力 ======\n",
    "UP2 = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT (2).xlsx\"\n",
    "UP1 = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT (1).xlsx\"\n",
    "BASE = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "QUARTER_XLSX = UP2 if os.path.exists(UP2) else (UP1 if os.path.exists(UP1) else BASE)\n",
    "\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "STATS_XLSX       = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\"\n",
    "\n",
    "# ====== 列（0-based）=====\n",
    "COL_WEEK = 0\n",
    "COL_AREA_OR_KIND = 1     # ヘッダ行=東/西/九州、次行=AJ/合同/SA\n",
    "COL_CITY = 2\n",
    "COL_VENUE = 3\n",
    "COL_PREF = 5\n",
    "COL_REASON_BT = 72\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,\n",
    "    \"SAME_WEEK_CITY_PENALTY\": 60.0,   # 同週同「連動グループ」ペナ（厳禁にすると詰むのでペナ）\n",
    "\n",
    "    \"FUZZY_CUTOFF\": 0.86,\n",
    "    \"CANON_CUTOFF\": 0.93,\n",
    "\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    \"OVR_CLASS_J_VALUE\": 1,\n",
    "    \"OVR_MIN_POP\": 180000,\n",
    "    \"OVR_OVERFLOW_PENALTY\": 15.0,\n",
    "\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 2.0, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0,\n",
    "              \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 0) alias辞書（CSV）…追記して育てる運用\n",
    "# ======================================================\n",
    "ALIAS_CSV = \"市区分_alias.csv\"\n",
    "\n",
    "def ensure_alias_template(path=ALIAS_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"alias\":\"なんば\",\"canonical\":\"難波\"},\n",
    "        {\"alias\":\"薩摩河内\",\"canonical\":\"薩摩川内\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ aliasテンプレ作成: {path}（必要に応じて追記してください）\")\n",
    "\n",
    "def load_alias_map(path=ALIAS_CSV):\n",
    "    ensure_alias_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"alias\"] = df[\"alias\"].astype(str).str.strip()\n",
    "        df[\"canonical\"] = df[\"canonical\"].astype(str).str.strip()\n",
    "        return {a:c for a,c in zip(df[\"alias\"], df[\"canonical\"]) if a and c}\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ alias読み込み失敗。aliasなしで続行:\", e)\n",
    "        return {}\n",
    "\n",
    "ALIAS_MAP = load_alias_map(ALIAS_CSV)\n",
    "\n",
    "def apply_alias(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    t = str(s).strip()\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    return ALIAS_MAP.get(t, t)\n",
    "\n",
    "# ======================================================\n",
    "# ★追加：連動グループ定義（CSVで育てる）\n",
    "#   city_key,group_key,cap\n",
    "#   例：木更津,木更津_市原,2\n",
    "#       市原,木更津_市原,2\n",
    "#       豊中,豊中_吹田,2\n",
    "#       吹田,豊中_吹田,2\n",
    "# ======================================================\n",
    "GROUP_CSV = \"市区分_group.csv\"\n",
    "\n",
    "def ensure_group_template(path=GROUP_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"city_key\":\"木更津\",\"group_key\":\"木更津_市原\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"市原\",\"group_key\":\"木更津_市原\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"豊中\",\"group_key\":\"豊中_吹田\",\"cap\":\"2\"},\n",
    "        {\"city_key\":\"吹田\",\"group_key\":\"豊中_吹田\",\"cap\":\"2\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ groupテンプレ作成: {path}（必要に応じて追記してください）\")\n",
    "\n",
    "def load_group_map(path=GROUP_CSV):\n",
    "    ensure_group_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"city_key\"]  = df[\"city_key\"].astype(str).str.strip()\n",
    "        df[\"group_key\"] = df[\"group_key\"].astype(str).str.strip()\n",
    "        # capは同一group内で同じ想定。空なら後で合算にフォールバック\n",
    "        df[\"cap\"] = df[\"cap\"].astype(str).str.strip()\n",
    "        city_to_group = {}\n",
    "        group_cap = {}\n",
    "        for _, r in df.iterrows():\n",
    "            ck = r[\"city_key\"]; gk = r[\"group_key\"]\n",
    "            if ck and gk:\n",
    "                city_to_group[ck] = gk\n",
    "                if r[\"cap\"]:\n",
    "                    try:\n",
    "                        group_cap[gk] = int(float(r[\"cap\"]))\n",
    "                    except:\n",
    "                        pass\n",
    "        return city_to_group, group_cap\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ group読み込み失敗。groupなしで続行:\", e)\n",
    "        return {}, {}\n",
    "\n",
    "CITY_TO_GROUP, GROUP_CAP = load_group_map(GROUP_CSV)\n",
    "\n",
    "def group_of_citykey(ck: str) -> str:\n",
    "    \"\"\"候補city_keyを連動グループに寄せる（未定義なら自分自身がグループ）\"\"\"\n",
    "    if not ck:\n",
    "        return \"\"\n",
    "    return CITY_TO_GROUP.get(ck, ck)\n",
    "\n",
    "# ======================================================\n",
    "# 1) 正規化・読みキー・誤字ゆれ生成\n",
    "# ======================================================\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def muni_base(name: str) -> str:\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r\"(都|道|府|県)$\", \"\", s)\n",
    "    s = re.sub(r\"(市|区|町|村)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def to_katakana_reading(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = re.sub(r\"[ \\t\\r\\n\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "\n",
    "    if re.search(r\"[ぁ-んァ-ン]\", s2):\n",
    "        s2 = jaconv.normalize(jaconv.hira2kata(s2))\n",
    "        s2 = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", s2)\n",
    "        return s2\n",
    "\n",
    "    yomi_parts = []\n",
    "    for w in tagger(s2):\n",
    "        feat = w.feature\n",
    "        reading = None\n",
    "        for k in [\"reading\", \"kana\", \"pron\"]:\n",
    "            if hasattr(feat, k):\n",
    "                reading = getattr(feat, k)\n",
    "                break\n",
    "        if not reading or reading == \"*\":\n",
    "            reading = w.surface\n",
    "        yomi_parts.append(reading)\n",
    "\n",
    "    yomi = \"\".join(yomi_parts)\n",
    "    yomi = jaconv.normalize(jaconv.hira2kata(yomi))\n",
    "    yomi = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", yomi)\n",
    "    return yomi\n",
    "\n",
    "CONFUSION = {\n",
    "    \"川\": [\"河\"], \"河\": [\"川\"],\n",
    "    \"崎\": [\"﨑\"], \"﨑\": [\"崎\"],\n",
    "    \"ヶ\": [\"ケ\"], \"ケ\": [\"ヶ\"],\n",
    "    \"斉\": [\"齋\", \"斎\"], \"齋\": [\"斉\", \"斎\"], \"斎\": [\"斉\", \"齋\"],\n",
    "    \"邊\": [\"辺\", \"邉\"], \"邉\": [\"辺\", \"邊\"], \"辺\": [\"邊\", \"邉\"],\n",
    "}\n",
    "\n",
    "def gen_variants(s: str, limit=12):\n",
    "    if s is None:\n",
    "        return [\"\"]\n",
    "    s = str(s)\n",
    "    vars_ = {s}\n",
    "    for a, bs in CONFUSION.items():\n",
    "        if a in s:\n",
    "            new_set = set(vars_)\n",
    "            for v in vars_:\n",
    "                for b in bs:\n",
    "                    new_set.add(v.replace(a, b))\n",
    "            vars_ = new_set\n",
    "        if len(vars_) >= limit:\n",
    "            break\n",
    "    return list(vars_)[:limit]\n",
    "\n",
    "def best_ratio(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ======================================================\n",
    "# ★束ね分解 + D列ヒント\n",
    "# ======================================================\n",
    "DELIMS = r\"[・／/、,＋+＆&\\s　]+\"\n",
    "\n",
    "def strip_annotations(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    t = str(s)\n",
    "    t = re.split(r\"[（(]\", t, maxsplit=1)[0]\n",
    "    t = re.split(r\"(会場|要検討|検討|確定)\", t, maxsplit=1)[0]\n",
    "    return t.strip()\n",
    "\n",
    "def split_city_tokens(raw: str):\n",
    "    t = strip_annotations(raw)\n",
    "    if not t:\n",
    "        return []\n",
    "    parts = [p.strip() for p in re.split(DELIMS, t) if p and p.strip()]\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p2 = apply_alias(p)\n",
    "        b = muni_base(p2)\n",
    "        if b:\n",
    "            out.append(b)\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for x in out:\n",
    "        if x not in seen:\n",
    "            uniq.append(x); seen.add(x)\n",
    "    return uniq\n",
    "\n",
    "def find_city_tokens_in_text(text: str, candidates_city_keys):\n",
    "    if not text:\n",
    "        return []\n",
    "    tn = norm(text)\n",
    "    if not tn:\n",
    "        return []\n",
    "    hits = []\n",
    "    for ck in candidates_city_keys:\n",
    "        nk = norm(ck)\n",
    "        if nk and nk in tn:\n",
    "            hits.append(ck)\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        if h not in seen:\n",
    "            out.append(h); seen.add(h)\n",
    "    return out\n",
    "\n",
    "# ======================================================\n",
    "# 2) 東/西/九州 の都道府県範囲\n",
    "# ======================================================\n",
    "EAST_PREF_NUMS  = set(list(range(1, 17)) + [19,20,21,22,23,24])\n",
    "WEST_PREF_NUMS  = set([17,18] + list(range(25, 34)) + [31,32] + [36,37,38,39])\n",
    "KYUSHU_PREF_NUMS= set([34,35] + list(range(40, 47)))\n",
    "\n",
    "def pref_num(pref_code_str: str):\n",
    "    if not pref_code_str:\n",
    "        return None\n",
    "    s = str(pref_code_str).strip()\n",
    "    m = re.match(r\"^(\\d{2})\", s)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def area_allowed(area_label: str, pref_code_str: str) -> bool:\n",
    "    al = (str(area_label).strip() if area_label else \"\")\n",
    "    pn = pref_num(pref_code_str)\n",
    "    if pn is None:\n",
    "        return True\n",
    "    if al == \"東\":\n",
    "        return pn in EAST_PREF_NUMS\n",
    "    if al == \"西\":\n",
    "        return pn in WEST_PREF_NUMS\n",
    "    if al == \"九州\":\n",
    "        return pn in KYUSHU_PREF_NUMS\n",
    "    return True\n",
    "\n",
    "# ======================================================\n",
    "# 3) 補助関数\n",
    "# ======================================================\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, group_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if group_key and group_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in {1}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "\n",
    "        area_label = \"\" if pd.isna(header[COL_AREA_OR_KIND]) else str(header[COL_AREA_OR_KIND]).strip()\n",
    "        kind = kind_norm(detail[COL_AREA_OR_KIND])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"area_label\": area_label,\n",
    "            \"kind\": kind, \"city_raw\": city, \"venue_raw\": venue, \"pref_code\": pref\n",
    "        })\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "# ======================================================\n",
    "# 4) 統計量（例外増枠用 + 正規化基準）\n",
    "# ======================================================\n",
    "stats = pd.read_excel(STATS_XLSX, sheet_name=0)\n",
    "stats.columns = [str(c).strip() for c in stats.columns]\n",
    "muni_col = \"市区町村\" if \"市区町村\" in stats.columns else stats.columns[0]\n",
    "\n",
    "stats_base_list = stats[muni_col].astype(str).map(muni_base).map(str.strip)\n",
    "stats_base_list = stats_base_list[stats_base_list != \"\"].dropna().unique().tolist()\n",
    "\n",
    "stats_norm_to_base = {norm(x): x for x in stats_base_list if x}\n",
    "stats_norms = list(stats_norm_to_base.keys())\n",
    "\n",
    "def canonize_city_key(city_key_raw: str):\n",
    "    if not city_key_raw:\n",
    "        return \"\", 0.0\n",
    "    x = apply_alias(city_key_raw)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in stats_norm_to_base and bn:\n",
    "        return stats_norm_to_base[bn], 1.0\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in stats_norm_to_base and vn:\n",
    "            return stats_norm_to_base[vn], 0.995\n",
    "\n",
    "    best_base, best_r = None, 0.0\n",
    "    for v in [b] + gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        for sn in stats_norms:\n",
    "            r = best_ratio(vn, sn)\n",
    "            if r > best_r:\n",
    "                best_r = r\n",
    "                best_base = stats_norm_to_base[sn]\n",
    "    if best_base and best_r >= CONFIG[\"CANON_CUTOFF\"]:\n",
    "        return best_base, best_r\n",
    "\n",
    "    return b, best_r\n",
    "\n",
    "# ======================================================\n",
    "# 5) 四半期表読み込み\n",
    "# ======================================================\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ======================================================\n",
    "# 6) 地域別回数読み込み → 市区分キー正規化して集約\n",
    "# ======================================================\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None, dtype=str)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()].copy()\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key_raw\"] = plan_rows[1].astype(str).str.strip()\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "canon_list = []\n",
    "for x in plan_rows[\"city_key_raw\"].tolist():\n",
    "    canon, sc = canonize_city_key(x)\n",
    "    canon_list.append(canon)\n",
    "plan_rows[\"city_key\"] = canon_list\n",
    "\n",
    "region_master = plan_rows.groupby([\"pref_parent\",\"city_key\"], as_index=False)[\"plan_count\"].sum()\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# ===== 連動グループで plan_count を組み直す（cap指定があればそれ優先）=====\n",
    "group_members = {}\n",
    "for ck in city_keys:\n",
    "    gk = group_of_citykey(ck)\n",
    "    group_members.setdefault(gk, []).append(ck)\n",
    "\n",
    "plan_count_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    if gk in GROUP_CAP and GROUP_CAP[gk] > 0:\n",
    "        plan_count_by_group[gk] = GROUP_CAP[gk]\n",
    "    else:\n",
    "        plan_count_by_group[gk] = int(sum(plan_count_by_city.get(m, 0) for m in members))\n",
    "\n",
    "# ======================================================\n",
    "# 7) 候補側の索引（表記norm + 読み）\n",
    "# ======================================================\n",
    "city_norm_map = {ck: norm(ck) for ck in city_keys}\n",
    "norm_to_city = {}\n",
    "for ck, nk in city_norm_map.items():\n",
    "    if nk:\n",
    "        norm_to_city.setdefault(nk, []).append(ck)\n",
    "\n",
    "reading_to_city = {}\n",
    "for ck in city_keys:\n",
    "    rd = to_katakana_reading(ck)\n",
    "    if rd:\n",
    "        reading_to_city.setdefault(rd, []).append(ck)\n",
    "\n",
    "def choose_best_by_fuzzy(query_base, cands):\n",
    "    qn = norm(query_base)\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in cands:\n",
    "        r = best_ratio(qn, norm(ck))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    return best_ck, best_r\n",
    "\n",
    "def match_city_key(city_name: str):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    x = apply_alias(city_name)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in norm_to_city and bn:\n",
    "        cands = norm_to_city[bn]\n",
    "        if len(cands) == 1:\n",
    "            return cands[0], 1.0\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        return ck, max(0.97, rr)\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in norm_to_city and vn:\n",
    "            cands = norm_to_city[vn]\n",
    "            if len(cands) == 1:\n",
    "                return cands[0], 0.995\n",
    "            ck, rr = choose_best_by_fuzzy(v, cands)\n",
    "            return ck, max(0.95, rr)\n",
    "\n",
    "    rd = to_katakana_reading(b)\n",
    "    cands = reading_to_city.get(rd, [])\n",
    "    if len(cands) == 1:\n",
    "        return cands[0], 0.99\n",
    "    elif len(cands) >= 2:\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        if ck:\n",
    "            return ck, max(0.93, rr)\n",
    "\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in city_keys:\n",
    "        r = best_ratio(bn, city_norm_map.get(ck, \"\"))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    if best_ck and best_r >= CONFIG[\"FUZZY_CUTOFF\"]:\n",
    "        return best_ck, best_r\n",
    "    return None, best_r\n",
    "\n",
    "def match_city_keys_multi(city_raw: str, venue_raw: str = \"\"):\n",
    "    keys = []\n",
    "    tokens = split_city_tokens(city_raw)\n",
    "    for tok in tokens:\n",
    "        ck, sc = match_city_key(tok)\n",
    "        if ck:\n",
    "            keys.append(ck)\n",
    "    if (not tokens or len(keys) == 0) and venue_raw:\n",
    "        hits = find_city_tokens_in_text(venue_raw, city_keys)\n",
    "        keys.extend(hits)\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for k in keys:\n",
    "        if k and k not in seen:\n",
    "            uniq.append(k); seen.add(k)\n",
    "    return uniq\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys1, scores = [], []\n",
    "    key_lists = []\n",
    "    group_lists = []\n",
    "    for city_raw, venue_raw in zip(df[\"city_raw\"].tolist(), df[\"venue_raw\"].tolist()):\n",
    "        klist = match_city_keys_multi(city_raw, venue_raw)\n",
    "        key_lists.append(klist)\n",
    "        k0 = klist[0] if klist else None\n",
    "        keys1.append(k0)\n",
    "\n",
    "        # 連動グループ（束ね構成市→グループに寄せる）\n",
    "        glist = []\n",
    "        for ck in klist:\n",
    "            gk = group_of_citykey(ck)\n",
    "            if gk and gk not in glist:\n",
    "                glist.append(gk)\n",
    "        group_lists.append(glist)\n",
    "\n",
    "        if k0:\n",
    "            toks = split_city_tokens(city_raw)\n",
    "            probe = toks[0] if toks else city_raw\n",
    "            _, sc = match_city_key(probe)\n",
    "            scores.append(sc)\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys1\n",
    "    out[\"city_keys\"] = key_lists\n",
    "    out[\"group_keys\"] = group_lists\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "scheduled42 = add_city_key(b42[(b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")].copy())\n",
    "scheduled43 = add_city_key(b43[(b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")].copy())\n",
    "\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ======================================================\n",
    "# 8) 都道府県コード推定\n",
    "# ======================================================\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "# グループ→県は「メンバーの県が取れるものを優先」で代表値\n",
    "pref_by_group = {}\n",
    "for gk, members in group_members.items():\n",
    "    pc = \"\"\n",
    "    for mck in members:\n",
    "        pc = pref_by_city.get(mck, \"\")\n",
    "        if pc:\n",
    "            break\n",
    "    pref_by_group[gk] = pc\n",
    "\n",
    "# gap（県/グループ）\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "group_gap = {gk: gap_weeks_from_count(int(cnt)) for gk, cnt in plan_count_by_group.items()}\n",
    "\n",
    "# ======================================================\n",
    "# 9) スパン履歴（42→43連結）★グループ単位で更新\n",
    "# ======================================================\n",
    "OFFSET_43 = len(week_order_42)\n",
    "\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_group = {}, {}\n",
    "\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "\n",
    "    # 連動グループ（束ね含む）：group_keys の全要素に反映\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if isinstance(glist, list) and glist:\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                last_pos_group[gk] = max(last_pos_group.get(gk, -999), ap)\n",
    "\n",
    "# ★A仕様：束ね1回＝構成市すべて1消化 → さらに連動グループで「合計消化」する\n",
    "scheduled_counts_43_group = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if isinstance(glist, list) and glist:\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                scheduled_counts_43_group[gk] = scheduled_counts_43_group.get(gk, 0) + 1\n",
    "\n",
    "# ======================================================\n",
    "# 10) 例外増枠プール（J列=1 & 人口>=18万）\n",
    "# ======================================================\n",
    "stats2 = stats.copy()\n",
    "stats2[muni_col] = stats2[muni_col].astype(str).str.strip()\n",
    "\n",
    "class_col = stats2.columns[9] if len(stats2.columns) >= 10 else stats2.columns[-1]\n",
    "stats2[class_col] = pd.to_numeric(stats2[class_col], errors=\"coerce\")\n",
    "\n",
    "pop_col = next((c for c in stats2.columns if \"人口\" in str(c)), None)\n",
    "if pop_col is None:\n",
    "    num_cols = []\n",
    "    for c in stats2.columns:\n",
    "        s = pd.to_numeric(stats2[c], errors=\"coerce\")\n",
    "        if s.notna().sum() > 0:\n",
    "            num_cols.append((c, float(s.max(skipna=True))))\n",
    "    pop_col = sorted(num_cols, key=lambda x: x[1], reverse=True)[0][0] if num_cols else stats2.columns[-1]\n",
    "stats2[pop_col] = pd.to_numeric(stats2[pop_col], errors=\"coerce\")\n",
    "\n",
    "ovr = stats2[(stats2[class_col] == CONFIG[\"OVR_CLASS_J_VALUE\"]) & (stats2[pop_col] >= CONFIG[\"OVR_MIN_POP\"])].copy()\n",
    "\n",
    "ovr_candidates = {}\n",
    "for name in ovr[muni_col].tolist():\n",
    "    ck, sc = match_city_key(name)\n",
    "    if ck:\n",
    "        pop_val = float(ovr.loc[ovr[muni_col] == name, pop_col].iloc[0])\n",
    "        if ck not in ovr_candidates or sc > ovr_candidates[ck][\"match_score\"]:\n",
    "            ovr_candidates[ck] = {\"name_raw\": name, \"match_score\": sc, \"pop\": pop_val}\n",
    "\n",
    "OVR_POOL = set(ovr_candidates.keys())\n",
    "print(f\"✅ 例外増枠プール: {len(OVR_POOL)}（J列={class_col}==1 & 人口列={pop_col}>=18万）\")\n",
    "\n",
    "# ======================================================\n",
    "# 11) 集客率（あれば市区分に寄せる。無ければ0.5）\n",
    "# ======================================================\n",
    "rate_col = next((c for c in stats2.columns if (\"集客率\" in str(c) or \"来場率\" in str(c) or \"動員率\" in str(c))), None)\n",
    "city_rate = {}\n",
    "if rate_col is not None:\n",
    "    tmp = stats2[[muni_col, rate_col]].copy()\n",
    "    tmp[\"rate\"] = pd.to_numeric(tmp[rate_col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"rate\"])\n",
    "    muni_rate_norm = {norm(muni_base(row[muni_col])): float(row[\"rate\"]) for _, row in tmp.iterrows()}\n",
    "    for ck in city_keys:\n",
    "        cn = norm(ck)\n",
    "        if cn in muni_rate_norm:\n",
    "            city_rate[ck] = muni_rate_norm[cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"不明\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"不明\"\n",
    "    return f\"下位{p*100:.0f}%\"\n",
    "\n",
    "# ======================================================\n",
    "# 理由生成（グループ単位のスパン・残回数を表示）\n",
    "# ======================================================\n",
    "def build_reason(variant, week_id, area_label, ck, gk, pc,\n",
    "                 need_gap_p, gp, need_gap_g, gg,\n",
    "                 remaining_plan_g, overflow_used, overflow_meta,\n",
    "                 same_week_pref_hit, same_week_group_hit, relax_mode, score):\n",
    "    lines = []\n",
    "    lines.append(f\"【案{variant}】この枠（{week_id}／{area_label}）はAJ枠が空いていたので、次の順で選びました。\")\n",
    "    lines.append(f\"0) 地域フィルタ：この枠は「{area_label}」なので、対象都道府県の範囲内だけから選定。\")\n",
    "    lines.append(f\"   連動グループ：{gk}（例：木更津+市原=合計年2回、豊中+吹田=合計年2回）\")\n",
    "    if not overflow_used:\n",
    "        lines.append(f\"1) 計画回数（グループ残）：{gk} は残り {remaining_plan_g} 回あるため計画内で採用。（候補={ck}）\")\n",
    "    else:\n",
    "        pop = overflow_meta.get(\"pop\", None)\n",
    "        pop_txt = f\"{int(pop):,}人\" if isinstance(pop, (int,float)) and not math.isnan(pop) else \"不明\"\n",
    "        nm = overflow_meta.get(\"name_raw\",\"\") or ck\n",
    "        lines.append(\"1) 計画内だけでは埋め切れず、例外ルールで増枠。\")\n",
    "        lines.append(f\"   例外条件：統計量のJ列=1 & 人口18万人以上 → {nm}（人口={pop_txt}）\")\n",
    "\n",
    "    lines.append(f\"2) スパン：県は必要{need_gap_p}週に対し実績{gp}週／グループは必要{need_gap_g}週に対し実績{gg}週\"\n",
    "                 + (f\"（制約緩和={relax_mode}）\" if relax_mode else \"\"))\n",
    "\n",
    "    if ck in city_rate:\n",
    "        lines.append(f\"3) 集客率：{fmt_rate(city_rate.get(ck))}（{fmt_pct(city_pct.get(ck))}）。改善余地が大きいほど優先度UP。\")\n",
    "    else:\n",
    "        lines.append(\"3) 集客率：データが取れないため、回数とスパンを優先。\")\n",
    "\n",
    "    lines.append(\"4) 同週はカニバりやすいので基本回避。\"\n",
    "                 + (\"（同週同県ペナ）\" if same_week_pref_hit else \"（同週同県は回避）\")\n",
    "                 + (\"（同週同グループペナ）\" if same_week_group_hit else \"\"))\n",
    "\n",
    "    lines.append(\"5) 豪雪の12〜2月・3月1wは原則除外（例外リストで解除可）。\")\n",
    "    lines.append(f\"【まとめ】グループ回数×グループスパン×改善余地×同週回避を総合。（score={score:.2f}）\")\n",
    "    return \" / \".join(lines)[:32000]\n",
    "\n",
    "# ======================================================\n",
    "# 週×都道府県 / 週×グループ（43期）\n",
    "# ======================================================\n",
    "week_used_pref_base = {}\n",
    "week_used_group_base = {}\n",
    "\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]\n",
    "    pc = e[\"pref_code\"]\n",
    "    if w and pc:\n",
    "        week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "    glist = e.get(\"group_keys\", [])\n",
    "    if w and isinstance(glist, list):\n",
    "        s = week_used_group_base.setdefault(w, set())\n",
    "        for gk in glist:\n",
    "            if gk:\n",
    "                s.add(gk)\n",
    "\n",
    "# ======================================================\n",
    "# 12) プラン生成（A/B/C）…★グループ単位で残回数・スパン判定\n",
    "# ======================================================\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used_in_plan_group = {gk: 0 for gk in plan_count_by_group.keys()}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_g = dict(last_pos_group)\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "    week_used_group = {w:set(s) for w,s in week_used_group_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow):\n",
    "        gk = group_of_citykey(ck)\n",
    "        pc = pref_by_group.get(gk, \"\") or pref_by_city.get(ck, \"\")\n",
    "\n",
    "        # 地域フィルタ（県ベース）\n",
    "        if not area_allowed(area_label, pc):\n",
    "            return None\n",
    "\n",
    "        plan_cnt_g = plan_count_by_group.get(gk, 0)\n",
    "        already_g  = scheduled_counts_43_group.get(gk, 0)\n",
    "        remaining_g = plan_cnt_g - already_g - used_in_plan_group.get(gk, 0)\n",
    "\n",
    "        overflow_used = False\n",
    "        overflow_meta = {}\n",
    "\n",
    "        if remaining_g <= 0:\n",
    "            # グループ残が無い場合は、例外増枠（ck単位のプール）に頼る\n",
    "            if not allow_overflow:\n",
    "                return None\n",
    "            if ck not in OVR_POOL:\n",
    "                return None\n",
    "            overflow_used = True\n",
    "            meta = ovr_candidates.get(ck, {})\n",
    "            overflow_meta = {\"name_raw\": meta.get(\"name_raw\",\"\"), \"pop\": meta.get(\"pop\", float(\"nan\"))}\n",
    "\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_g = group_gap.get(gk, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_g = lp_g.get(gk, None)\n",
    "\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gg = 999 if last_g is None else (apos - last_g)\n",
    "\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_g = (last_g is None) or (gg >= need_gap_g)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_g):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪（グループ単位で弾く）\n",
    "        if pc and is_snow_blackout(pc, gk, week_id):\n",
    "            return None\n",
    "\n",
    "        same_week_pref_hit  = (pc and pc in week_used_pref.get(week_id, set()))\n",
    "        same_week_group_hit = (gk and gk in week_used_group.get(week_id, set()))\n",
    "\n",
    "        same_week_pen = (CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0) + \\\n",
    "                        (CONFIG[\"SAME_WEEK_CITY_PENALTY\"] if same_week_group_hit else 0.0)\n",
    "\n",
    "        overflow_pen = CONFIG[\"OVR_OVERFLOW_PENALTY\"] if overflow_used else 0.0\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_g = gg - need_gap_g\n",
    "        need_city = city_need.get(ck, 0.5)\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_g * W[\"city_slack\"] +                      # ★市ではなくグループスパンを採点\n",
    "            max(remaining_g, 0) * W[\"unmet_bonus\"] * 5.0 +   # ★残回数もグループ\n",
    "            (need_city * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen - same_week_pen - overflow_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        reason = build_reason(\n",
    "            variant, week_id, area_label, ck, gk, pc,\n",
    "            need_gap_p, gp, need_gap_g, gg,\n",
    "            remaining_g,\n",
    "            overflow_used, overflow_meta,\n",
    "            same_week_pref_hit, same_week_group_hit, relax_mode, score\n",
    "        )\n",
    "\n",
    "        return {\"ck\": ck, \"gk\": gk, \"pc\": pc, \"score\": float(score), \"reason\": reason}\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "        area_label = slot.get(\"area_label\", \"\")\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # 計画内で探す\n",
    "        for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "            for ck in city_keys:\n",
    "                cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=False)\n",
    "                if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                    best = cand\n",
    "            if best is not None:\n",
    "                break\n",
    "\n",
    "        # 例外増枠\n",
    "        if best is None:\n",
    "            for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "                for ck in city_keys:\n",
    "                    cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=True)\n",
    "                    if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                        best = cand\n",
    "                if best is not None:\n",
    "                    break\n",
    "\n",
    "        if best is None:\n",
    "            assigns.append({\n",
    "                \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "                \"assign_city_key\": \"\", \"pref_code_guess\": \"\", \"score\": float(\"-inf\"),\n",
    "                \"reason_BT\": f\"案{variant}: 条件により候補なし（地域={area_label}）\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; gk = best[\"gk\"]; pc = best[\"pc\"]\n",
    "\n",
    "        # ★更新：消化・履歴はグループ単位\n",
    "        used_in_plan_group[gk] = used_in_plan_group.get(gk, 0) + 1\n",
    "        lp_g[gk] = apos\n",
    "        week_used_group.setdefault(week_id, set()).add(gk)\n",
    "\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck, \"pref_code_guess\": pc, \"score\": best[\"score\"],\n",
    "            \"reason_BT\": best[\"reason\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "def to_map(df, col):\n",
    "    return {int(r[\"row_header\"]): r[col] for _, r in df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ======================================================\n",
    "# 13) 書き戻し（43期の空欄AJ枠に A + (B/C併記) + BT理由）\n",
    "# ======================================================\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in {sheet42, sheet43}:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1\n",
    "\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "    if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "        continue\n",
    "\n",
    "    a = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    ws43.cell(r, COL_CITY+1).value = a\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b if b else '-'} / C:{c if c else '-'}）\"\n",
    "\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    if (ws43.cell(r, COL_PREF+1).value is None) or (str(ws43.cell(r, COL_PREF+1).value).strip()==\"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    ws43.cell(r, COL_REASON_BT+1).value = str(A_reason.get(int(row0), \"案A: 理由生成なし\"))\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "print(\"\\n✅ 入力:\", QUARTER_XLSX)\n",
    "print(\"✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"✅ 43期 空欄AJ枠 書込数:\", written)\n",
    "print(\"✅ 連動グループ cap（例：年2回→gap約26週）:\", {k:GROUP_CAP.get(k) for k in sorted(GROUP_CAP)[:20]})\n",
    "print(\"✅ 東:\", sorted(EAST_PREF_NUMS))\n",
    "print(\"✅ 西:\", sorted(WEST_PREF_NUMS))\n",
    "print(\"✅ 九州:\", sorted(KYUSHU_PREF_NUMS))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjOeOnh6g1ET",
    "outputId": "c4e48ee5-4f1c-4f9e-b19f-c35d911932a0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 例外増枠プール: 1（J列=Zの4分位（1=赤,2=黄,3=青,4=灰）==1 & 人口列=人口>=18万）\n",
      "\n",
      "✅ 入力: SA+AJ+共有用_四半期表20240303.xlsx\n",
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\n",
      "✅ 43期 空欄AJ枠 書込数: 137\n",
      "✅ 連動グループ cap（例：年2回→gap約26週）: {'木更津_市原': 2, '豊中_吹田': 2}\n",
      "✅ 東: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24]\n",
      "✅ 西: [17, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39]\n",
      "✅ 九州: [34, 35, 40, 41, 42, 43, 44, 45, 46]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）\n",
    "# ★追加：東/西/九州の都道府県範囲フィルタ\n",
    "# ★追加：①alias ②読みキー ③誤字ゆれ生成 による表記ゆれ吸収\n",
    "# ★追加：市区分「束ね」対応（例：木更津・市原）＝構成市すべてを同一エリア扱い（A仕様：両方1消化）\n",
    "# ★追加：C列基本、Cで拾えない時はD列（会場）から市区分ヒント拾い（同セル内）\n",
    "# （会場マスタは使わない）\n",
    "# ============================================\n",
    "\n",
    "!pip -q install fugashi unidic-lite jaconv\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import jaconv\n",
    "from fugashi import Tagger\n",
    "\n",
    "tagger = Tagger()\n",
    "\n",
    "# ====== 入力 ======\n",
    "# まず /mnt/data にあるアップロードファイルを優先して拾う（あれば）\n",
    "DEFAULT_UPLOADED = \"/mnt/data/SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT (1).xlsx\"\n",
    "QUARTER_XLSX = DEFAULT_UPLOADED if os.path.exists(DEFAULT_UPLOADED) else \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "STATS_XLSX       = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "# ====== 出力（42/43のみ残して出す）======\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\"\n",
    "\n",
    "# ====== 列（0-based）=====\n",
    "COL_WEEK = 0\n",
    "COL_AREA_OR_KIND = 1     # ★ヘッダ行=東/西/九州、次行=AJ/合同/SA\n",
    "COL_CITY = 2             # 都道府県/市区分（例：静岡、難波、博多…）\n",
    "COL_VENUE = 3            # 会場（※この文字列内にもヒントがある場合がある）\n",
    "COL_PREF = 5\n",
    "COL_REASON_BT = 72       # BT\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,  # 同週同県ペナ\n",
    "    \"SAME_WEEK_CITY_PENALTY\": 60.0,  # ★追加：同週同市区分（束ね構成市含む）ペナ（破綻しにくいのでペナに留める）\n",
    "\n",
    "    # 表記ゆれ\n",
    "    \"FUZZY_CUTOFF\": 0.86,\n",
    "    \"CANON_CUTOFF\": 0.93,\n",
    "\n",
    "    # 豪雪\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    # 例外増枠\n",
    "    \"OVR_CLASS_J_VALUE\": 1,\n",
    "    \"OVR_MIN_POP\": 180000,\n",
    "    \"OVR_OVERFLOW_PENALTY\": 15.0,\n",
    "\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 2.0, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0,\n",
    "              \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 0) alias辞書（CSV）…追記して育てる運用\n",
    "# ======================================================\n",
    "ALIAS_CSV = \"市区分_alias.csv\"\n",
    "\n",
    "def ensure_alias_template(path=ALIAS_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"alias\":\"なんば\",\"canonical\":\"難波\"},\n",
    "        {\"alias\":\"薩摩河内\",\"canonical\":\"薩摩川内\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ aliasテンプレ作成: {path}（必要に応じて追記してください）\")\n",
    "\n",
    "def load_alias_map(path=ALIAS_CSV):\n",
    "    ensure_alias_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"alias\"] = df[\"alias\"].astype(str).str.strip()\n",
    "        df[\"canonical\"] = df[\"canonical\"].astype(str).str.strip()\n",
    "        return {a:c for a,c in zip(df[\"alias\"], df[\"canonical\"]) if a and c}\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ alias読み込み失敗。aliasなしで続行:\", e)\n",
    "        return {}\n",
    "\n",
    "ALIAS_MAP = load_alias_map(ALIAS_CSV)\n",
    "\n",
    "def apply_alias(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    t = str(s).strip()\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    return ALIAS_MAP.get(t, t)\n",
    "\n",
    "# ======================================================\n",
    "# 1) 正規化・読みキー・誤字ゆれ生成\n",
    "# ======================================================\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def muni_base(name: str) -> str:\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r\"(都|道|府|県)$\", \"\", s)\n",
    "    s = re.sub(r\"(市|区|町|村)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def to_katakana_reading(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = re.sub(r\"[ \\t\\r\\n\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "\n",
    "    if re.search(r\"[ぁ-んァ-ン]\", s2):\n",
    "        s2 = jaconv.normalize(jaconv.hira2kata(s2))\n",
    "        s2 = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", s2)\n",
    "        return s2\n",
    "\n",
    "    yomi_parts = []\n",
    "    for w in tagger(s2):\n",
    "        feat = w.feature\n",
    "        reading = None\n",
    "        for k in [\"reading\", \"kana\", \"pron\"]:\n",
    "            if hasattr(feat, k):\n",
    "                reading = getattr(feat, k)\n",
    "                break\n",
    "        if not reading or reading == \"*\":\n",
    "            reading = w.surface\n",
    "        yomi_parts.append(reading)\n",
    "\n",
    "    yomi = \"\".join(yomi_parts)\n",
    "    yomi = jaconv.normalize(jaconv.hira2kata(yomi))\n",
    "    yomi = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", yomi)\n",
    "    return yomi\n",
    "\n",
    "CONFUSION = {\n",
    "    \"川\": [\"河\"],\n",
    "    \"河\": [\"川\"],\n",
    "    \"崎\": [\"﨑\"],\n",
    "    \"﨑\": [\"崎\"],\n",
    "    \"ヶ\": [\"ケ\"],\n",
    "    \"ケ\": [\"ヶ\"],\n",
    "    \"斉\": [\"齋\", \"斎\"],\n",
    "    \"齋\": [\"斉\", \"斎\"],\n",
    "    \"斎\": [\"斉\", \"齋\"],\n",
    "    \"邊\": [\"辺\", \"邉\"],\n",
    "    \"邉\": [\"辺\", \"邊\"],\n",
    "    \"辺\": [\"邊\", \"邉\"],\n",
    "}\n",
    "\n",
    "def gen_variants(s: str, limit=12):\n",
    "    if s is None:\n",
    "        return [\"\"]\n",
    "    s = str(s)\n",
    "    vars_ = {s}\n",
    "    for a, bs in CONFUSION.items():\n",
    "        if a in s:\n",
    "            new_set = set(vars_)\n",
    "            for v in vars_:\n",
    "                for b in bs:\n",
    "                    new_set.add(v.replace(a, b))\n",
    "            vars_ = new_set\n",
    "        if len(vars_) >= limit:\n",
    "            break\n",
    "    return list(vars_)[:limit]\n",
    "\n",
    "def best_ratio(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ======================================================\n",
    "# ★追加：束ね分解 + D列ヒント（同じ列内）\n",
    "# ======================================================\n",
    "DELIMS = r\"[・／/、,＋+＆&\\s　]+\"\n",
    "\n",
    "def strip_annotations(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    t = str(s)\n",
    "    t = re.split(r\"[（(]\", t, maxsplit=1)[0]\n",
    "    t = re.split(r\"(会場|要検討|検討|確定)\", t, maxsplit=1)[0]\n",
    "    return t.strip()\n",
    "\n",
    "def split_city_tokens(raw: str):\n",
    "    t = strip_annotations(raw)\n",
    "    if not t:\n",
    "        return []\n",
    "    parts = [p.strip() for p in re.split(DELIMS, t) if p and p.strip()]\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p2 = apply_alias(p)\n",
    "        b = muni_base(p2)\n",
    "        if b:\n",
    "            out.append(b)\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for x in out:\n",
    "        if x not in seen:\n",
    "            uniq.append(x); seen.add(x)\n",
    "    return uniq\n",
    "\n",
    "def find_city_tokens_in_text(text: str, candidates_city_keys):\n",
    "    if not text:\n",
    "        return []\n",
    "    tn = norm(text)\n",
    "    if not tn:\n",
    "        return []\n",
    "    hits = []\n",
    "    for ck in candidates_city_keys:\n",
    "        nk = norm(ck)\n",
    "        if nk and nk in tn:\n",
    "            hits.append(ck)\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        if h not in seen:\n",
    "            out.append(h); seen.add(h)\n",
    "    return out\n",
    "\n",
    "# ======================================================\n",
    "# 2) 東/西/九州 の都道府県範囲（ユーザー指定）\n",
    "# ======================================================\n",
    "EAST_PREF_NUMS  = set(list(range(1, 17)) + [19,20,21,22,23,24])      # 01-16, 19-24（17,18は西へ）\n",
    "WEST_PREF_NUMS  = set([17,18] + list(range(25, 34)) + [31,32] +      # 17-18, 25-33（31,32含む）\n",
    "                      [36,37,38,39])                                 # ★四国 36-39 を西に追加\n",
    "KYUSHU_PREF_NUMS= set([34,35] + list(range(40, 47)))                 # ★広島34, 山口35, 40-46（沖縄47除外）\n",
    "\n",
    "def pref_num(pref_code_str: str):\n",
    "    if not pref_code_str:\n",
    "        return None\n",
    "    s = str(pref_code_str).strip()\n",
    "    m = re.match(r\"^(\\d{2})\", s)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def area_allowed(area_label: str, pref_code_str: str) -> bool:\n",
    "    al = (str(area_label).strip() if area_label else \"\")\n",
    "    pn = pref_num(pref_code_str)\n",
    "    if pn is None:\n",
    "        return True\n",
    "    if al == \"東\":\n",
    "        return pn in EAST_PREF_NUMS\n",
    "    if al == \"西\":\n",
    "        return pn in WEST_PREF_NUMS\n",
    "    if al == \"九州\":\n",
    "        return pn in KYUSHU_PREF_NUMS\n",
    "    return True\n",
    "\n",
    "# ======================================================\n",
    "# 3) 補助関数（週順、スパン、豪雪）\n",
    "# ======================================================\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, city_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if city_key and city_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in {1}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "\n",
    "        area_label = \"\" if pd.isna(header[COL_AREA_OR_KIND]) else str(header[COL_AREA_OR_KIND]).strip()\n",
    "        kind = kind_norm(detail[COL_AREA_OR_KIND])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"area_label\": area_label,\n",
    "            \"kind\": kind, \"city_raw\": city, \"venue_raw\": venue, \"pref_code\": pref\n",
    "        })\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "# ======================================================\n",
    "# 4) 統計量（例外増枠用 + 正規化基準）\n",
    "# ======================================================\n",
    "stats = pd.read_excel(STATS_XLSX, sheet_name=0)\n",
    "stats.columns = [str(c).strip() for c in stats.columns]\n",
    "muni_col = \"市区町村\" if \"市区町村\" in stats.columns else stats.columns[0]\n",
    "\n",
    "stats_base_list = stats[muni_col].astype(str).map(muni_base).map(str.strip)\n",
    "stats_base_list = stats_base_list[stats_base_list != \"\"].dropna().unique().tolist()\n",
    "\n",
    "stats_norm_to_base = {norm(x): x for x in stats_base_list if x}\n",
    "stats_norms = list(stats_norm_to_base.keys())\n",
    "\n",
    "def canonize_city_key(city_key_raw: str):\n",
    "    if not city_key_raw:\n",
    "        return \"\", 0.0\n",
    "    x = apply_alias(city_key_raw)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in stats_norm_to_base and bn:\n",
    "        return stats_norm_to_base[bn], 1.0\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in stats_norm_to_base and vn:\n",
    "            return stats_norm_to_base[vn], 0.995\n",
    "\n",
    "    best_base, best_r = None, 0.0\n",
    "    for v in [b] + gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        for sn in stats_norms:\n",
    "            r = best_ratio(vn, sn)\n",
    "            if r > best_r:\n",
    "                best_r = r\n",
    "                best_base = stats_norm_to_base[sn]\n",
    "    if best_base and best_r >= CONFIG[\"CANON_CUTOFF\"]:\n",
    "        return best_base, best_r\n",
    "\n",
    "    return b, best_r\n",
    "\n",
    "# ======================================================\n",
    "# 5) 四半期表読み込み\n",
    "# ======================================================\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ======================================================\n",
    "# 6) 地域別回数読み込み → 市区分キー正規化して集約\n",
    "# ======================================================\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None, dtype=str)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()].copy()\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key_raw\"] = plan_rows[1].astype(str).str.strip()\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "canon_list = []\n",
    "fix_logs = []\n",
    "for x in plan_rows[\"city_key_raw\"].tolist():\n",
    "    canon, sc = canonize_city_key(x)\n",
    "    canon_list.append(canon)\n",
    "    if canon != muni_base(apply_alias(x)) and sc >= 0.93:\n",
    "        fix_logs.append((x, canon, sc))\n",
    "plan_rows[\"city_key\"] = canon_list\n",
    "\n",
    "region_master = plan_rows.groupby([\"pref_parent\",\"city_key\"], as_index=False)[\"plan_count\"].sum()\n",
    "\n",
    "if fix_logs:\n",
    "    print(\"✅ 市区分キーの自動補正（alias/誤字ゆれ/統計量基準）:\")\n",
    "    for a,b,sc in fix_logs[:40]:\n",
    "        print(f\"  - {a} → {b} (match={sc:.3f})\")\n",
    "    if len(fix_logs) > 40:\n",
    "        print(f\"  ...他 {len(fix_logs)-40} 件\")\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# ======================================================\n",
    "# 7) 候補側の索引（表記norm + 読み）\n",
    "# ======================================================\n",
    "city_norm_map = {ck: norm(ck) for ck in city_keys}\n",
    "norm_to_city = {}\n",
    "for ck, nk in city_norm_map.items():\n",
    "    if nk:\n",
    "        norm_to_city.setdefault(nk, []).append(ck)\n",
    "\n",
    "reading_to_city = {}\n",
    "for ck in city_keys:\n",
    "    rd = to_katakana_reading(ck)\n",
    "    if rd:\n",
    "        reading_to_city.setdefault(rd, []).append(ck)\n",
    "\n",
    "def choose_best_by_fuzzy(query_base, cands):\n",
    "    qn = norm(query_base)\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in cands:\n",
    "        r = best_ratio(qn, norm(ck))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    return best_ck, best_r\n",
    "\n",
    "def match_city_key(city_name: str):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    x = apply_alias(city_name)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in norm_to_city and bn:\n",
    "        cands = norm_to_city[bn]\n",
    "        if len(cands) == 1:\n",
    "            return cands[0], 1.0\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        return ck, max(0.97, rr)\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in norm_to_city and vn:\n",
    "            cands = norm_to_city[vn]\n",
    "            if len(cands) == 1:\n",
    "                return cands[0], 0.995\n",
    "            ck, rr = choose_best_by_fuzzy(v, cands)\n",
    "            return ck, max(0.95, rr)\n",
    "\n",
    "    rd = to_katakana_reading(b)\n",
    "    cands = reading_to_city.get(rd, [])\n",
    "    if len(cands) == 1:\n",
    "        return cands[0], 0.99\n",
    "    elif len(cands) >= 2:\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        if ck:\n",
    "            return ck, max(0.93, rr)\n",
    "\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in city_keys:\n",
    "        r = best_ratio(bn, city_norm_map.get(ck, \"\"))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    if best_ck and best_r >= CONFIG[\"FUZZY_CUTOFF\"]:\n",
    "        return best_ck, best_r\n",
    "    return None, best_r\n",
    "\n",
    "def match_city_keys_multi(city_raw: str, venue_raw: str = \"\"):\n",
    "    keys = []\n",
    "    tokens = split_city_tokens(city_raw)\n",
    "    for tok in tokens:\n",
    "        ck, sc = match_city_key(tok)\n",
    "        if ck:\n",
    "            keys.append(ck)\n",
    "    if (not tokens or len(keys) == 0) and venue_raw:\n",
    "        hits = find_city_tokens_in_text(venue_raw, city_keys)\n",
    "        keys.extend(hits)\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for k in keys:\n",
    "        if k and k not in seen:\n",
    "            uniq.append(k); seen.add(k)\n",
    "    return uniq\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys1, scores = [], []\n",
    "    key_lists = []\n",
    "    for city_raw, venue_raw in zip(df[\"city_raw\"].tolist(), df[\"venue_raw\"].tolist()):\n",
    "        klist = match_city_keys_multi(city_raw, venue_raw)\n",
    "        key_lists.append(klist)\n",
    "        k0 = klist[0] if klist else None\n",
    "        keys1.append(k0)\n",
    "        if k0:\n",
    "            toks = split_city_tokens(city_raw)\n",
    "            probe = toks[0] if toks else city_raw\n",
    "            _, sc = match_city_key(probe)\n",
    "            scores.append(sc)\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys1\n",
    "    out[\"city_keys\"] = key_lists\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "scheduled42 = add_city_key(b42[(b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")].copy())\n",
    "scheduled43 = add_city_key(b43[(b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")].copy())\n",
    "\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ======================================================\n",
    "# 8) 都道府県コード推定（候補city_key→pref_code）\n",
    "# ======================================================\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "city_gap = {ck: gap_weeks_from_count(int(cnt)) for ck, cnt in plan_count_by_city.items()}\n",
    "\n",
    "# ======================================================\n",
    "# 9) スパン履歴（42→43連結）★束ね反映\n",
    "# ======================================================\n",
    "week_order_42 = week_order_42 if week_order_42 else []\n",
    "week_order_43 = week_order_43 if week_order_43 else []\n",
    "OFFSET_43 = len(week_order_42)\n",
    "\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_city = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "\n",
    "    klist = e.get(\"city_keys\", [])\n",
    "    if isinstance(klist, list) and klist:\n",
    "        for ck in klist:\n",
    "            if ck:\n",
    "                last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "    else:\n",
    "        ck = e.get(\"city_key\", None)\n",
    "        if ck:\n",
    "            last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "\n",
    "# ★A仕様：束ね1回＝構成市すべて1消化\n",
    "scheduled_counts_43 = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    klist = e.get(\"city_keys\", [])\n",
    "    if isinstance(klist, list) and klist:\n",
    "        for ck in klist:\n",
    "            if ck:\n",
    "                scheduled_counts_43[ck] = scheduled_counts_43.get(ck, 0) + 1\n",
    "    else:\n",
    "        ck = e.get(\"city_key\", None)\n",
    "        if ck:\n",
    "            scheduled_counts_43[ck] = scheduled_counts_43.get(ck, 0) + 1\n",
    "\n",
    "# ======================================================\n",
    "# 10) 例外増枠プール（J列=1 & 人口>=18万）\n",
    "# ======================================================\n",
    "stats2 = stats.copy()\n",
    "stats2[muni_col] = stats2[muni_col].astype(str).str.strip()\n",
    "\n",
    "class_col = stats2.columns[9] if len(stats2.columns) >= 10 else stats2.columns[-1]\n",
    "stats2[class_col] = pd.to_numeric(stats2[class_col], errors=\"coerce\")\n",
    "\n",
    "pop_col = next((c for c in stats2.columns if \"人口\" in str(c)), None)\n",
    "if pop_col is None:\n",
    "    num_cols = []\n",
    "    for c in stats2.columns:\n",
    "        s = pd.to_numeric(stats2[c], errors=\"coerce\")\n",
    "        if s.notna().sum() > 0:\n",
    "            num_cols.append((c, float(s.max(skipna=True))))\n",
    "    pop_col = sorted(num_cols, key=lambda x: x[1], reverse=True)[0][0] if num_cols else stats2.columns[-1]\n",
    "stats2[pop_col] = pd.to_numeric(stats2[pop_col], errors=\"coerce\")\n",
    "\n",
    "ovr = stats2[(stats2[class_col] == CONFIG[\"OVR_CLASS_J_VALUE\"]) & (stats2[pop_col] >= CONFIG[\"OVR_MIN_POP\"])].copy()\n",
    "\n",
    "ovr_candidates = {}\n",
    "for name in ovr[muni_col].tolist():\n",
    "    ck, sc = match_city_key(name)\n",
    "    if ck:\n",
    "        pop_val = float(ovr.loc[ovr[muni_col] == name, pop_col].iloc[0])\n",
    "        if ck not in ovr_candidates or sc > ovr_candidates[ck][\"match_score\"]:\n",
    "            ovr_candidates[ck] = {\"name_raw\": name, \"match_score\": sc, \"pop\": pop_val}\n",
    "OVR_POOL = set(ovr_candidates.keys())\n",
    "print(f\"✅ 例外増枠プール: {len(OVR_POOL)}（J列={class_col}==1 & 人口列={pop_col}>=18万）\")\n",
    "\n",
    "# ======================================================\n",
    "# 11) 集客率（あれば市区分に寄せる。無ければ0.5固定）\n",
    "# ======================================================\n",
    "rate_col = next((c for c in stats2.columns if (\"集客率\" in str(c) or \"来場率\" in str(c) or \"動員率\" in str(c))), None)\n",
    "city_rate = {}\n",
    "if rate_col is not None:\n",
    "    tmp = stats2[[muni_col, rate_col]].copy()\n",
    "    tmp[\"rate\"] = pd.to_numeric(tmp[rate_col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"rate\"])\n",
    "    muni_rate_norm = {norm(muni_base(row[muni_col])): float(row[\"rate\"]) for _, row in tmp.iterrows()}\n",
    "    for ck in city_keys:\n",
    "        cn = norm(ck)\n",
    "        if cn in muni_rate_norm:\n",
    "            city_rate[ck] = muni_rate_norm[cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"不明\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"不明\"\n",
    "    return f\"下位{p*100:.0f}%\"\n",
    "\n",
    "def build_reason(variant, week_id, area_label, ck, pc,\n",
    "                 need_gap_p, gp, need_gap_c, gc,\n",
    "                 remaining_plan, overflow_used, overflow_meta,\n",
    "                 same_week_pref_hit, same_week_city_hit, relax_mode, score):\n",
    "    lines = []\n",
    "    lines.append(f\"【案{variant}】この枠（{week_id}／{area_label}）はAJ枠が空いていたので、次の順で選びました。\")\n",
    "    lines.append(f\"0) 地域フィルタ：この枠は「{area_label}」なので、対象都道府県の範囲内だけから選定しています。\")\n",
    "    if not overflow_used:\n",
    "        lines.append(f\"1) まずは『43期の計画回数の残りがある市区分』から選定。→ {ck} は残り {remaining_plan} 回あるため計画内で入れています。\")\n",
    "    else:\n",
    "        pop = overflow_meta.get(\"pop\", None)\n",
    "        pop_txt = f\"{int(pop):,}人\" if isinstance(pop, (int,float)) and not math.isnan(pop) else \"不明\"\n",
    "        nm = overflow_meta.get(\"name_raw\",\"\") or ck\n",
    "        lines.append(\"1) 計画回数の残りがある候補だけでは埋め切れなかったため、例外ルールで増枠しています。\")\n",
    "        lines.append(f\"   例外条件：統計量のJ列=1 & 人口18万人以上。→ {nm}（人口={pop_txt}）を採用。\")\n",
    "\n",
    "    lines.append(f\"2) スパン：県は必要{need_gap_p}週に対し実績{gp}週、市区分は必要{need_gap_c}週に対し実績{gc}週。\"\n",
    "                 + (f\"（制約緩和={relax_mode}）\" if relax_mode else \"\"))\n",
    "\n",
    "    if ck in city_rate:\n",
    "        lines.append(f\"3) 集客率：{fmt_rate(city_rate.get(ck))}（{fmt_pct(city_pct.get(ck))}）。改善余地が大きいほど優先度を上げています。\")\n",
    "    else:\n",
    "        lines.append(\"3) 集客率：データが取れない市区分のため、回数とスパンを優先しています。\")\n",
    "\n",
    "    lines.append(\"4) 同週はカニバりやすいので基本回避。\"\n",
    "                 + (\"（同週同県ペナ）\" if same_week_pref_hit else \"（同週同県は回避）\")\n",
    "                 + (\"（同週同市区分ペナ）\" if same_week_city_hit else \"\"))\n",
    "\n",
    "    lines.append(\"5) 豪雪の12〜2月・3月1wは原則除外（例外リストで解除可）。祭り/マラソンは未連携で後日追加可能。\")\n",
    "    lines.append(f\"【まとめ】回数×スパン×改善余地×同週回避を総合した点が最も高いので採用。（score={score:.2f}）\")\n",
    "    return \" / \".join(lines)[:32000]\n",
    "\n",
    "# 週×都道府県（43期）\n",
    "week_used_pref_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]; pc = e[\"pref_code\"]\n",
    "    if w and pc:\n",
    "        week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "\n",
    "# ★追加：週×市区分（束ね構成市含む）\n",
    "week_used_city_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]\n",
    "    klist = e.get(\"city_keys\", [])\n",
    "    if not w or not isinstance(klist, list):\n",
    "        continue\n",
    "    s = week_used_city_base.setdefault(w, set())\n",
    "    for ck in klist:\n",
    "        if ck:\n",
    "            s.add(ck)\n",
    "\n",
    "# ======================================================\n",
    "# 12) プラン生成（A/B/C）\n",
    "# ======================================================\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used_in_plan = {ck: 0 for ck in city_keys}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_c = dict(last_pos_city)\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "    week_used_city = {w:set(s) for w,s in week_used_city_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow):\n",
    "        pc = pref_by_city.get(ck, \"\")\n",
    "\n",
    "        if not area_allowed(area_label, pc):\n",
    "            return None\n",
    "\n",
    "        plan_cnt = plan_count_by_city.get(ck, 0)\n",
    "        already  = scheduled_counts_43.get(ck, 0)\n",
    "        remaining = plan_cnt - already - used_in_plan.get(ck, 0)\n",
    "\n",
    "        overflow_used = False\n",
    "        overflow_meta = {}\n",
    "\n",
    "        if remaining <= 0:\n",
    "            if not allow_overflow:\n",
    "                return None\n",
    "            if ck not in OVR_POOL:\n",
    "                return None\n",
    "            overflow_used = True\n",
    "            meta = ovr_candidates.get(ck, {})\n",
    "            overflow_meta = {\"name_raw\": meta.get(\"name_raw\",\"\"), \"pop\": meta.get(\"pop\", float(\"nan\"))}\n",
    "\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_c = city_gap.get(ck, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_c = lp_c.get(ck, None)\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gc = 999 if last_c is None else (apos - last_c)\n",
    "\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_c = (last_c is None) or (gc >= need_gap_c)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_c):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪（市区分キー単位で判定）\n",
    "        if pc and is_snow_blackout(pc, ck, week_id):\n",
    "            return None\n",
    "\n",
    "        same_week_pref_hit = (pc and pc in week_used_pref.get(week_id, set()))\n",
    "        same_week_city_hit = (ck and ck in week_used_city.get(week_id, set()))\n",
    "\n",
    "        same_week_pen = (CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0) + \\\n",
    "                        (CONFIG[\"SAME_WEEK_CITY_PENALTY\"] if same_week_city_hit else 0.0)\n",
    "        overflow_pen = CONFIG[\"OVR_OVERFLOW_PENALTY\"] if overflow_used else 0.0\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_c = gc - need_gap_c\n",
    "        need_city = city_need.get(ck, 0.5)\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_c * W[\"city_slack\"] +\n",
    "            max(remaining, 0) * W[\"unmet_bonus\"] * 5.0 +\n",
    "            (need_city * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen - same_week_pen - overflow_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        reason = build_reason(\n",
    "            variant, week_id, area_label, ck, pc,\n",
    "            need_gap_p, gp, need_gap_c, gc,\n",
    "            (plan_cnt - already - used_in_plan.get(ck,0)),\n",
    "            overflow_used, overflow_meta,\n",
    "            same_week_pref_hit, same_week_city_hit, relax_mode, score\n",
    "        )\n",
    "\n",
    "        return {\"ck\": ck, \"pc\": pc, \"score\": float(score), \"reason\": reason}\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "        area_label = slot.get(\"area_label\", \"\")\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # 計画内で探す\n",
    "        for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "            for ck in city_keys:\n",
    "                cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=False)\n",
    "                if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                    best = cand\n",
    "            if best is not None:\n",
    "                break\n",
    "\n",
    "        # 例外増枠\n",
    "        if best is None:\n",
    "            for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "                for ck in city_keys:\n",
    "                    cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=True)\n",
    "                    if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                        best = cand\n",
    "                if best is not None:\n",
    "                    break\n",
    "\n",
    "        if best is None:\n",
    "            assigns.append({\n",
    "                \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "                \"assign_city_key\": \"\", \"pref_code_guess\": \"\", \"score\": float(\"-inf\"),\n",
    "                \"reason_BT\": f\"案{variant}: 条件により候補なし（地域={area_label}）\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; pc = best[\"pc\"]\n",
    "\n",
    "        # ★プラン内使用回数＆履歴更新\n",
    "        used_in_plan[ck] += 1\n",
    "        lp_c[ck] = apos\n",
    "        week_used_city.setdefault(week_id, set()).add(ck)\n",
    "\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck, \"pref_code_guess\": pc, \"score\": best[\"score\"],\n",
    "            \"reason_BT\": best[\"reason\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "def to_map(df, col):\n",
    "    return {int(r[\"row_header\"]): r[col] for _, r in df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ======================================================\n",
    "# 13) 書き戻し（43期の空欄AJ枠に A + (B/C併記) + BT理由）\n",
    "# ======================================================\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in {sheet42, sheet43}:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1\n",
    "\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "    if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "        continue\n",
    "\n",
    "    a = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    ws43.cell(r, COL_CITY+1).value = a\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b if b else '-'} / C:{c if c else '-'}）\"\n",
    "\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    if (ws43.cell(r, COL_PREF+1).value is None) or (str(ws43.cell(r, COL_PREF+1).value).strip()==\"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    ws43.cell(r, COL_REASON_BT+1).value = str(A_reason.get(int(row0), \"案A: 理由生成なし\"))\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "print(\"\\n✅ 入力:\", QUARTER_XLSX)\n",
    "print(\"✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"✅ 43期 空欄AJ枠 書込数:\", written)\n",
    "print(\"✅ 地域フィルタ定義:\")\n",
    "print(\"  東:\", sorted(EAST_PREF_NUMS))\n",
    "print(\"  西:\", sorted(WEST_PREF_NUMS))\n",
    "print(\"  九州:\", sorted(KYUSHU_PREF_NUMS))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GHFdHMb3a1oh",
    "outputId": "e6a8c5da-b13a-4378-9944-ccb9c35d0073"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 例外増枠プール: 1（J列=Zの4分位（1=赤,2=黄,3=青,4=灰）==1 & 人口列=人口>=18万）\n",
      "\n",
      "✅ 入力: SA+AJ+共有用_四半期表20240303.xlsx\n",
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\n",
      "✅ 43期 空欄AJ枠 書込数: 137\n",
      "✅ 地域フィルタ定義:\n",
      "  東: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24]\n",
      "  西: [17, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39]\n",
      "  九州: [34, 35, 40, 41, 42, 43, 44, 45, 46]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）\n",
    "# ★追加：東/西/九州の都道府県範囲フィルタ\n",
    "# ★追加：①alias ②読みキー ③誤字ゆれ生成 による表記ゆれ吸収\n",
    "# （会場マスタは使わない）\n",
    "# ============================================\n",
    "\n",
    "!pip -q install fugashi unidic-lite jaconv\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import jaconv\n",
    "from fugashi import Tagger\n",
    "\n",
    "tagger = Tagger()\n",
    "\n",
    "# ====== 入力 ======\n",
    "QUARTER_XLSX     = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "STATS_XLSX       = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "# ====== 出力（42/43のみ残して出す）======\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\"\n",
    "\n",
    "# ====== 列（0-based）=====\n",
    "COL_WEEK = 0\n",
    "COL_AREA_OR_KIND = 1     # ★ヘッダ行=東/西/九州、次行=AJ/合同/SA\n",
    "COL_CITY = 2             # 都道府県/市区分（例：静岡、難波、博多…）\n",
    "COL_VENUE = 3\n",
    "COL_PREF = 5\n",
    "COL_REASON_BT = 72       # BT\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,  # 同週同県ペナ\n",
    "\n",
    "    # 表記ゆれ\n",
    "    \"FUZZY_CUTOFF\": 0.86,\n",
    "    \"CANON_CUTOFF\": 0.93,\n",
    "\n",
    "    # 豪雪\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    # 例外増枠\n",
    "    \"OVR_CLASS_J_VALUE\": 1,\n",
    "    \"OVR_MIN_POP\": 180000,\n",
    "    \"OVR_OVERFLOW_PENALTY\": 15.0,\n",
    "\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 2.0, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0,\n",
    "              \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 0) alias辞書（CSV）…追記して育てる運用\n",
    "# ======================================================\n",
    "ALIAS_CSV = \"市区分_alias.csv\"\n",
    "\n",
    "def ensure_alias_template(path=ALIAS_CSV):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    df = pd.DataFrame([\n",
    "        {\"alias\":\"なんば\",\"canonical\":\"難波\"},\n",
    "        {\"alias\":\"薩摩河内\",\"canonical\":\"薩摩川内\"},\n",
    "    ])\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ aliasテンプレ作成: {path}（必要に応じて追記してください）\")\n",
    "\n",
    "def load_alias_map(path=ALIAS_CSV):\n",
    "    ensure_alias_template(path)\n",
    "    try:\n",
    "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "        df[\"alias\"] = df[\"alias\"].astype(str).str.strip()\n",
    "        df[\"canonical\"] = df[\"canonical\"].astype(str).str.strip()\n",
    "        return {a:c for a,c in zip(df[\"alias\"], df[\"canonical\"]) if a and c}\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ alias読み込み失敗。aliasなしで続行:\", e)\n",
    "        return {}\n",
    "\n",
    "ALIAS_MAP = load_alias_map(ALIAS_CSV)\n",
    "\n",
    "def apply_alias(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    t = str(s).strip()\n",
    "    if not t:\n",
    "        return \"\"\n",
    "    return ALIAS_MAP.get(t, t)\n",
    "\n",
    "# ======================================================\n",
    "# 1) 正規化・読みキー・誤字ゆれ生成\n",
    "# ======================================================\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def muni_base(name: str) -> str:\n",
    "    if name is None:\n",
    "        return \"\"\n",
    "    s = str(name).strip()\n",
    "    s = re.sub(r\"(都|道|府|県)$\", \"\", s)\n",
    "    s = re.sub(r\"(市|区|町|村)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def to_katakana_reading(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = re.sub(r\"[ \\t\\r\\n\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "\n",
    "    if re.search(r\"[ぁ-んァ-ン]\", s2):\n",
    "        s2 = jaconv.normalize(jaconv.hira2kata(s2))\n",
    "        s2 = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", s2)\n",
    "        return s2\n",
    "\n",
    "    yomi_parts = []\n",
    "    for w in tagger(s2):\n",
    "        feat = w.feature\n",
    "        reading = None\n",
    "        for k in [\"reading\", \"kana\", \"pron\"]:\n",
    "            if hasattr(feat, k):\n",
    "                reading = getattr(feat, k)\n",
    "                break\n",
    "        if not reading or reading == \"*\":\n",
    "            reading = w.surface\n",
    "        yomi_parts.append(reading)\n",
    "\n",
    "    yomi = \"\".join(yomi_parts)\n",
    "    yomi = jaconv.normalize(jaconv.hira2kata(yomi))\n",
    "    yomi = re.sub(r\"[^ァ-ン0-9A-Z]\", \"\", yomi)\n",
    "    return yomi\n",
    "\n",
    "CONFUSION = {\n",
    "    \"川\": [\"河\"],\n",
    "    \"河\": [\"川\"],\n",
    "    \"崎\": [\"﨑\"],\n",
    "    \"﨑\": [\"崎\"],\n",
    "    \"ヶ\": [\"ケ\"],\n",
    "    \"ケ\": [\"ヶ\"],\n",
    "    \"斉\": [\"齋\", \"斎\"],\n",
    "    \"齋\": [\"斉\", \"斎\"],\n",
    "    \"斎\": [\"斉\", \"齋\"],\n",
    "    \"邊\": [\"辺\", \"邉\"],\n",
    "    \"邉\": [\"辺\", \"邊\"],\n",
    "    \"辺\": [\"邊\", \"邉\"],\n",
    "}\n",
    "\n",
    "def gen_variants(s: str, limit=12):\n",
    "    if s is None:\n",
    "        return [\"\"]\n",
    "    s = str(s)\n",
    "    vars_ = {s}\n",
    "    for a, bs in CONFUSION.items():\n",
    "        if a in s:\n",
    "            new_set = set(vars_)\n",
    "            for v in vars_:\n",
    "                for b in bs:\n",
    "                    new_set.add(v.replace(a, b))\n",
    "            vars_ = new_set\n",
    "        if len(vars_) >= limit:\n",
    "            break\n",
    "    return list(vars_)[:limit]\n",
    "\n",
    "def best_ratio(a, b):\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# ======================================================\n",
    "# 2) 東/西/九州 の都道府県範囲（ユーザー指定）\n",
    "#   - 東：北海道～富山/愛知/岐阜/三重あたりまで\n",
    "#   - 西：石川/福井/滋賀あたり～岡山/鳥取/島根まで ＋ 四国（36-39）\n",
    "#   - 九州：山口県＋広島県＋九州（沖縄=47は除外）\n",
    "# ======================================================\n",
    "# 2桁都道府県コード（01〜47）\n",
    "EAST_PREF_NUMS  = set(list(range(1, 17)) + [19,20,21,22,23,24])      # 01-16, 19-24（17,18は西へ）\n",
    "WEST_PREF_NUMS  = set([17,18] + list(range(25, 34)) + [31,32] +      # 17-18, 25-33（31,32含む）\n",
    "                      [36,37,38,39])                                 # ★四国 36-39 を西に追加\n",
    "KYUSHU_PREF_NUMS= set([34,35] + list(range(40, 47)))                 # ★広島34, 山口35, 40-46（沖縄47除外）\n",
    "\n",
    "def pref_num(pref_code_str: str):\n",
    "    if not pref_code_str:\n",
    "        return None\n",
    "    s = str(pref_code_str).strip()\n",
    "    m = re.match(r\"^(\\d{2})\", s)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def area_allowed(area_label: str, pref_code_str: str) -> bool:\n",
    "    \"\"\"\n",
    "    ヘッダのエリア（東/西/九州）で都道府県範囲を制限\n",
    "    \"\"\"\n",
    "    al = (str(area_label).strip() if area_label else \"\")\n",
    "    pn = pref_num(pref_code_str)\n",
    "    if pn is None:\n",
    "        return True  # 不明な時は落とさない（後段でスパン等に任せる）\n",
    "    if al == \"東\":\n",
    "        return pn in EAST_PREF_NUMS\n",
    "    if al == \"西\":\n",
    "        return pn in WEST_PREF_NUMS\n",
    "    if al == \"九州\":\n",
    "        return pn in KYUSHU_PREF_NUMS\n",
    "    return True\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3) 補助関数（週順、スパン、豪雪）\n",
    "# ======================================================\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, city_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if city_key and city_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in {1}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "\n",
    "        area_label = \"\" if pd.isna(header[COL_AREA_OR_KIND]) else str(header[COL_AREA_OR_KIND]).strip()  # ★東/西/九州\n",
    "        kind = kind_norm(detail[COL_AREA_OR_KIND])  # ★AJ/合同/SA\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"area_label\": area_label,\n",
    "            \"kind\": kind, \"city_raw\": city, \"venue_raw\": venue, \"pref_code\": pref\n",
    "        })\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "# ======================================================\n",
    "# 4) 統計量（例外増枠用 + 正規化基準）\n",
    "# ======================================================\n",
    "stats = pd.read_excel(STATS_XLSX, sheet_name=0)\n",
    "stats.columns = [str(c).strip() for c in stats.columns]\n",
    "muni_col = \"市区町村\" if \"市区町村\" in stats.columns else stats.columns[0]\n",
    "\n",
    "stats_base_list = stats[muni_col].astype(str).map(muni_base).map(str.strip)\n",
    "stats_base_list = stats_base_list[stats_base_list != \"\"].dropna().unique().tolist()\n",
    "\n",
    "stats_norm_to_base = {norm(x): x for x in stats_base_list if x}\n",
    "stats_norms = list(stats_norm_to_base.keys())\n",
    "\n",
    "def canonize_city_key(city_key_raw: str):\n",
    "    \"\"\"\n",
    "    地域別回数表の市区分を統計量ベース名へ寄せる\n",
    "    優先：alias → base → 誤字ゆれ生成 → fuzzy\n",
    "    \"\"\"\n",
    "    if not city_key_raw:\n",
    "        return \"\", 0.0\n",
    "    x = apply_alias(city_key_raw)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in stats_norm_to_base and bn:\n",
    "        return stats_norm_to_base[bn], 1.0\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in stats_norm_to_base and vn:\n",
    "            return stats_norm_to_base[vn], 0.995\n",
    "\n",
    "    best_base, best_r = None, 0.0\n",
    "    for v in [b] + gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        for sn in stats_norms:\n",
    "            r = best_ratio(vn, sn)\n",
    "            if r > best_r:\n",
    "                best_r = r\n",
    "                best_base = stats_norm_to_base[sn]\n",
    "    if best_base and best_r >= CONFIG[\"CANON_CUTOFF\"]:\n",
    "        return best_base, best_r\n",
    "\n",
    "    return b, best_r\n",
    "\n",
    "# ======================================================\n",
    "# 5) 四半期表読み込み\n",
    "# ======================================================\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ======================================================\n",
    "# 6) 地域別回数読み込み → 市区分キー正規化して集約\n",
    "# ======================================================\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None, dtype=str)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()].copy()\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key_raw\"] = plan_rows[1].astype(str).str.strip()\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "canon_list = []\n",
    "fix_logs = []\n",
    "for x in plan_rows[\"city_key_raw\"].tolist():\n",
    "    canon, sc = canonize_city_key(x)\n",
    "    canon_list.append(canon)\n",
    "    if canon != muni_base(apply_alias(x)) and sc >= 0.93:\n",
    "        fix_logs.append((x, canon, sc))\n",
    "plan_rows[\"city_key\"] = canon_list\n",
    "\n",
    "region_master = plan_rows.groupby([\"pref_parent\",\"city_key\"], as_index=False)[\"plan_count\"].sum()\n",
    "\n",
    "if fix_logs:\n",
    "    print(\"✅ 市区分キーの自動補正（alias/誤字ゆれ/統計量基準）:\")\n",
    "    for a,b,sc in fix_logs[:40]:\n",
    "        print(f\"  - {a} → {b} (match={sc:.3f})\")\n",
    "    if len(fix_logs) > 40:\n",
    "        print(f\"  ...他 {len(fix_logs)-40} 件\")\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# ======================================================\n",
    "# 7) 候補側の索引（表記norm + 読み）\n",
    "# ======================================================\n",
    "city_norm_map = {ck: norm(ck) for ck in city_keys}\n",
    "norm_to_city = {}\n",
    "for ck, nk in city_norm_map.items():\n",
    "    if nk:\n",
    "        norm_to_city.setdefault(nk, []).append(ck)\n",
    "\n",
    "reading_to_city = {}\n",
    "for ck in city_keys:\n",
    "    rd = to_katakana_reading(ck)\n",
    "    if rd:\n",
    "        reading_to_city.setdefault(rd, []).append(ck)\n",
    "\n",
    "def choose_best_by_fuzzy(query_base, cands):\n",
    "    qn = norm(query_base)\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in cands:\n",
    "        r = best_ratio(qn, norm(ck))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    return best_ck, best_r\n",
    "\n",
    "def match_city_key(city_name: str):\n",
    "    \"\"\"\n",
    "    四半期表側の市区分（入力）を候補キーにマッチ\n",
    "    優先：alias → 表記一致 → 誤字ゆれ一致 → 読み一致 → fuzzy\n",
    "    \"\"\"\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    x = apply_alias(city_name)\n",
    "    b = muni_base(x)\n",
    "    bn = norm(b)\n",
    "\n",
    "    if bn in norm_to_city and bn:\n",
    "        cands = norm_to_city[bn]\n",
    "        if len(cands) == 1:\n",
    "            return cands[0], 1.0\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        return ck, max(0.97, rr)\n",
    "\n",
    "    for v in gen_variants(b):\n",
    "        vn = norm(v)\n",
    "        if vn in norm_to_city and vn:\n",
    "            cands = norm_to_city[vn]\n",
    "            if len(cands) == 1:\n",
    "                return cands[0], 0.995\n",
    "            ck, rr = choose_best_by_fuzzy(v, cands)\n",
    "            return ck, max(0.95, rr)\n",
    "\n",
    "    rd = to_katakana_reading(b)\n",
    "    cands = reading_to_city.get(rd, [])\n",
    "    if len(cands) == 1:\n",
    "        return cands[0], 0.99\n",
    "    elif len(cands) >= 2:\n",
    "        ck, rr = choose_best_by_fuzzy(b, cands)\n",
    "        if ck:\n",
    "            return ck, max(0.93, rr)\n",
    "\n",
    "    best_ck, best_r = None, 0.0\n",
    "    for ck in city_keys:\n",
    "        r = best_ratio(bn, city_norm_map.get(ck, \"\"))\n",
    "        if r > best_r:\n",
    "            best_r = r\n",
    "            best_ck = ck\n",
    "    if best_ck and best_r >= CONFIG[\"FUZZY_CUTOFF\"]:\n",
    "        return best_ck, best_r\n",
    "    return None, best_r\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys, scores = [], []\n",
    "    for x in df[\"city_raw\"].tolist():\n",
    "        k, s = match_city_key(x)\n",
    "        keys.append(k); scores.append(s)\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "scheduled42 = add_city_key(b42[(b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")].copy())\n",
    "scheduled43 = add_city_key(b43[(b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")].copy())\n",
    "\n",
    "# 43期の空きAJ枠（ヘッダが空欄）\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ======================================================\n",
    "# 8) 都道府県コード推定（候補city_key→pref_code）\n",
    "# ======================================================\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "city_gap = {ck: gap_weeks_from_count(int(cnt)) for ck, cnt in plan_count_by_city.items()}\n",
    "\n",
    "# ======================================================\n",
    "# 9) スパン履歴（42→43連結）\n",
    "# ======================================================\n",
    "week_order_42 = week_order_42 if week_order_42 else []\n",
    "week_order_43 = week_order_43 if week_order_43 else []\n",
    "OFFSET_43 = len(week_order_42)\n",
    "\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_city = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    ck = e[\"city_key\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "    if ck:\n",
    "        last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "\n",
    "scheduled_counts_43 = scheduled43.dropna(subset=[\"city_key\"]).groupby(\"city_key\").size().to_dict()\n",
    "\n",
    "# ======================================================\n",
    "# 10) 例外増枠プール（J列=1 & 人口>=18万）\n",
    "# ======================================================\n",
    "stats2 = stats.copy()\n",
    "stats2[muni_col] = stats2[muni_col].astype(str).str.strip()\n",
    "\n",
    "# J列=10列目\n",
    "class_col = stats2.columns[9] if len(stats2.columns) >= 10 else stats2.columns[-1]\n",
    "stats2[class_col] = pd.to_numeric(stats2[class_col], errors=\"coerce\")\n",
    "\n",
    "pop_col = next((c for c in stats2.columns if \"人口\" in str(c)), None)\n",
    "if pop_col is None:\n",
    "    # 数値列の最大を人口っぽい列として採用\n",
    "    num_cols = []\n",
    "    for c in stats2.columns:\n",
    "        s = pd.to_numeric(stats2[c], errors=\"coerce\")\n",
    "        if s.notna().sum() > 0:\n",
    "            num_cols.append((c, float(s.max(skipna=True))))\n",
    "    pop_col = sorted(num_cols, key=lambda x: x[1], reverse=True)[0][0] if num_cols else stats2.columns[-1]\n",
    "stats2[pop_col] = pd.to_numeric(stats2[pop_col], errors=\"coerce\")\n",
    "\n",
    "ovr = stats2[(stats2[class_col] == CONFIG[\"OVR_CLASS_J_VALUE\"]) & (stats2[pop_col] >= CONFIG[\"OVR_MIN_POP\"])].copy()\n",
    "\n",
    "ovr_candidates = {}\n",
    "for name in ovr[muni_col].tolist():\n",
    "    ck, sc = match_city_key(name)\n",
    "    if ck:\n",
    "        pop_val = float(ovr.loc[ovr[muni_col] == name, pop_col].iloc[0])\n",
    "        if ck not in ovr_candidates or sc > ovr_candidates[ck][\"match_score\"]:\n",
    "            ovr_candidates[ck] = {\"name_raw\": name, \"match_score\": sc, \"pop\": pop_val}\n",
    "OVR_POOL = set(ovr_candidates.keys())\n",
    "print(f\"✅ 例外増枠プール: {len(OVR_POOL)}（J列={class_col}==1 & 人口列={pop_col}>=18万）\")\n",
    "\n",
    "# ======================================================\n",
    "# 11) 集客率（あれば市区分に寄せる。無ければ0.5固定）\n",
    "# ======================================================\n",
    "rate_col = next((c for c in stats2.columns if (\"集客率\" in str(c) or \"来場率\" in str(c) or \"動員率\" in str(c))), None)\n",
    "city_rate = {}\n",
    "if rate_col is not None:\n",
    "    tmp = stats2[[muni_col, rate_col]].copy()\n",
    "    tmp[\"rate\"] = pd.to_numeric(tmp[rate_col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[\"rate\"])\n",
    "    muni_rate_norm = {norm(muni_base(row[muni_col])): float(row[\"rate\"]) for _, row in tmp.iterrows()}\n",
    "    for ck in city_keys:\n",
    "        cn = norm(ck)\n",
    "        if cn in muni_rate_norm:\n",
    "            city_rate[ck] = muni_rate_norm[cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"不明\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"不明\"\n",
    "    return f\"下位{p*100:.0f}%\"\n",
    "\n",
    "def build_reason(variant, week_id, area_label, ck, pc,\n",
    "                 need_gap_p, gp, need_gap_c, gc,\n",
    "                 remaining_plan, overflow_used, overflow_meta,\n",
    "                 same_week_pref_hit, relax_mode, score):\n",
    "    lines = []\n",
    "    lines.append(f\"【案{variant}】この枠（{week_id}／{area_label}）はAJ枠が空いていたので、次の順で選びました。\")\n",
    "    lines.append(f\"0) 地域フィルタ：この枠は「{area_label}」なので、対象都道府県の範囲内だけから選定しています。\")\n",
    "    if not overflow_used:\n",
    "        lines.append(f\"1) まずは『43期の計画回数の残りがある市区分』から選定。→ {ck} は残り {remaining_plan} 回あるため計画内で入れています。\")\n",
    "    else:\n",
    "        pop = overflow_meta.get(\"pop\", None)\n",
    "        pop_txt = f\"{int(pop):,}人\" if isinstance(pop, (int,float)) and not math.isnan(pop) else \"不明\"\n",
    "        nm = overflow_meta.get(\"name_raw\",\"\") or ck\n",
    "        lines.append(\"1) 計画回数の残りがある候補だけでは埋め切れなかったため、例外ルールで増枠しています。\")\n",
    "        lines.append(f\"   例外条件：統計量のJ列=1 & 人口18万人以上。→ {nm}（人口={pop_txt}）を採用。\")\n",
    "\n",
    "    lines.append(f\"2) スパン：県は必要{need_gap_p}週に対し実績{gp}週、市区分は必要{need_gap_c}週に対し実績{gc}週。\"\n",
    "                 + (f\"（制約緩和={relax_mode}）\" if relax_mode else \"\"))\n",
    "\n",
    "    if ck in city_rate:\n",
    "        lines.append(f\"3) 集客率：{fmt_rate(city_rate.get(ck))}（{fmt_pct(city_pct.get(ck))}）。改善余地が大きいほど優先度を上げています。\")\n",
    "    else:\n",
    "        lines.append(\"3) 集客率：データが取れない市区分のため、回数とスパンを優先しています。\")\n",
    "\n",
    "    lines.append(\"4) 同週同県はカニバりやすいので基本回避。\"\n",
    "                 + (\"（ただし候補都合で同県になりペナルティ付き）\" if same_week_pref_hit else \"（今回は回避できています）\"))\n",
    "\n",
    "    lines.append(\"5) 豪雪の12〜2月・3月1wは原則除外（例外リストで解除可）。祭り/マラソンは未連携で後日追加可能。\")\n",
    "    lines.append(f\"【まとめ】回数×スパン×改善余地×同週同県回避を総合した点が最も高いので採用。（score={score:.2f}）\")\n",
    "    return \" / \".join(lines)[:32000]\n",
    "\n",
    "# 週×都道府県（43期）\n",
    "week_used_pref_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]; pc = e[\"pref_code\"]\n",
    "    if w and pc:\n",
    "        week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "\n",
    "# ======================================================\n",
    "# 12) プラン生成（A/B/C）…★エリア範囲フィルタを強制\n",
    "# ======================================================\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used_in_plan = {ck: 0 for ck in city_keys}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_c = dict(last_pos_city)\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow):\n",
    "        pc = pref_by_city.get(ck, \"\")\n",
    "\n",
    "        # ★地域フィルタ（東/西/九州）\n",
    "        if not area_allowed(area_label, pc):\n",
    "            return None\n",
    "\n",
    "        plan_cnt = plan_count_by_city.get(ck, 0)\n",
    "        already  = scheduled_counts_43.get(ck, 0)\n",
    "        remaining = plan_cnt - already - used_in_plan.get(ck, 0)\n",
    "\n",
    "        overflow_used = False\n",
    "        overflow_meta = {}\n",
    "\n",
    "        if remaining <= 0:\n",
    "            if not allow_overflow:\n",
    "                return None\n",
    "            if ck not in OVR_POOL:\n",
    "                return None\n",
    "            overflow_used = True\n",
    "            meta = ovr_candidates.get(ck, {})\n",
    "            overflow_meta = {\"name_raw\": meta.get(\"name_raw\",\"\"), \"pop\": meta.get(\"pop\", float(\"nan\"))}\n",
    "\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_c = city_gap.get(ck, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_c = lp_c.get(ck, None)\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gc = 999 if last_c is None else (apos - last_c)\n",
    "\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_c = (last_c is None) or (gc >= need_gap_c)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_c):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪\n",
    "        if pc and is_snow_blackout(pc, ck, week_id):\n",
    "            return None\n",
    "\n",
    "        same_week_pref_hit = (pc and pc in week_used_pref.get(week_id, set()))\n",
    "        same_week_pen = CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0\n",
    "        overflow_pen = CONFIG[\"OVR_OVERFLOW_PENALTY\"] if overflow_used else 0.0\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_c = gc - need_gap_c\n",
    "        need_city = city_need.get(ck, 0.5)\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_c * W[\"city_slack\"] +\n",
    "            max(remaining, 0) * W[\"unmet_bonus\"] * 5.0 +\n",
    "            (need_city * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen - same_week_pen - overflow_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        reason = build_reason(\n",
    "            variant, week_id, area_label, ck, pc,\n",
    "            need_gap_p, gp, need_gap_c, gc,\n",
    "            (plan_cnt - already - used_in_plan.get(ck,0)),\n",
    "            overflow_used, overflow_meta,\n",
    "            same_week_pref_hit, relax_mode, score\n",
    "        )\n",
    "\n",
    "        return {\"ck\": ck, \"pc\": pc, \"score\": float(score), \"reason\": reason}\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "        area_label = slot.get(\"area_label\", \"\")\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # 計画内で探す\n",
    "        for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "            for ck in city_keys:\n",
    "                cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=False)\n",
    "                if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                    best = cand\n",
    "            if best is not None:\n",
    "                break\n",
    "\n",
    "        # 例外増枠\n",
    "        if best is None:\n",
    "            for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "                for ck in city_keys:\n",
    "                    cand = score_city(ck, apos, week_id, area_label, relax_mode, allow_overflow=True)\n",
    "                    if cand and (best is None or cand[\"score\"] > best[\"score\"]):\n",
    "                        best = cand\n",
    "                if best is not None:\n",
    "                    break\n",
    "\n",
    "        if best is None:\n",
    "            assigns.append({\n",
    "                \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "                \"assign_city_key\": \"\", \"pref_code_guess\": \"\", \"score\": float(\"-inf\"),\n",
    "                \"reason_BT\": f\"案{variant}: 条件により候補なし（地域={area_label}）\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; pc = best[\"pc\"]\n",
    "\n",
    "        used_in_plan[ck] += 1\n",
    "        lp_c[ck] = apos\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant, \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck, \"pref_code_guess\": pc, \"score\": best[\"score\"],\n",
    "            \"reason_BT\": best[\"reason\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "def to_map(df, col):\n",
    "    return {int(r[\"row_header\"]): r[col] for _, r in df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ======================================================\n",
    "# 13) 書き戻し（43期の空欄AJ枠に A + (B/C併記) + BT理由）\n",
    "# ======================================================\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "\n",
    "# 42/43以外は削除\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in {sheet42, sheet43}:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1\n",
    "\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "    if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "        continue\n",
    "\n",
    "    a = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    ws43.cell(r, COL_CITY+1).value = a\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b if b else '-'} / C:{c if c else '-'}）\"\n",
    "\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    if (ws43.cell(r, COL_PREF+1).value is None) or (str(ws43.cell(r, COL_PREF+1).value).strip()==\"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    ws43.cell(r, COL_REASON_BT+1).value = str(A_reason.get(int(row0), \"案A: 理由生成なし\"))\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "print(\"\\n✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"✅ 43期 空欄AJ枠 書込数:\", written)\n",
    "print(\"✅ 地域フィルタ定義:\")\n",
    "print(\"  東:\", sorted(EAST_PREF_NUMS))\n",
    "print(\"  西:\", sorted(WEST_PREF_NUMS))\n",
    "print(\"  九州:\", sorted(KYUSHU_PREF_NUMS))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzNXDZNr_KUM",
    "outputId": "9f0e24b9-14a5-44ad-a800-48de1ea3faea"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/694.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.9/694.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "✅ aliasテンプレ作成: 市区分_alias.csv（必要に応じて追記してください）\n",
      "✅ 例外増枠プール: 1（J列=Zの4分位（1=赤,2=黄,3=青,4=灰）==1 & 人口列=人口>=18万）\n",
      "\n",
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_東西九州範囲対応_市区分ゆれ吸収_42_43のみ_理由BT.xlsx\n",
      "✅ 43期 空欄AJ枠 書込数: 137\n",
      "✅ 地域フィルタ定義:\n",
      "  東: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24]\n",
      "  西: [17, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39]\n",
      "  九州: [34, 35, 40, 41, 42, 43, 44, 45, 46]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）【不足時のみ例外増枠OK + 理由を上司向け口語に】\n",
    "#\n",
    "# ✅基本：43期地域別会場回数（plan_count）を上限として使う\n",
    "# ✅ただし「その枠が候補ゼロで埋められない」時だけ、例外増枠を許可\n",
    "#   - 市区町村統計量（Excel）J列=1\n",
    "#   - 人口>=18万人\n",
    "#   - 豪雪/外部イベントは引き続き除外\n",
    "# ✅BT列の理由：上司プレゼン向けに、根拠を口語で分かりやすく\n",
    "# ✅同週同県はなるべく避ける（ペナルティ）\n",
    "# ✅F列(例:25滋賀)を書き込む（空欄なら）\n",
    "# ✅出力は 42期マスタ / 43期マスタ のみ（1ファイル）\n",
    "# ✅D列に B/C案を併記（欠損でも \"-\" として必ず出す）\n",
    "#\n",
    "# 入力:\n",
    "#   SA+AJ+共有用_四半期表20240303.xlsx\n",
    "#   43期地域別会場回数.xlsx\n",
    "#   市区町村_統計量_全国 (1).xlsx\n",
    "#   豪雪例外リスト.xlsx（無ければ自動生成）\n",
    "#\n",
    "# 出力:\n",
    "#   SA+AJ+共有用_四半期表20240303_43期提案ABC_不足時例外増枠_42_43のみ_理由BT.xlsx\n",
    "# ============================================\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# ====== 入力 ======\n",
    "QUARTER_XLSX     = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "STATS_XLSX       = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "# ====== 出力（1ファイル） ======\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_不足時例外増枠_42_43のみ_理由BT.xlsx\"\n",
    "\n",
    "# ====== 列（0-based）=====\n",
    "COL_WEEK = 0           # A 週ID\n",
    "COL_CITY = 2           # C 市区分（A案）\n",
    "COL_VENUE = 3          # D 会場（会場要検討 + B/C案併記）\n",
    "COL_PREF = 5           # F 都道府県コード（例 25滋賀）\n",
    "COL_KIND_DETAIL = 1    # 形態行のB列\n",
    "COL_REASON_BT = 72     # BT列（openpyxlでは 1-based=72）\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,   # 同週同県を避ける\n",
    "    \"FUZZY_CUTOFF\": 0.82,\n",
    "    \"MANUAL_CITY_MAP\": {},\n",
    "    \"EXTERNAL_EVENT_BLACKOUT\": [],\n",
    "\n",
    "    # 豪雪ブラックアウト（暫定）\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    # 例外増枠条件\n",
    "    \"OVR_CLASS_J_VALUE\": 1,          # 統計量シートの「J列=1」\n",
    "    \"OVR_MIN_POP\": 180000,           # 人口>=18万人\n",
    "    \"OVR_OVERFLOW_PENALTY\": 15.0,    # “例外増枠”を乱発しないための軽いペナ（不足時にしか使わないので控えめ）\n",
    "\n",
    "    # 3案の重み\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_pref\": 2.0, \"low_attr_city\": 1.5, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0,\n",
    "              \"low_attr_pref\": 0.8, \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2,\n",
    "              \"low_attr_pref\": 3.8, \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ====== Utility ======\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    ws[\"C2\"] = \"豪雪NGを例外的にOKにしたい対象を追加。空欄は無視。\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, city_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if city_key and city_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in CONFIG[\"SNOW_BLACKOUT_MARCH_W\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "        kind = kind_norm(detail[COL_KIND_DETAIL])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"kind\": kind,\n",
    "            \"city_raw\": city,\n",
    "            \"venue_raw\": venue,\n",
    "            \"pref_code\": pref\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "def best_fuzzy_key(a_norm, candidates_norm):\n",
    "    best_ratio, best_norm = 0.0, \"\"\n",
    "    for cand in candidates_norm:\n",
    "        if not cand:\n",
    "            continue\n",
    "        r = difflib.SequenceMatcher(None, a_norm, cand).ratio()\n",
    "        if r > best_ratio:\n",
    "            best_ratio, best_norm = r, cand\n",
    "    return best_norm, best_ratio\n",
    "\n",
    "# ====== 1) 四半期表読み込み ======\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ====== 2) 地域別回数（43期上限のベース） ======\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()]\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key\"] = plan_rows[1].astype(str)\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "region_master = plan_rows[[\"pref_parent\",\"city_key\",\"plan_count\"]].reset_index(drop=True)\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "city_norm_map = {k: norm(k) for k in city_keys}\n",
    "_norm_values = list(city_norm_map.values())\n",
    "_norm_to_key = {city_norm_map[k]: k for k in city_norm_map}\n",
    "\n",
    "def match_city_key(city_name):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    if city_name in CONFIG[\"MANUAL_CITY_MAP\"]:\n",
    "        return CONFIG[\"MANUAL_CITY_MAP\"][city_name], 1.0\n",
    "    a = norm(city_name)\n",
    "    if a in _norm_to_key and a:\n",
    "        return _norm_to_key[a], 1.0\n",
    "    for ck, ckn in city_norm_map.items():\n",
    "        if ckn and (ckn in a or a in ckn):\n",
    "            return ck, 0.95\n",
    "    bn, ratio = best_fuzzy_key(a, _norm_values)\n",
    "    if ratio >= CONFIG[\"FUZZY_CUTOFF\"] and bn:\n",
    "        return _norm_to_key[bn], ratio\n",
    "    return None, ratio\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys, scores = [], []\n",
    "    for x in df[\"city_raw\"].tolist():\n",
    "        k, s = match_city_key(x)\n",
    "        keys.append(k); scores.append(s)\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "scheduled42 = b42[(b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")].copy()\n",
    "scheduled43 = b43[(b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")].copy()\n",
    "scheduled42 = add_city_key(scheduled42)\n",
    "scheduled43 = add_city_key(scheduled43)\n",
    "\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ====== 3) 都道府県コード推定 ======\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "city_gap = {ck: gap_weeks_from_count(int(cnt)) for ck, cnt in plan_count_by_city.items()}\n",
    "\n",
    "# ====== 4) 42→43のスパン履歴用タイムライン ======\n",
    "OFFSET_43 = len(week_order_42)\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_city = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    ck = e[\"city_key\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "    if ck:\n",
    "        last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "\n",
    "# ====== 5) 43期内の既存回数 ======\n",
    "scheduled_counts_43 = scheduled43.dropna(subset=[\"city_key\"]).groupby(\"city_key\").size().to_dict()\n",
    "\n",
    "# ====== 6) 統計量（J列=1 + 人口>=18万）で “例外候補プール” を作る ======\n",
    "stats = pd.read_excel(STATS_XLSX, sheet_name=0)\n",
    "stats.columns = [str(c).strip() for c in stats.columns]\n",
    "\n",
    "# 市区町村名列を推定\n",
    "muni_col = next((c for c in stats.columns if c in [\"市区町村\",\"市町村\",\"自治体\",\"市区分\",\"municipality\"]), None)\n",
    "if muni_col is None:\n",
    "    # それっぽい文字列列を拾う\n",
    "    obj_cols = [c for c in stats.columns if stats[c].dtype == object]\n",
    "    muni_col = obj_cols[0] if obj_cols else stats.columns[0]\n",
    "\n",
    "# 人口列を推定\n",
    "pop_col = next((c for c in stats.columns if (\"人口\" in c or \"総人口\" in c)), None)\n",
    "\n",
    "# J列（ExcelのJ列＝10列目）を取得：ヘッダ名が分からない前提で位置優先\n",
    "# ただし \"J\" という列名があればそれを優先\n",
    "class_col = \"J\" if \"J\" in stats.columns else None\n",
    "if class_col is None:\n",
    "    # \"分類\"っぽい列があればそれを優先\n",
    "    class_col = next((c for c in stats.columns if (\"分類\" in c or \"クラス\" in c or \"class\" in c.lower())), None)\n",
    "if class_col is None:\n",
    "    # 最終手段：10列目（0-based 9）\n",
    "    if len(stats.columns) >= 10:\n",
    "        class_col = stats.columns[9]\n",
    "    else:\n",
    "        class_col = stats.columns[-1]\n",
    "\n",
    "# 人口列が見つからない場合：次善として11列目（0-based 10）を使う\n",
    "if pop_col is None:\n",
    "    if len(stats.columns) >= 11:\n",
    "        pop_col = stats.columns[10]\n",
    "    else:\n",
    "        # どうしても無いなら例外候補は作れない\n",
    "        pop_col = None\n",
    "\n",
    "stats2 = stats.copy()\n",
    "stats2[muni_col] = stats2[muni_col].astype(str).str.strip()\n",
    "stats2[class_col] = pd.to_numeric(stats2[class_col], errors=\"coerce\")\n",
    "if pop_col is not None:\n",
    "    stats2[pop_col] = pd.to_numeric(stats2[pop_col], errors=\"coerce\")\n",
    "else:\n",
    "    stats2[\"__pop__\"] = float(\"nan\")\n",
    "    pop_col = \"__pop__\"\n",
    "\n",
    "# 条件抽出\n",
    "ovr = stats2[(stats2[class_col] == CONFIG[\"OVR_CLASS_J_VALUE\"]) & (stats2[pop_col] >= CONFIG[\"OVR_MIN_POP\"])].copy()\n",
    "\n",
    "# 例外候補：統計ファイルの市区町村名→city_key へマッチして集める\n",
    "ovr_candidates = {}\n",
    "for name in ovr[muni_col].tolist():\n",
    "    ck, sc = match_city_key(name)\n",
    "    if ck:\n",
    "        # 同じckが複数名で引っかかったら、より高スコアを採用\n",
    "        if ck not in ovr_candidates or sc > ovr_candidates[ck][\"match_score\"]:\n",
    "            pop_val = float(ovr.loc[ovr[muni_col] == name, pop_col].iloc[0])\n",
    "            ovr_candidates[ck] = {\"name_raw\": name, \"match_score\": sc, \"pop\": pop_val}\n",
    "\n",
    "OVR_POOL = set(ovr_candidates.keys())\n",
    "print(f\"✅ 例外増枠プール: {len(OVR_POOL)} 市区分（条件: J列=1 & 人口>=18万）\")\n",
    "print(f\"   - J列として使用: {class_col} / 人口列として使用: {pop_col} / 市区町村列: {muni_col}\")\n",
    "\n",
    "# ====== 7) 集客率（既存ロジック流用：県平均 + 市区町村率） ======\n",
    "# ここは“列名依存”が強いので、前回同様に「集客率っぽい列」を自動検出\n",
    "def load_attraction(path):\n",
    "    df = pd.read_excel(path, sheet_name=0)\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    pref_col = next((c for c in df.columns if c in [\"県\",\"都道府県\",\"pref\",\"prefecture\"]), None)\n",
    "    muni_col2 = next((c for c in df.columns if c in [\"市区町村\",\"市町村\",\"自治体\",\"municipality\",\"市区分\"]), None)\n",
    "    rate_col = next((c for c in df.columns if (\"集客率\" in c or \"来場率\" in c or \"動員率\" in c)), None)\n",
    "\n",
    "    if pref_col is None:\n",
    "        pref_col = next((c for c in df.columns if (\"都道府県\" in c or c.endswith(\"県\") or \"県\" in c)), df.columns[0])\n",
    "    if muni_col2 is None:\n",
    "        muni_col2 = next((c for c in df.columns if (\"市\" in c or \"町\" in c or \"村\" in c or \"区\" in c)), df.columns[0])\n",
    "    if rate_col is None:\n",
    "        # 率っぽい数値列\n",
    "        cand = []\n",
    "        for c in df.columns:\n",
    "            if \"率\" in c:\n",
    "                cand.append(c)\n",
    "        rate_col = cand[0] if cand else df.columns[-1]\n",
    "\n",
    "    d = df.copy()\n",
    "    d[pref_col] = d[pref_col].astype(str).str.strip()\n",
    "    d[muni_col2] = d[muni_col2].astype(str).str.strip()\n",
    "    d[rate_col] = pd.to_numeric(d[rate_col], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[rate_col])\n",
    "\n",
    "    muni_rate_norm = {norm(row[muni_col2]): float(row[rate_col]) for _, row in d.iterrows()}\n",
    "    pref_rate = d.groupby(pref_col)[rate_col].mean().to_dict()\n",
    "\n",
    "    return {\"pref_col\": pref_col, \"muni_col\": muni_col2, \"rate_col\": rate_col,\n",
    "            \"muni_rate_norm\": muni_rate_norm,\n",
    "            \"pref_rate\": {str(k).strip(): float(v) for k, v in pref_rate.items()}}\n",
    "\n",
    "attr = load_attraction(STATS_XLSX)\n",
    "\n",
    "pref_rate_by_code = {}\n",
    "for pc in pref_gap.keys():\n",
    "    m = re.match(r\"^\\d{2}(.+)$\", pc)\n",
    "    if m:\n",
    "        name = m.group(1)\n",
    "        if name in attr[\"pref_rate\"]:\n",
    "            pref_rate_by_code[pc] = attr[\"pref_rate\"][name]\n",
    "\n",
    "city_rate = {}\n",
    "for ck in city_keys:\n",
    "    cn = norm(ck)\n",
    "    if cn in attr[\"muni_rate_norm\"]:\n",
    "        city_rate[ck] = attr[\"muni_rate_norm\"][cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "pref_pct, pref_need = percentile_need(pref_rate_by_code)\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "# ====== 外部イベント（後日） ======\n",
    "external_blackout = {(d.get(\"city_key\"), d.get(\"week_id\")): d.get(\"reason\",\"外部イベント\")\n",
    "                     for d in CONFIG[\"EXTERNAL_EVENT_BLACKOUT\"]}\n",
    "\n",
    "# ====== 理由（上司向け口語） ======\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"不明\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"不明\"\n",
    "    return f\"下位{p*100:.0f}%\"\n",
    "\n",
    "def build_reason_presentation(variant, week_id, city_key, pref_code,\n",
    "                              gap_need_pref, gap_real_pref, gap_need_city, gap_real_city,\n",
    "                              pref_rate, pref_rank, city_rate_v, city_rank,\n",
    "                              same_week_pref_hit, relax_mode,\n",
    "                              remaining_plan, overflow_used, overflow_meta, score):\n",
    "    # 口語で、でも根拠は数字を残す（上司が突っ込める）\n",
    "    lines = []\n",
    "    lines.append(f\"【案{variant}】この枠（{week_id}）はAJ枠が空いていたので、次の優先順位で選びました。\")\n",
    "\n",
    "    # 1) 回数枠\n",
    "    if not overflow_used:\n",
    "        lines.append(f\"1) まず『43期の開催回数の残り』がある市区分から選定。→ {city_key} は残り {remaining_plan} 回あったため、計画の範囲内で入れています。\")\n",
    "    else:\n",
    "        # 例外増枠\n",
    "        pop = overflow_meta.get(\"pop\", None)\n",
    "        jv  = overflow_meta.get(\"j_value\", None)\n",
    "        nm  = overflow_meta.get(\"name_raw\", \"\")\n",
    "        pop_txt = f\"{int(pop):,}人\" if isinstance(pop, (int,float)) and not math.isnan(pop) else \"不明\"\n",
    "        lines.append(\"1) ここは『計画回数の残りがある市区分』だけでは候補が出ず、埋め切れなかったため例外ルールで増枠しています。\")\n",
    "        lines.append(f\"   例外ルール：統計量のJ列=1 かつ 人口18万人以上。→ {nm or city_key}（J={jv} / 人口={pop_txt}）を対象にしました。\")\n",
    "\n",
    "    # 2) スパン（B=県 / A=市区）\n",
    "    lines.append(f\"2) 開催間隔（スパン）も見ています。県は『必要{gap_need_pref}週』に対して『前回から{gap_real_pref}週』、市区分は『必要{gap_need_city}週』に対して『前回から{gap_real_city}週』です。\"\n",
    "                 + (f\"（制約緩和={relax_mode}）\" if relax_mode else \"\"))\n",
    "\n",
    "    # 3) 集客率（テコ入れ優先）\n",
    "    if pref_rate is not None or city_rate_v is not None:\n",
    "        lines.append(f\"3) 集客率のテコ入れ観点。県平均は {fmt_rate(pref_rate)}（{fmt_pct(pref_rank)}）、市区分は {fmt_rate(city_rate_v)}（{fmt_pct(city_rank)}）。\"\n",
    "                     \" 低いほど優先度を上げるロジックなので、改善余地の大きいエリアが上に来ます。\")\n",
    "    else:\n",
    "        lines.append(\"3) 集客率はデータが取れていない項目があったため、スパンと回数を優先して選んでいます。\")\n",
    "\n",
    "    # 4) 同週同県回避\n",
    "    lines.append(\"4) 同じ週に同じ都道府県が固まるとカニバりやすいので、同週同県はなるべく避けています。\"\n",
    "                 + (\"（ただし他候補が厳しく同県になったためペナルティは付けています）\" if same_week_pref_hit else \"（今回は同週同県を回避できています）\"))\n",
    "\n",
    "    # 5) 豪雪・祭り\n",
    "    lines.append(\"5) 豪雪地帯の12〜2月・3月1wは原則除外しています（例外リストで解除可能）。祭り/マラソン等は現状未連携で、後日API等をつなげて自動除外できます。\")\n",
    "\n",
    "    # 最後にまとめ\n",
    "    lines.append(f\"【まとめ】『回数の整合』×『間隔（県/市区）』×『集客率の改善余地』×『同週同県回避』を総合して、この候補が一番バランスが良いので採用しています。（score={score:.2f}）\")\n",
    "    return \" / \".join(lines)[:32000]\n",
    "\n",
    "# ====== 週×都道府県の既存使用（43期） ======\n",
    "week_used_pref_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]\n",
    "    pc = e[\"pref_code\"]\n",
    "    if w and pc:\n",
    "        week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "\n",
    "# ====== Plan generator ======\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used_in_plan = {ck: 0 for ck in city_keys}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_c = dict(last_pos_city)\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_city(ck, apos, week_id, relax_mode, allow_overflow):\n",
    "        pc = pref_by_city.get(ck, \"\")\n",
    "        plan_cnt = plan_count_by_city.get(ck, 0)\n",
    "        already  = scheduled_counts_43.get(ck, 0)\n",
    "        remaining = plan_cnt - already - used_in_plan.get(ck, 0)\n",
    "\n",
    "        overflow_used = False\n",
    "        overflow_meta = {}\n",
    "\n",
    "        # 回数ルール\n",
    "        if remaining <= 0:\n",
    "            if not allow_overflow:\n",
    "                return None\n",
    "            # 例外増枠の対象に入っていないなら不可\n",
    "            if ck not in OVR_POOL:\n",
    "                return None\n",
    "            overflow_used = True\n",
    "            meta = ovr_candidates.get(ck, {})\n",
    "            overflow_meta = {\n",
    "                \"name_raw\": meta.get(\"name_raw\",\"\"),\n",
    "                \"pop\": meta.get(\"pop\", float(\"nan\")),\n",
    "                \"j_value\": CONFIG[\"OVR_CLASS_J_VALUE\"],\n",
    "                \"match_score\": meta.get(\"match_score\", None)\n",
    "            }\n",
    "            # 例外増枠は残り回数を「0→-1」みたいに扱う\n",
    "            remaining = remaining  # そのまま（理由に残す）\n",
    "\n",
    "        # スパン要件\n",
    "        gap_need_pref = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        gap_need_city = city_gap.get(ck, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_c = lp_c.get(ck, None)\n",
    "        gap_real_pref = 999 if last_p is None else (apos - last_p)\n",
    "        gap_real_city = 999 if last_c is None else (apos - last_c)\n",
    "\n",
    "        ok_p = (last_p is None) or (gap_real_pref >= gap_need_pref)\n",
    "        ok_c = (last_c is None) or (gap_real_city >= gap_need_city)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_c):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪/外部イベント除外\n",
    "        if pc and is_snow_blackout(pc, ck, week_id):\n",
    "            return None\n",
    "        if (ck, week_id) in external_blackout:\n",
    "            return None\n",
    "\n",
    "        # 同週同県ペナルティ\n",
    "        same_week_pref_hit = False\n",
    "        if pc and pc in week_used_pref.get(week_id, set()):\n",
    "            same_week_pref_hit = True\n",
    "        same_week_pen = CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0\n",
    "\n",
    "        # 集客率（低いほどneedが高い）\n",
    "        pref_need_score = pref_need.get(pc, 0.5)\n",
    "        city_need_score = city_need.get(ck, 0.5)\n",
    "\n",
    "        # “不足時の例外増枠”は軽くペナルティ（でも候補ゼロなら使う）\n",
    "        overflow_pen = CONFIG[\"OVR_OVERFLOW_PENALTY\"] if overflow_used else 0.0\n",
    "\n",
    "        # スコア\n",
    "        slack_p = gap_real_pref - gap_need_pref\n",
    "        slack_c = gap_real_city - gap_need_city\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_c * W[\"city_slack\"] +\n",
    "            max(remaining, 0) * W[\"unmet_bonus\"] * 5.0 +\n",
    "            (pref_need_score * 10) * W[\"low_attr_pref\"] +\n",
    "            (city_need_score * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen - same_week_pen - overflow_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        reason = build_reason_presentation(\n",
    "            variant=variant, week_id=week_id, city_key=ck, pref_code=pc,\n",
    "            gap_need_pref=gap_need_pref, gap_real_pref=gap_real_pref,\n",
    "            gap_need_city=gap_need_city, gap_real_city=gap_real_city,\n",
    "            pref_rate=pref_rate_by_code.get(pc, None), pref_rank=pref_pct.get(pc, None),\n",
    "            city_rate_v=city_rate.get(ck, None), city_rank=city_pct.get(ck, None),\n",
    "            same_week_pref_hit=same_week_pref_hit, relax_mode=relax_mode,\n",
    "            remaining_plan=(plan_cnt - already - used_in_plan.get(ck,0)),\n",
    "            overflow_used=overflow_used, overflow_meta=overflow_meta,\n",
    "            score=score\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"ck\": ck, \"pc\": pc, \"score\": float(score),\n",
    "            \"relax_mode\": relax_mode,\n",
    "            \"same_week_pref_hit\": same_week_pref_hit,\n",
    "            \"overflow_used\": overflow_used,\n",
    "            \"overflow_meta\": overflow_meta,\n",
    "            \"reason\": reason\n",
    "        }\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # ①通常候補（回数残あり）で探す：strict → relax\n",
    "        for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "            for ck in city_keys:\n",
    "                cand = score_city(ck, apos, week_id, relax_mode, allow_overflow=False)\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "            if best is not None:\n",
    "                break\n",
    "\n",
    "        # ②どうしても無理なら例外増枠で探す（指定条件プール内のみ）\n",
    "        used_overflow_for_this_slot = False\n",
    "        if best is None:\n",
    "            for relax_mode in [None, \"Aのみ\", \"B+A\"]:\n",
    "                for ck in city_keys:\n",
    "                    cand = score_city(ck, apos, week_id, relax_mode, allow_overflow=True)\n",
    "                    if cand is None:\n",
    "                        continue\n",
    "                    if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                        best = cand\n",
    "                if best is not None:\n",
    "                    break\n",
    "            used_overflow_for_this_slot = True if (best is not None and best.get(\"overflow_used\")) else False\n",
    "\n",
    "        if best is None:\n",
    "            # それでも無理なら空にする（誤提案より安全）\n",
    "            assigns.append({\n",
    "                \"variant\": variant,\n",
    "                \"week_id_43\": week_id,\n",
    "                \"week_pos_43\": int(slot[\"week_pos\"]),\n",
    "                \"row_header\": int(slot[\"row_header\"]),\n",
    "                \"assign_city_key\": \"\",\n",
    "                \"pref_code_guess\": \"\",\n",
    "                \"score\": float(\"-inf\"),\n",
    "                \"reason_BT\": f\"案{variant}: 回数残/例外増枠プール/豪雪/スパン等の条件で候補が作れず空欄\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; pc = best[\"pc\"]\n",
    "        used_in_plan[ck] += 1\n",
    "        lp_c[ck] = apos\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant,\n",
    "            \"week_id_43\": week_id,\n",
    "            \"week_pos_43\": int(slot[\"week_pos\"]),\n",
    "            \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck,\n",
    "            \"pref_code_guess\": pc,\n",
    "            \"score\": best[\"score\"],\n",
    "            \"reason_BT\": best[\"reason\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "def to_map(plan_df, key_col):\n",
    "    return {int(r[\"row_header\"]): r[key_col] for _, r in plan_df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ====== 11) 書き戻し（42/43のみ残す） ======\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "keep = {sheet42, sheet43}\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in keep:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "skipped = 0\n",
    "overflow_used_cnt = 0\n",
    "\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1\n",
    "\n",
    "    # 上書き防止：CとDが空のときだけ書く\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "    if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    a_city = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b_city = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c_city = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    # B/Cは必ず表示（欠損は \"-\"; 同じでも表示）\n",
    "    b_disp = b_city if b_city else \"-\"\n",
    "    c_disp = c_city if c_city else \"-\"\n",
    "\n",
    "    ws43.cell(r, COL_CITY+1).value = a_city\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b_disp} / C:{c_disp}）\"\n",
    "\n",
    "    # F列：A→B→Cの順でpref_codeを入れる（空欄なら）\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    if (ws43.cell(r, COL_PREF+1).value is None) or (str(ws43.cell(r, COL_PREF+1).value).strip()==\"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    reason = str(A_reason.get(int(row0), \"案A: 理由生成なし\"))\n",
    "    ws43.cell(r, COL_REASON_BT).value = reason\n",
    "    if \"例外ルールで増枠\" in reason:\n",
    "        overflow_used_cnt += 1\n",
    "\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "\n",
    "print(\"\\n✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"   - 42期マスタ:\", sheet42)\n",
    "print(\"   - 43期マスタ:\", sheet43)\n",
    "print(\"✅ 43期 空欄AJ枠:\", len(open43_AJ), \" / 書込:\", written, \" / スキップ:\", skipped)\n",
    "print(\"✅ 例外増枠が使われた枠数（A案の理由から判定）:\", overflow_used_cnt)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGn3YzPS6yJJ",
    "outputId": "b83ccb48-5fdf-4a50-9230-20e270de8a83"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 例外増枠プール: 3 市区分（条件: J列=1 & 人口>=18万）\n",
      "   - J列として使用: Zの4分位（1=赤,2=黄,3=青,4=灰） / 人口列として使用: 人口 / 市区町村列: 市区町村\n",
      "\n",
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_不足時例外増枠_42_43のみ_理由BT.xlsx\n",
      "   - 42期マスタ: 42期　マスタ\n",
      "   - 43期マスタ: 43期　マスタ\n",
      "✅ 43期 空欄AJ枠: 137  / 書込: 137  / スキップ: 0\n",
      "✅ 例外増枠が使われた枠数（A案の理由から判定）: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）【仕様修正版】\n",
    "#\n",
    "# ✅修正①：B案/C案が出ないケースの対策\n",
    "#   - 原因A: これまで「Aと同じなら表示しない」仕様だった → 常にB/Cを表示する（同じでも出す、欠損は\"-\"）\n",
    "#   - 原因B: 制約でB/C側の候補が取れず planB/planC に行が無い → フォールバック強化は維持しつつ、欠損は\"-\"で明示\n",
    "#\n",
    "# ✅修正②：同一週に同一都道府県をなるべく入れない（ソフト制約）\n",
    "#   - 43期の既存枠(埋まり) + その案で既に提案した枠 を「週×都道府県」で使用済みにして\n",
    "#     同一週の同一pref_codeにペナルティを付与（※不可能なら入るが優先度は下がる）\n",
    "#\n",
    "# ✅修正③：F列(都道府県コード+県名、例:25滋賀)を提案枠に書き込む\n",
    "#   - city_key→pref_code_guess を用いてヘッダ行のF列に入れる（既に値があれば上書きしない）\n",
    "#\n",
    "# ✅修正④：出力ファイルは「42期マスタ」「43期マスタ」シートのみ\n",
    "#   - その2シート以外は削除して保存（1ファイルのみ出力）\n",
    "#\n",
    "# 入力:\n",
    "#   SA+AJ+共有用_四半期表20240303.xlsx\n",
    "#   43期地域別会場回数.xlsx\n",
    "#   市区町村_統計量_全国 (1).xlsx\n",
    "#   豪雪例外リスト.xlsx（無ければ自動生成）\n",
    "#\n",
    "# 出力:\n",
    "#   SA+AJ+共有用_四半期表20240303_43期提案ABC_42_43のみ_理由BT.xlsx\n",
    "# ============================================\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# ====== 入力 ======\n",
    "QUARTER_XLSX     = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "ATTRACTION_XLSX  = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "# ====== 出力（1ファイル） ======\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_42_43のみ_理由BT.xlsx\"\n",
    "\n",
    "# ====== 列定義（0-based）=====\n",
    "COL_WEEK = 0           # A 週ID\n",
    "COL_REGION = 1         # B 地域 / (形態行ではAJ/合同/SA)\n",
    "COL_CITY = 2           # C 市区分（提案Aを書き込む）\n",
    "COL_VENUE = 3          # D 会場（会場要検討 + B/C案を併記）\n",
    "COL_PREF = 5           # F 都道府県コード（例 25滋賀）←今回書き込みもする\n",
    "COL_KIND_DETAIL = 1    # 形態行のB列\n",
    "COL_REASON_BT = 72     # BT列（openpyxl: 1-based=72）\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "# ====== 設定 ======\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "\n",
    "    # 同一週 同一都道府県を避けるペナルティ（大きいほど避ける）\n",
    "    \"SAME_WEEK_PREF_PENALTY\": 80.0,\n",
    "\n",
    "    # 豪雪ブラックアウト（暫定）\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    # 表記ゆれ\n",
    "    \"FUZZY_CUTOFF\": 0.82,\n",
    "    \"MANUAL_CITY_MAP\": {},\n",
    "\n",
    "    # 祭り/マラソン等（後日差し込み）\n",
    "    \"EXTERNAL_EVENT_BLACKOUT\": [],\n",
    "\n",
    "    # 3案の重み\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2, \"over_penalty\": 1.0,\n",
    "              \"low_attr_pref\": 2.0, \"low_attr_city\": 1.5, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0, \"over_penalty\": 1.2,\n",
    "              \"low_attr_pref\": 0.8, \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2, \"over_penalty\": 1.0,\n",
    "              \"low_attr_pref\": 3.8, \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ====== Utility ======\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    ws[\"C2\"] = \"豪雪NGを例外的にOKにしたい対象を追加。空欄は無視。\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, city_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if city_key and city_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in CONFIG[\"SNOW_BLACKOUT_MARCH_W\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    # 週IDのヘッダ行 → 次行が形態行（B列）\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "        kind = kind_norm(detail[COL_KIND_DETAIL])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"kind\": kind,\n",
    "            \"city_raw\": city,\n",
    "            \"venue_raw\": venue,\n",
    "            \"pref_code\": pref\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    # AJ/合同のみ扱う（SAは除外）\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "def best_fuzzy_key(a_norm, candidates_norm):\n",
    "    best_ratio, best_norm = 0.0, \"\"\n",
    "    for cand in candidates_norm:\n",
    "        if not cand:\n",
    "            continue\n",
    "        r = difflib.SequenceMatcher(None, a_norm, cand).ratio()\n",
    "        if r > best_ratio:\n",
    "            best_ratio, best_norm = r, cand\n",
    "    return best_norm, best_ratio\n",
    "\n",
    "# ====== 1) Load quarter sheets ======\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ====== 2) city plan（市区分キー & 回数） ======\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()]\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key\"] = plan_rows[1].astype(str)\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "region_master = plan_rows[[\"pref_parent\",\"city_key\",\"plan_count\"]].reset_index(drop=True)\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "city_norm_map = {k: norm(k) for k in city_keys}\n",
    "_norm_values = list(city_norm_map.values())\n",
    "_norm_to_key = {city_norm_map[k]: k for k in city_norm_map}\n",
    "\n",
    "def match_city_key(city_name):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    if city_name in CONFIG[\"MANUAL_CITY_MAP\"]:\n",
    "        return CONFIG[\"MANUAL_CITY_MAP\"][city_name], 1.0\n",
    "    a = norm(city_name)\n",
    "    if a in _norm_to_key and a:\n",
    "        return _norm_to_key[a], 1.0\n",
    "    for ck, ckn in city_norm_map.items():\n",
    "        if ckn and (ckn in a or a in ckn):\n",
    "            return ck, 0.95\n",
    "    bn, ratio = best_fuzzy_key(a, _norm_values)\n",
    "    if ratio >= CONFIG[\"FUZZY_CUTOFF\"] and bn:\n",
    "        return _norm_to_key[bn], ratio\n",
    "    return None, ratio\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys, scores = [], []\n",
    "    for x in df[\"city_raw\"].tolist():\n",
    "        k, s = match_city_key(x)\n",
    "        keys.append(k); scores.append(s)\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "# 既存（埋まり）＝市区分or会場が入っている枠（AJ/合同とも）\n",
    "scheduled42 = b42[(b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")].copy()\n",
    "scheduled43 = b43[(b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")].copy()\n",
    "scheduled42 = add_city_key(scheduled42)\n",
    "scheduled43 = add_city_key(scheduled43)\n",
    "\n",
    "# ★提案対象：43期の「AJ」かつ「CとDが空」のヘッダ行のみ\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ====== 3) pref_code 推定（city_key→pref_code_guess） ======\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# gap（年N回→52/N週）\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "city_gap = {ck: gap_weeks_from_count(int(cnt)) for ck, cnt in plan_count_by_city.items()}\n",
    "\n",
    "# ====== 4) Timeline & last positions（42→43連結） ======\n",
    "OFFSET_43 = len(week_order_42)\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_city = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    ck = e[\"city_key\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "    if ck:\n",
    "        last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "\n",
    "# ====== 5) 43期の計画残（plan - scheduled43） ======\n",
    "scheduled_counts_43 = scheduled43.dropna(subset=[\"city_key\"]).groupby(\"city_key\").size().to_dict()\n",
    "rem_base = {ck: plan_count_by_city.get(ck,0) - scheduled_counts_43.get(ck,0) for ck in city_keys}\n",
    "\n",
    "# ====== 6) 集客率 ======\n",
    "def load_attraction(path):\n",
    "    df = pd.read_excel(path, sheet_name=0)\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "    pref_col = next((c for c in df.columns if c in [\"県\",\"都道府県\",\"pref\",\"prefecture\"]), None)\n",
    "    muni_col = next((c for c in df.columns if c in [\"市区町村\",\"市町村\",\"自治体\",\"municipality\",\"市区分\"]), None)\n",
    "    rate_col = next((c for c in df.columns if \"集客率\" in c or \"来場率\" in c or \"動員率\" in c), None)\n",
    "\n",
    "    if pref_col is None or muni_col is None or rate_col is None:\n",
    "        text_cols = [c for c in df.columns if df[c].dtype == object]\n",
    "        if rate_col is None:\n",
    "            for c in df.columns:\n",
    "                if \"率\" in c and df[c].dtype != object:\n",
    "                    rate_col = c; break\n",
    "        if pref_col is None:\n",
    "            for c in text_cols:\n",
    "                if \"県\" in c or \"都道府県\" in c:\n",
    "                    pref_col = c; break\n",
    "        if muni_col is None:\n",
    "            for c in text_cols:\n",
    "                if \"市\" in c or \"町\" in c or \"村\" in c or \"区\" in c:\n",
    "                    muni_col = c; break\n",
    "\n",
    "    d = df.copy()\n",
    "    d[pref_col] = d[pref_col].astype(str).str.strip()\n",
    "    d[muni_col] = d[muni_col].astype(str).str.strip()\n",
    "    d[rate_col] = pd.to_numeric(d[rate_col], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[rate_col])\n",
    "\n",
    "    muni_rate_norm = {norm(row[muni_col]): float(row[rate_col]) for _, row in d.iterrows()}\n",
    "    pref_rate = d.groupby(pref_col)[rate_col].mean().to_dict()\n",
    "\n",
    "    return {\"pref_col\": pref_col, \"muni_col\": muni_col, \"rate_col\": rate_col,\n",
    "            \"muni_rate_norm\": muni_rate_norm,\n",
    "            \"pref_rate\": {str(k).strip(): float(v) for k, v in pref_rate.items()}}\n",
    "\n",
    "attr = load_attraction(ATTRACTION_XLSX)\n",
    "\n",
    "# pref_code(07福島) → 県名\"福島\"で平均集客率\n",
    "pref_rate_by_code = {}\n",
    "for pc in pref_gap.keys():\n",
    "    m = re.match(r\"^\\d{2}(.+)$\", pc)\n",
    "    if m:\n",
    "        name = m.group(1)\n",
    "        if name in attr[\"pref_rate\"]:\n",
    "            pref_rate_by_code[pc] = attr[\"pref_rate\"][name]\n",
    "\n",
    "# city_key → 集客率（市区町村）\n",
    "city_rate = {}\n",
    "for ck in city_keys:\n",
    "    cn = norm(ck)\n",
    "    if cn in attr[\"muni_rate_norm\"]:\n",
    "        city_rate[ck] = attr[\"muni_rate_norm\"][cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    if not values_dict:\n",
    "        return {}, {}\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "pref_pct, pref_need = percentile_need(pref_rate_by_code)\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "# ====== 7) 外部イベント（後日） ======\n",
    "external_blackout = {(d.get(\"city_key\"), d.get(\"week_id\")): d.get(\"reason\",\"外部イベント\")\n",
    "                     for d in CONFIG[\"EXTERNAL_EVENT_BLACKOUT\"]}\n",
    "\n",
    "def fmt_pct(p):\n",
    "    return \"NA\" if p is None else f\"{p*100:.0f}%\"\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"NA\"\n",
    "    return f\"{v*100:.2f}%\" if v <= 1.0 else f\"{v:.4g}\"\n",
    "\n",
    "def build_reason(variant, relax_mode, need_gap_p, need_gap_c, gp, gc,\n",
    "                 pref_rate, pref_p, city_rate_v, city_p,\n",
    "                 rem_before, rem_after, same_week_pref_hit, score):\n",
    "    parts = []\n",
    "    parts.append(f\"案{variant}\")\n",
    "    if relax_mode:\n",
    "        parts.append(f\"制約緩和={relax_mode}\")\n",
    "    parts.append(f\"スパンB(県):必要{need_gap_p}w/実績{gp}w\")\n",
    "    parts.append(f\"スパンA(市区):必要{need_gap_c}w/実績{gc}w\")\n",
    "    parts.append(f\"集客率(県)={fmt_rate(pref_rate)}(下位{fmt_pct(pref_p)})\" if pref_rate is not None else \"集客率(県)=NA\")\n",
    "    parts.append(f\"集客率(市区)={fmt_rate(city_rate_v)}(下位{fmt_pct(city_p)})\" if city_rate_v is not None else \"集客率(市区)=NA\")\n",
    "    parts.append(f\"同週同県={'回避成功' if not same_week_pref_hit else '同県あり(ペナ)'}\")\n",
    "    parts.append(f\"豪雪=判定済\")\n",
    "    parts.append(f\"祭り=未連携\")\n",
    "    parts.append(f\"計画残(前)={rem_before}→(後)={rem_after}\")\n",
    "    parts.append(f\"score={score:.2f}\")\n",
    "    return \" / \".join(parts)[:32000]\n",
    "\n",
    "# ====== 8) 週×都道府県の既存使用状況（43期）を作る ======\n",
    "# 既に埋まってる枠のpref_codeは週内重複回避の対象にする\n",
    "week_used_pref_base = {}\n",
    "for _, e in scheduled43.iterrows():\n",
    "    w = e[\"week_id\"]\n",
    "    pc = e[\"pref_code\"]\n",
    "    if not w or not pc:\n",
    "        continue\n",
    "    week_used_pref_base.setdefault(w, set()).add(pc)\n",
    "\n",
    "# ====== 9) Plan generator（A/B/C） ======\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used = {ck: 0 for ck in city_keys}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_c = dict(last_pos_city)\n",
    "\n",
    "    # 週内pref使用状況（案内で更新）\n",
    "    week_used_pref = {w:set(s) for w,s in week_used_pref_base.items()}\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_candidate(ck, apos, week_id, relax_mode):\n",
    "        pc = pref_by_city.get(ck, \"\")\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_c = city_gap.get(ck, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_c = lp_c.get(ck, None)\n",
    "\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gc = 999 if last_c is None else (apos - last_c)\n",
    "\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_c = (last_c is None) or (gc >= need_gap_c)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_c):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪/外部イベントは常に除外\n",
    "        if pc and is_snow_blackout(pc, ck, week_id):\n",
    "            return None\n",
    "        if (ck, week_id) in external_blackout:\n",
    "            return None\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_c = gc - need_gap_c\n",
    "\n",
    "        rem_before = rem_base.get(ck, 0) - used.get(ck, 0)\n",
    "        unmet = max(rem_before, 0)\n",
    "        over  = max(-rem_before, 0)\n",
    "\n",
    "        pref_rate = pref_rate_by_code.get(pc, None)\n",
    "        pref_need_score = pref_need.get(pc, 0.5)\n",
    "        city_rate_v = city_rate.get(ck, None)\n",
    "        city_need_score = city_need.get(ck, 0.5)\n",
    "\n",
    "        # 週内同県回避ペナルティ（ソフト）\n",
    "        same_week_pref_hit = False\n",
    "        if pc:\n",
    "            used_set = week_used_pref.get(week_id, set())\n",
    "            if pc in used_set:\n",
    "                same_week_pref_hit = True\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        same_week_pen = CONFIG[\"SAME_WEEK_PREF_PENALTY\"] if same_week_pref_hit else 0.0\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_c * W[\"city_slack\"] +\n",
    "            unmet   * W[\"unmet_bonus\"] * 5.0 -\n",
    "            over    * W[\"over_penalty\"] * 5.0 +\n",
    "            (pref_need_score * 10) * W[\"low_attr_pref\"] +\n",
    "            (city_need_score * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen -\n",
    "            same_week_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"ck\": ck, \"pc\": pc, \"score\": score,\n",
    "            \"need_gap_p\": need_gap_p, \"need_gap_c\": need_gap_c,\n",
    "            \"gp\": gp, \"gc\": gc,\n",
    "            \"pref_rate\": pref_rate, \"pref_p\": pref_pct.get(pc, None),\n",
    "            \"city_rate\": city_rate_v, \"city_p\": city_pct.get(ck, None),\n",
    "            \"rem_before\": rem_before,\n",
    "            \"relax_mode\": relax_mode,\n",
    "            \"same_week_pref_hit\": same_week_pref_hit\n",
    "        }\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # strict\n",
    "        for ck in city_keys:\n",
    "            cand = score_candidate(ck, apos, week_id, relax_mode=None)\n",
    "            if cand is None:\n",
    "                continue\n",
    "            if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                best = cand\n",
    "\n",
    "        # relax A only\n",
    "        if best is None:\n",
    "            for ck in city_keys:\n",
    "                cand = score_candidate(ck, apos, week_id, relax_mode=\"Aのみ\")\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "\n",
    "        # relax B+A (last resort)\n",
    "        if best is None:\n",
    "            for ck in city_keys:\n",
    "                cand = score_candidate(ck, apos, week_id, relax_mode=\"B+A\")\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "\n",
    "        if best is None:\n",
    "            # ここは「豪雪/外部イベントで全候補除外」など極端ケース\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; pc = best[\"pc\"]\n",
    "\n",
    "        # consume\n",
    "        used[ck] += 1\n",
    "        lp_c[ck] = apos\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "\n",
    "        # 週内使用prefを更新\n",
    "        if pc:\n",
    "            week_used_pref.setdefault(week_id, set()).add(pc)\n",
    "\n",
    "        rem_after = best[\"rem_before\"] - 1\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant,\n",
    "            \"week_id_43\": week_id,\n",
    "            \"week_pos_43\": int(slot[\"week_pos\"]),\n",
    "            \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck,\n",
    "            \"pref_code_guess\": pc,\n",
    "            \"score\": float(best[\"score\"]),\n",
    "            \"reason_BT\": build_reason(\n",
    "                variant, best[\"relax_mode\"],\n",
    "                best[\"need_gap_p\"], best[\"need_gap_c\"],\n",
    "                best[\"gp\"], best[\"gc\"],\n",
    "                best[\"pref_rate\"], best[\"pref_p\"],\n",
    "                best[\"city_rate\"], best[\"city_p\"],\n",
    "                best[\"rem_before\"], rem_after,\n",
    "                best[\"same_week_pref_hit\"],\n",
    "                best[\"score\"]\n",
    "            )\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "# row_header -> city_key / pref_code / reason\n",
    "def to_map(plan_df, key_col):\n",
    "    return {int(r[\"row_header\"]): r[key_col] for _, r in plan_df.iterrows()}\n",
    "\n",
    "A_city = to_map(planA, \"assign_city_key\")\n",
    "B_city = to_map(planB, \"assign_city_key\")\n",
    "C_city = to_map(planC, \"assign_city_key\")\n",
    "\n",
    "A_pref = to_map(planA, \"pref_code_guess\")\n",
    "B_pref = to_map(planB, \"pref_code_guess\")\n",
    "C_pref = to_map(planC, \"pref_code_guess\")\n",
    "\n",
    "A_reason = to_map(planA, \"reason_BT\")\n",
    "\n",
    "# ====== 10) 1ファイルに書き戻し（43期マスタのみ変更） + 42/43のみ残す ======\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "\n",
    "# 42/43以外削除（修正④）\n",
    "keep = {sheet42, sheet43}\n",
    "for name in list(wb.sheetnames):\n",
    "    if name not in keep:\n",
    "        wb.remove(wb[name])\n",
    "\n",
    "ws43 = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "skipped = 0\n",
    "\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1  # 0-based -> 1-based\n",
    "\n",
    "    # 安全：CとDが空のときだけ書く（上書き防止）\n",
    "    c_val = ws43.cell(r, COL_CITY+1).value\n",
    "    d_val = ws43.cell(r, COL_VENUE+1).value\n",
    "    if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    a_city = str(A_city.get(int(row0), \"\") or \"\")\n",
    "    b_city = str(B_city.get(int(row0), \"\") or \"\")\n",
    "    c_city = str(C_city.get(int(row0), \"\") or \"\")\n",
    "\n",
    "    # 修正①：B/Cは「同じでも表示」・欠損は\"-\"\n",
    "    b_disp = b_city if b_city else \"-\"\n",
    "    c_disp = c_city if c_city else \"-\"\n",
    "\n",
    "    # C列：A案（第一候補）\n",
    "    ws43.cell(r, COL_CITY+1).value = a_city\n",
    "\n",
    "    # D列：会場要検討（B/C併記）\n",
    "    ws43.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}（B:{b_disp} / C:{c_disp}）\"\n",
    "\n",
    "    # F列：都道府県コード（修正③）\n",
    "    # まずA案のprefを優先、無ければB→C\n",
    "    pref_candidate = A_pref.get(int(row0), \"\") or B_pref.get(int(row0), \"\") or C_pref.get(int(row0), \"\")\n",
    "    f_val = ws43.cell(r, COL_PREF+1).value\n",
    "    if (f_val is None) or (str(f_val).strip() == \"\"):\n",
    "        if pref_candidate:\n",
    "            ws43.cell(r, COL_PREF+1).value = str(pref_candidate)\n",
    "\n",
    "    # BT列：A案の理由\n",
    "    ws43.cell(r, COL_REASON_BT).value = str(A_reason.get(int(row0), \"案A:理由生成なし\"))\n",
    "\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "\n",
    "print(\"✅ 出力:\", OUT_QUARTER_ABC)\n",
    "print(\"   - 42期マスタ:\", sheet42)\n",
    "print(\"   - 43期マスタ:\", sheet43)\n",
    "print(\"✅ 43期 空欄AJ枠:\", len(open43_AJ), \" / 書込:\", written, \" / スキップ:\", skipped)\n",
    "print(\"✅ B/C 欠損(行数) 目安:\",\n",
    "      (len(open43_AJ) - len(planB)), \"(B),\",\n",
    "      (len(open43_AJ) - len(planC)), \"(C)\")\n",
    "print(\"✅ 列確認: C=市区分, D=会場, F=都道府県, BT=理由\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_hDWZ-twhY8",
    "outputId": "3c0c1a46-63df-4298-9a31-bb7dbeb7fd05"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 出力: SA+AJ+共有用_四半期表20240303_43期提案ABC_42_43のみ_理由BT.xlsx\n",
      "   - 42期マスタ: 42期　マスタ\n",
      "   - 43期マスタ: 43期　マスタ\n",
      "✅ 43期 空欄AJ枠: 137  / 書込: 137  / スキップ: 0\n",
      "✅ B/C 欠損(行数) 目安: 0 (B), 0 (C)\n",
      "✅ 列確認: C=市区分, D=会場, F=都道府県, BT=理由\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）【1ファイル統合版】\n",
    "# ✅ 42期も考慮（スパン履歴に含める）\n",
    "# ✅ 集客率も勘案（低い都道府県/市区町村ほど優先度↑）\n",
    "# ✅ 豪雪NG（12〜2月 + 3月1w）※例外は外部Excelで解除\n",
    "# ✅ 選定理由をBT列に出力（A案の理由をBT）\n",
    "# ✅ 「ＡＪの空欄だけ」埋める（合同は“提案しない”が、履歴としてスパンには使う）\n",
    "#\n",
    "# ★仕様変更（今回の要望）\n",
    "# - 出力は1ファイルだけ\n",
    "# - C列（市区分）は A案の提案を書き込む（今まで通り）\n",
    "# - D列（会場）には「会場要検討（B:xxx / C:yyy）」のように B案・C案の市区分も同時に載せる\n",
    "#   → これで四半期表上で「Aが第一候補、B/Cが控え」を1セルで見れる\n",
    "#\n",
    "# 入力:\n",
    "#   SA+AJ+共有用_四半期表20240303.xlsx\n",
    "#   43期地域別会場回数.xlsx\n",
    "#   市区町村_統計量_全国 (1).xlsx\n",
    "# 出力:\n",
    "#   SA+AJ+共有用_四半期表20240303_43期提案ABC_1ファイル統合_理由BT.xlsx\n",
    "#   43期_MVP_提案スケジュール案_ABC_集客率_理由BT.xlsx（検証用）\n",
    "#   豪雪例外リスト.xlsx（無ければ自動生成）\n",
    "# ============================================\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# ====== 入力（Colabにアップロードしたファイル名） ======\n",
    "QUARTER_XLSX     = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "ATTRACTION_XLSX  = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "\n",
    "# ====== 出力 ======\n",
    "OUT_QUARTER_ABC = \"SA+AJ+共有用_四半期表20240303_43期提案ABC_1ファイル統合_理由BT.xlsx\"\n",
    "OUT_ANALYSIS    = \"43期_MVP_提案スケジュール案_ABC_集客率_理由BT.xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "# ====== 四半期表の列（0-based） ======\n",
    "COL_WEEK = 0           # A\n",
    "COL_REGION = 1         # B\n",
    "COL_CITY = 2           # C（市区分）\n",
    "COL_VENUE = 3          # D（会場）\n",
    "COL_PREF = 5           # F（例: 07福島）\n",
    "COL_KIND_DETAIL = 1    # 形態行のB列にAJ/合同/SA\n",
    "COL_REASON_BT = 72     # BT列（1-based=72）\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "# ====== 設定 ======\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "\n",
    "    # 豪雪ブラックアウト（暫定）\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    # 表記ゆれ\n",
    "    \"FUZZY_CUTOFF\": 0.82,\n",
    "    \"MANUAL_CITY_MAP\": {},\n",
    "\n",
    "    # 祭り/マラソン等（後日差し込み）\n",
    "    \"EXTERNAL_EVENT_BLACKOUT\": [],\n",
    "\n",
    "    # 3案の重み\n",
    "    \"WEIGHTS\": {\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2, \"over_penalty\": 1.0,\n",
    "              \"low_attr_pref\": 2.0, \"low_attr_city\": 1.5, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0, \"over_penalty\": 1.2,\n",
    "              \"low_attr_pref\": 0.8, \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2, \"over_penalty\": 1.0,\n",
    "              \"low_attr_pref\": 3.8, \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ====== Utility ======\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"\n",
    "    ws[\"B1\"] = \"city_key\"\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    ws[\"C2\"] = \"豪雪NGを例外的にOKにしたい対象を追加。空欄は無視。\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, city_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if city_key and city_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in CONFIG[\"SNOW_BLACKOUT_MARCH_W\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "        kind = kind_norm(detail[COL_KIND_DETAIL])\n",
    "\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"kind\": kind,\n",
    "            \"city_raw\": city,\n",
    "            \"venue_raw\": venue,\n",
    "            \"pref_code\": pref\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "def best_fuzzy_key(a_norm, candidates_norm):\n",
    "    best_ratio, best_norm = 0.0, \"\"\n",
    "    for cand in candidates_norm:\n",
    "        if not cand:\n",
    "            continue\n",
    "        r = difflib.SequenceMatcher(None, a_norm, cand).ratio()\n",
    "        if r > best_ratio:\n",
    "            best_ratio, best_norm = r, cand\n",
    "    return best_norm, best_ratio\n",
    "\n",
    "# ====== 1) Load quarter sheets ======\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ====== 2) region plan (city_key & 回数) ======\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()]\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()\n",
    "plan_rows[\"city_key\"] = plan_rows[1].astype(str)\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "region_master = plan_rows[[\"pref_parent\",\"city_key\",\"plan_count\"]].reset_index(drop=True)\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "city_norm_map = {k: norm(k) for k in city_keys}\n",
    "_norm_values = list(city_norm_map.values())\n",
    "_norm_to_key = {city_norm_map[k]: k for k in city_norm_map}\n",
    "\n",
    "def match_city_key(city_name):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    if city_name in CONFIG[\"MANUAL_CITY_MAP\"]:\n",
    "        return CONFIG[\"MANUAL_CITY_MAP\"][city_name], 1.0\n",
    "    a = norm(city_name)\n",
    "    if a in _norm_to_key and a:\n",
    "        return _norm_to_key[a], 1.0\n",
    "    for ck, ckn in city_norm_map.items():\n",
    "        if ckn and (ckn in a or a in ckn):\n",
    "            return ck, 0.95\n",
    "    bn, ratio = best_fuzzy_key(a, _norm_values)\n",
    "    if ratio >= CONFIG[\"FUZZY_CUTOFF\"] and bn:\n",
    "        return _norm_to_key[bn], ratio\n",
    "    return None, ratio\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys, scores = [], []\n",
    "    for x in df[\"city_raw\"].tolist():\n",
    "        k, s = match_city_key(x)\n",
    "        keys.append(k); scores.append(s)\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "EXCLUDE_AJ_BASE_VENUES = (\"AJ日本橋\", \"AJ秋葉原\")\n",
    "EXCLUDE_AJ_COUNT_KEYWORDS = (\"萌え\", \"イラスト\", \"JIF\")\n",
    "\n",
    "def is_excluded_aj_base_venue(venue_raw):\n",
    "    s = \"\" if venue_raw is None else str(venue_raw)\n",
    "    s = re.sub(r\"[\\s　]+\", \"\", s)\n",
    "    for base in EXCLUDE_AJ_BASE_VENUES:\n",
    "        if s == base:\n",
    "            return True\n",
    "        if s.startswith(base):\n",
    "            tail = s[len(base):]\n",
    "            if tail and any(k in tail for k in EXCLUDE_AJ_COUNT_KEYWORDS):\n",
    "                return False\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "scheduled42 = b42[((b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")) & (~b42[\"venue_raw\"].apply(is_excluded_aj_base_venue))].copy()\n",
    "scheduled43 = b43[((b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")) & (~b43[\"venue_raw\"].apply(is_excluded_aj_base_venue))].copy()\n",
    "\n",
    "scheduled42 = add_city_key(scheduled42)\n",
    "scheduled43 = add_city_key(scheduled43)\n",
    "\n",
    "# ★提案対象：43期の「AJ」かつ「C(市区分)とD(会場)が空」のヘッダ行のみ\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ====== 3) Pref mapping & gap ======\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "city_gap = {ck: gap_weeks_from_count(int(cnt)) for ck, cnt in plan_count_by_city.items()}\n",
    "\n",
    "# ====== 4) Timeline & last positions ======\n",
    "OFFSET_43 = len(week_order_42)\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_city = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    ck = e[\"city_key\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "    if ck:\n",
    "        last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "\n",
    "# ====== 5) Remaining base (plan - scheduled43) ======\n",
    "scheduled_counts_43 = scheduled43.dropna(subset=[\"city_key\"]).groupby(\"city_key\").size().to_dict()\n",
    "rem_base = {ck: plan_count_by_city.get(ck,0) - scheduled_counts_43.get(ck,0) for ck in city_keys}\n",
    "\n",
    "# ====== 6) Attraction (集客率) ======\n",
    "def load_attraction(path):\n",
    "    df = pd.read_excel(path, sheet_name=0)\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "    pref_col = next((c for c in df.columns if c in [\"県\",\"都道府県\",\"pref\",\"prefecture\"]), None)\n",
    "    muni_col = next((c for c in df.columns if c in [\"市区町村\",\"市町村\",\"自治体\",\"municipality\",\"市区分\"]), None)\n",
    "    rate_col = next((c for c in df.columns if \"集客率\" in c or \"来場率\" in c or \"動員率\" in c), None)\n",
    "\n",
    "    if pref_col is None or muni_col is None or rate_col is None:\n",
    "        text_cols = [c for c in df.columns if df[c].dtype == object]\n",
    "        if rate_col is None:\n",
    "            for c in df.columns:\n",
    "                if \"率\" in c and df[c].dtype != object:\n",
    "                    rate_col = c; break\n",
    "        if pref_col is None:\n",
    "            for c in text_cols:\n",
    "                if \"県\" in c or \"都道府県\" in c:\n",
    "                    pref_col = c; break\n",
    "        if muni_col is None:\n",
    "            for c in text_cols:\n",
    "                if \"市\" in c or \"町\" in c or \"村\" in c or \"区\" in c:\n",
    "                    muni_col = c; break\n",
    "\n",
    "    d = df.copy()\n",
    "    d[pref_col] = d[pref_col].astype(str).str.strip()\n",
    "    d[muni_col] = d[muni_col].astype(str).str.strip()\n",
    "    d[rate_col] = pd.to_numeric(d[rate_col], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[rate_col])\n",
    "\n",
    "    muni_rate_norm = {norm(row[muni_col]): float(row[rate_col]) for _, row in d.iterrows()}\n",
    "    pref_rate = d.groupby(pref_col)[rate_col].mean().to_dict()\n",
    "\n",
    "    return {\"df\": d, \"pref_col\": pref_col, \"muni_col\": muni_col, \"rate_col\": rate_col,\n",
    "            \"muni_rate_norm\": muni_rate_norm, \"pref_rate\": {str(k).strip(): float(v) for k, v in pref_rate.items()}}\n",
    "\n",
    "attr = load_attraction(ATTRACTION_XLSX)\n",
    "\n",
    "pref_rate_by_code = {}\n",
    "for pc in pref_gap.keys():\n",
    "    m = re.match(r\"^\\d{2}(.+)$\", pc)\n",
    "    if m:\n",
    "        name = m.group(1)\n",
    "        if name in attr[\"pref_rate\"]:\n",
    "            pref_rate_by_code[pc] = attr[\"pref_rate\"][name]\n",
    "\n",
    "city_rate = {}\n",
    "for ck in city_keys:\n",
    "    cn = norm(ck)\n",
    "    if cn in attr[\"muni_rate_norm\"]:\n",
    "        city_rate[ck] = attr[\"muni_rate_norm\"][cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    if not values_dict:\n",
    "        return {}, {}\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map}\n",
    "    return pct_map, need_map\n",
    "\n",
    "pref_pct, pref_need = percentile_need(pref_rate_by_code)\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "# ====== 7) External blackout placeholder ======\n",
    "external_blackout = {(d.get(\"city_key\"), d.get(\"week_id\")): d.get(\"reason\",\"外部イベント\")\n",
    "                     for d in CONFIG[\"EXTERNAL_EVENT_BLACKOUT\"]}\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"NA\"\n",
    "    return f\"{p*100:.0f}%\"\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"NA\"\n",
    "    if v <= 1.0:\n",
    "        return f\"{v*100:.2f}%\"\n",
    "    return f\"{v:.4g}\"\n",
    "\n",
    "def build_reason(variant, relax_mode, need_gap_p, need_gap_c, gp, gc,\n",
    "                 pref_rate, pref_p, city_rate_v, city_p,\n",
    "                 rem_before, rem_after, score):\n",
    "    parts = []\n",
    "    parts.append(f\"案{variant}\")\n",
    "    if relax_mode:\n",
    "        parts.append(f\"制約緩和={relax_mode}\")\n",
    "    parts.append(f\"スパンB(県):必要{need_gap_p}w/実績{gp}w\")\n",
    "    parts.append(f\"スパンA(市区):必要{need_gap_c}w/実績{gc}w\")\n",
    "    parts.append(f\"集客率(県)={fmt_rate(pref_rate)}(下位{fmt_pct(pref_p)})\" if pref_rate is not None else \"集客率(県)=NA\")\n",
    "    parts.append(f\"集客率(市区)={fmt_rate(city_rate_v)}(下位{fmt_pct(city_p)})\" if city_rate_v is not None else \"集客率(市区)=NA\")\n",
    "    parts.append(f\"豪雪=判定済\")\n",
    "    parts.append(f\"祭り=未連携\")\n",
    "    parts.append(f\"計画残(前)={rem_before}→(後)={rem_after}\")\n",
    "    parts.append(f\"score={score:.2f}\")\n",
    "    return \" / \".join(parts)[:32000]\n",
    "\n",
    "# ====== 8) Plan generator ======\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    used = {ck: 0 for ck in city_keys}\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_c = dict(last_pos_city)\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_candidate(ck, apos, week_id, relax_mode):\n",
    "        pc = pref_by_city.get(ck, \"\")\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_c = city_gap.get(ck, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_c = lp_c.get(ck, None)\n",
    "\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gc = 999 if last_c is None else (apos - last_c)\n",
    "\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_c = (last_c is None) or (gc >= need_gap_c)\n",
    "\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_c):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪/外部イベントは常に除外\n",
    "        if pc and is_snow_blackout(pc, ck, week_id):\n",
    "            return None\n",
    "        if (ck, week_id) in external_blackout:\n",
    "            return None\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_c = gc - need_gap_c\n",
    "\n",
    "        rem_before = rem_base.get(ck, 0) - used.get(ck, 0)\n",
    "        unmet = max(rem_before, 0)\n",
    "        over  = max(-rem_before, 0)\n",
    "\n",
    "        pref_rate = pref_rate_by_code.get(pc, None)\n",
    "        pref_need_score = pref_need.get(pc, 0.5)\n",
    "        city_rate_v = city_rate.get(ck, None)\n",
    "        city_need_score = city_need.get(ck, 0.5)\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_c * W[\"city_slack\"] +\n",
    "            unmet   * W[\"unmet_bonus\"] * 5.0 -\n",
    "            over    * W[\"over_penalty\"] * 5.0 +\n",
    "            (pref_need_score * 10) * W[\"low_attr_pref\"] +\n",
    "            (city_need_score * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"ck\": ck, \"pc\": pc, \"score\": score,\n",
    "            \"need_gap_p\": need_gap_p, \"need_gap_c\": need_gap_c,\n",
    "            \"gp\": gp, \"gc\": gc,\n",
    "            \"pref_rate\": pref_rate, \"pref_p\": pref_pct.get(pc, None),\n",
    "            \"city_rate\": city_rate_v, \"city_p\": city_pct.get(ck, None),\n",
    "            \"rem_before\": rem_before,\n",
    "            \"relax_mode\": relax_mode\n",
    "        }\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # strict\n",
    "        for ck in city_keys:\n",
    "            cand = score_candidate(ck, apos, week_id, relax_mode=None)\n",
    "            if cand is None:\n",
    "                continue\n",
    "            if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                best = cand\n",
    "\n",
    "        # relax A only\n",
    "        if best is None:\n",
    "            for ck in city_keys:\n",
    "                cand = score_candidate(ck, apos, week_id, relax_mode=\"Aのみ\")\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "\n",
    "        # relax B+A (last resort)\n",
    "        if best is None:\n",
    "            for ck in city_keys:\n",
    "                cand = score_candidate(ck, apos, week_id, relax_mode=\"B+A\")\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "\n",
    "        if best is None:\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; pc = best[\"pc\"]\n",
    "\n",
    "        # consume\n",
    "        used[ck] += 1\n",
    "        lp_c[ck] = apos\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "\n",
    "        rem_after = best[\"rem_before\"] - 1\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant,\n",
    "            \"week_id_43\": week_id,\n",
    "            \"week_pos_43\": int(slot[\"week_pos\"]),\n",
    "            \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"assign_city_key\": ck,\n",
    "            \"pref_code_guess\": pc,\n",
    "            \"score\": float(best[\"score\"]),\n",
    "            \"reason_BT\": build_reason(\n",
    "                variant, best[\"relax_mode\"],\n",
    "                best[\"need_gap_p\"], best[\"need_gap_c\"],\n",
    "                best[\"gp\"], best[\"gc\"],\n",
    "                best[\"pref_rate\"], best[\"pref_p\"],\n",
    "                best[\"city_rate\"], best[\"city_p\"],\n",
    "                best[\"rem_before\"], rem_after,\n",
    "                best[\"score\"]\n",
    "            )\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "# ====== 9) Merge A/B/C by row_header ======\n",
    "def idx_map(plan_df):\n",
    "    return {int(r[\"row_header\"]): str(r[\"assign_city_key\"]) for _, r in plan_df.iterrows()}\n",
    "\n",
    "mapA = idx_map(planA)\n",
    "mapB = idx_map(planB)\n",
    "mapC = idx_map(planC)\n",
    "\n",
    "reasonA = {int(r[\"row_header\"]): str(r[\"reason_BT\"]) for _, r in planA.iterrows()}\n",
    "\n",
    "# ====== 10) Write-back to ONE file ======\n",
    "wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "ws = wb[sheet43]\n",
    "\n",
    "written = 0\n",
    "skipped = 0\n",
    "\n",
    "for row0 in open43_AJ[\"row_header\"].tolist():\n",
    "    r = int(row0) + 1  # 0-based -> 1-based\n",
    "\n",
    "    # 安全：CとDが空のときだけ書く\n",
    "    c_val = ws.cell(r, COL_CITY+1).value\n",
    "    d_val = ws.cell(r, COL_VENUE+1).value\n",
    "    if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    a_city = mapA.get(int(row0), \"\")\n",
    "    b_city = mapB.get(int(row0), \"\")\n",
    "    c_city = mapC.get(int(row0), \"\")\n",
    "\n",
    "    # C列：A案（第一候補）\n",
    "    ws.cell(r, COL_CITY+1).value = a_city if a_city else \"\"\n",
    "\n",
    "    # D列：会場要検討（B/Cも併記）\n",
    "    # 例：会場要検討（B:○○ / C:△△）\n",
    "    extra = []\n",
    "    if b_city and b_city != a_city:\n",
    "        extra.append(f\"B:{b_city}\")\n",
    "    if c_city and c_city != a_city and c_city != b_city:\n",
    "        extra.append(f\"C:{c_city}\")\n",
    "    suffix = f\"（{' / '.join(extra)}）\" if extra else \"\"\n",
    "    ws.cell(r, COL_VENUE+1).value = f\"{VENUE_PLACEHOLDER}{suffix}\"\n",
    "\n",
    "    # BT列：A案の選定理由\n",
    "    ws.cell(r, COL_REASON_BT).value = reasonA.get(int(row0), f\"案A:理由生成なし\")\n",
    "\n",
    "    written += 1\n",
    "\n",
    "wb.save(OUT_QUARTER_ABC)\n",
    "\n",
    "# ====== 11) Analysis workbook ======\n",
    "with pd.ExcelWriter(OUT_ANALYSIS, engine=\"openpyxl\") as w:\n",
    "    planA.sort_values([\"week_pos_43\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"提案A\")\n",
    "    planB.sort_values([\"week_pos_43\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"提案B\")\n",
    "    planC.sort_values([\"week_pos_43\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"提案C\")\n",
    "    open43_AJ.to_excel(w, index=False, sheet_name=\"空欄_AJヘッダ\")\n",
    "\n",
    "    pd.DataFrame([{\"info\":\"sheet43\", \"value\": sheet43},\n",
    "                  {\"info\":\"空欄_AJヘッダ数\", \"value\": len(open43_AJ)},\n",
    "                  {\"info\":\"書込\", \"value\": written},\n",
    "                  {\"info\":\"スキップ\", \"value\": skipped},\n",
    "                  {\"info\":\"BT列\", \"value\": f\"{COL_REASON_BT}({get_column_letter(COL_REASON_BT)})\"},\n",
    "                  {\"info\":\"集客率列(pref_col)\", \"value\": attr[\"pref_col\"]},\n",
    "                  {\"info\":\"集客率列(muni_col)\", \"value\": attr[\"muni_col\"]},\n",
    "                  {\"info\":\"集客率列(rate_col)\", \"value\": attr[\"rate_col\"]},\n",
    "                  ]).to_excel(w, index=False, sheet_name=\"サマリ\")\n",
    "\n",
    "print(\"✅ 出力（四半期表_統合）:\", OUT_QUARTER_ABC, f\"(書込{written}/スキップ{skipped})\")\n",
    "print(\"✅ 出力（検証）:\", OUT_ANALYSIS)\n",
    "print(\"✅ 豪雪例外:\", SNOW_EXCEPT_XLSX)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6drAdrKpadh",
    "outputId": "8ca7db00-a671-4510-8cd4-a8487742df45"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 出力（四半期表_統合）: SA+AJ+共有用_四半期表20240303_43期提案ABC_1ファイル統合_理由BT.xlsx (書込137/スキップ0)\n",
      "✅ 出力（検証）: 43期_MVP_提案スケジュール案_ABC_集客率_理由BT.xlsx\n",
      "✅ 豪雪例外: 豪雪例外リスト.xlsx\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# 43期 スケジュール自動提案 MVP（A/B/C案）\n",
    "# ✅ 42期も考慮（スパン履歴に含める）\n",
    "# ✅ 集客率も勘案（低い都道府県/市区町村ほど優先度↑）\n",
    "# ✅ 豪雪NG（12〜2月 + 3月1w）※例外は外部Excelで解除\n",
    "# ✅ 選定理由を四半期表のBT列に出力\n",
    "# ✅ 「ＡＪの空欄だけ」埋める（合同は“提案しない”が、履歴としてスパンには使う）\n",
    "# ✅ 空欄＝(市区分(C列) & 会場(D列) が空) のヘッダ行だけ書き込み（上書き防止）\n",
    "#\n",
    "# ★修正ポイント（重要）\n",
    "# - 「地域別会場回数の残数(rem)が0になったら候補から除外」だと、提案が1件しか出ないことがある\n",
    "#   → rem<=0 でも候補として残し、\"未達ボーナス\" と \"超過ペナルティ\" で優先度を調整する\n",
    "# - それでもスパン制約が厳しすぎて候補が無い枠が出た場合\n",
    "#   → フォールバックで A(市区)スパンだけ緩和 → 最後にBも緩和(強ペナ/要確認) して「全部埋める」\n",
    "# ============================================\n",
    "\n",
    "import os, re, math, random, difflib\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# ====== 入力（Colabにアップロードしたファイル名） ======\n",
    "QUARTER_XLSX     = \"SA+AJ+共有用_四半期表20240303.xlsx\"\n",
    "REGION_XLSX      = \"43期地域別会場回数.xlsx\"\n",
    "ATTRACTION_XLSX  = \"市区町村_統計量_全国 (1).xlsx\"\n",
    "\n",
    "# ====== 出力 ======\n",
    "OUT_QUARTER_A = \"SA+AJ+共有用_四半期表20240303_43期提案A_集客率考慮_理由BT書込.xlsx\"\n",
    "OUT_QUARTER_B = \"SA+AJ+共有用_四半期表20240303_43期提案B_集客率考慮_理由BT書込.xlsx\"\n",
    "OUT_QUARTER_C = \"SA+AJ+共有用_四半期表20240303_43期提案C_集客率考慮_理由BT書込.xlsx\"\n",
    "OUT_ANALYSIS  = \"43期_MVP_提案スケジュール案_ABC_集客率_理由BT.xlsx\"\n",
    "SNOW_EXCEPT_XLSX = \"豪雪例外リスト.xlsx\"\n",
    "\n",
    "# ====== 四半期表の列（openpyxl/pandas: 0-based） ======\n",
    "# 実データ確認済み：A=週ID, B=地域/形態, C=市区分, D=会場, F=都道府県コード\n",
    "COL_WEEK = 0           # A\n",
    "COL_REGION = 1         # B（東/西/九州/北 etc. / 形態行では AJ/合同/SA）\n",
    "COL_CITY = 2           # C（あなたが埋めたい「市区分」）\n",
    "COL_VENUE = 3          # D（会場名）\n",
    "COL_PREF = 5           # F（例: 07福島）\n",
    "COL_KIND_DETAIL = 1    # 形態行のB列にAJ/合同/SAが入る\n",
    "COL_REASON_BT = 72     # BT列（openpyxl 1-based=72）\n",
    "\n",
    "VENUE_PLACEHOLDER = \"会場要検討\"\n",
    "week_id_pat = re.compile(r\"^\\d{1,2}-\\dw$\")\n",
    "\n",
    "# ====== 設定 ======\n",
    "CONFIG = {\n",
    "    \"GAP_WEEKS_MIN\": 6,\n",
    "    \"GAP_WEEKS_MAX\": 30,\n",
    "\n",
    "    # 豪雪ブラックアウト（暫定）\n",
    "    \"SNOW_BLACKOUT_MONTHS\": {12, 1, 2},\n",
    "    \"SNOW_BLACKOUT_MARCH_W\": {1},\n",
    "    \"SNOW_PREF_CODES\": {\n",
    "        \"01北海道\",\"02青森\",\"03岩手\",\"04宮城\",\"05秋田\",\"06山形\",\"07福島\",\n",
    "        \"15新潟\",\"16富山\",\"17石川\",\"18福井\",\"19山梨\",\n",
    "        \"20長野\",\"21岐阜\",\"31鳥取\",\"32島根\"\n",
    "    },\n",
    "\n",
    "    # 表記ゆれ\n",
    "    \"FUZZY_CUTOFF\": 0.82,\n",
    "    \"MANUAL_CITY_MAP\": {},  # 例: {\"郡山\":\"福島(郡山)\"} のように手動対応\n",
    "\n",
    "    # 祭り/マラソン等（後日差し込み）\n",
    "    # 例: {\"city_key\":\"福島\", \"week_id\":\"5-5w\", \"reason\":\"大祭\"}\n",
    "    \"EXTERNAL_EVENT_BLACKOUT\": [],\n",
    "\n",
    "    # 3案の重み（ハード制約は全案共通）\n",
    "    \"WEIGHTS\": {\n",
    "        # A: バランス\n",
    "        \"A\": {\"pref_slack\": 3.0, \"city_slack\": 2.0, \"unmet_bonus\": 1.2, \"over_penalty\": 1.0,\n",
    "              \"low_attr_pref\": 2.0, \"low_attr_city\": 1.5, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "        # B: スパン最重視\n",
    "        \"B\": {\"pref_slack\": 4.5, \"city_slack\": 3.2, \"unmet_bonus\": 1.0, \"over_penalty\": 1.2,\n",
    "              \"low_attr_pref\": 0.8, \"low_attr_city\": 0.6, \"relax_penalty\": 30.0, \"noise\": 0.8},\n",
    "        # C: 低集客最重視\n",
    "        \"C\": {\"pref_slack\": 2.0, \"city_slack\": 1.2, \"unmet_bonus\": 1.2, \"over_penalty\": 1.0,\n",
    "              \"low_attr_pref\": 3.8, \"low_attr_city\": 3.2, \"relax_penalty\": 25.0, \"noise\": 0.8},\n",
    "    },\n",
    "    \"SEEDS\": {\"A\": 4301, \"B\": 4302, \"C\": 4303},\n",
    "}\n",
    "\n",
    "# ====== Utility ======\n",
    "def norm(s):\n",
    "    if s is None or (isinstance(s, float) and math.isnan(s)):\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"　\",\" \").strip()\n",
    "    s = re.sub(r\"[ \\t\\n\\r\\-‐ー–—/／・,，\\.。()（）【】\\[\\]「」『』]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def find_sheet_name(xlsx_path, keywords):\n",
    "    wb = openpyxl.load_workbook(xlsx_path, read_only=True, data_only=True)\n",
    "    for name in wb.sheetnames:\n",
    "        if all(k in name for k in keywords):\n",
    "            return name\n",
    "    return wb.sheetnames[0]\n",
    "\n",
    "def parse_week_id(week_id):\n",
    "    m = re.match(r\"^(\\d{1,2})-(\\d)w$\", str(week_id))\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def gap_weeks_from_count(cnt):\n",
    "    if cnt <= 0:\n",
    "        return CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "    g = int(math.ceil(52 / cnt))\n",
    "    return max(CONFIG[\"GAP_WEEKS_MIN\"], min(CONFIG[\"GAP_WEEKS_MAX\"], g))\n",
    "\n",
    "def kind_norm(x):\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\"AJ\", \"ＡＪ\").replace(\"ａｊ\", \"ＡＪ\")\n",
    "    s = s.replace(\"SA\", \"ＳＡ\").replace(\"ｓａ\", \"ＳＡ\")\n",
    "    return s\n",
    "\n",
    "def ensure_snow_except_template(path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"例外\"\n",
    "    ws[\"A1\"] = \"pref_code\"     # 例）02青森\n",
    "    ws[\"B1\"] = \"city_key\"      # 例）福島 / 郡山 など（市区分キー）\n",
    "    ws[\"C1\"] = \"memo\"\n",
    "    ws[\"C2\"] = \"豪雪NGを例外的にOKにしたい対象を追加。空欄は無視。\"\n",
    "    wb.save(path)\n",
    "\n",
    "def load_snow_excepts(path):\n",
    "    ensure_snow_except_template(path)\n",
    "    df = pd.read_excel(path, sheet_name=0, dtype=str)\n",
    "    pref = set(df.get(\"pref_code\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    city = set(df.get(\"city_key\", pd.Series([], dtype=str)).dropna().astype(str).str.strip())\n",
    "    return {p for p in pref if p}, {c for c in city if c}\n",
    "\n",
    "SNOW_EXCEPT_PREF_CODES, SNOW_EXCEPT_CITY_KEYS = load_snow_excepts(SNOW_EXCEPT_XLSX)\n",
    "\n",
    "def is_snow_blackout(pref_code, city_key, week_id):\n",
    "    if not pref_code:\n",
    "        return False\n",
    "    if pref_code in SNOW_EXCEPT_PREF_CODES:\n",
    "        return False\n",
    "    if city_key and city_key in SNOW_EXCEPT_CITY_KEYS:\n",
    "        return False\n",
    "    if pref_code not in CONFIG[\"SNOW_PREF_CODES\"]:\n",
    "        return False\n",
    "    month, w = parse_week_id(week_id)\n",
    "    if month is None:\n",
    "        return False\n",
    "    if month in CONFIG[\"SNOW_BLACKOUT_MONTHS\"]:\n",
    "        return True\n",
    "    if month == 3 and w in CONFIG[\"SNOW_BLACKOUT_MARCH_W\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def build_week_order(qsheet):\n",
    "    week_order, seen = [], set()\n",
    "    for v in qsheet[COL_WEEK].astype(str).tolist():\n",
    "        if week_id_pat.match(v) and v not in seen:\n",
    "            week_order.append(v); seen.add(v)\n",
    "    return week_order, {w:i for i,w in enumerate(week_order)}\n",
    "\n",
    "def extract_blocks(qsheet, week_index_map, which):\n",
    "    # 週IDのヘッダ行 → 次行が形態行（B列）\n",
    "    blocks = []\n",
    "    for i in range(len(qsheet)-1):\n",
    "        w = qsheet.iat[i, COL_WEEK]\n",
    "        if pd.isna(w):\n",
    "            continue\n",
    "        w = str(w).strip()\n",
    "        if not week_id_pat.match(w):\n",
    "            continue\n",
    "\n",
    "        header = qsheet.iloc[i]\n",
    "        detail = qsheet.iloc[i+1]\n",
    "        kind = kind_norm(detail[COL_KIND_DETAIL])\n",
    "\n",
    "        region = \"\" if pd.isna(header[COL_REGION]) else str(header[COL_REGION]).strip()\n",
    "        city   = \"\" if pd.isna(header[COL_CITY]) else str(header[COL_CITY]).strip()\n",
    "        venue  = \"\" if pd.isna(header[COL_VENUE]) else str(header[COL_VENUE]).strip()\n",
    "        pref   = \"\" if pd.isna(header[COL_PREF]) else str(header[COL_PREF]).strip()\n",
    "\n",
    "        blocks.append({\n",
    "            \"fy\": which, \"week_id\": w, \"week_pos\": week_index_map.get(w, None),\n",
    "            \"row_header\": i, \"row_detail\": i+1,\n",
    "            \"kind\": kind,\n",
    "            \"region_raw\": region,\n",
    "            \"city_raw\": city,\n",
    "            \"venue_raw\": venue,\n",
    "            \"pref_code\": pref\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(blocks).dropna(subset=[\"week_pos\"]).copy()\n",
    "    df[\"week_pos\"] = df[\"week_pos\"].astype(int)\n",
    "    return df[df[\"kind\"].isin([\"ＡＪ\",\"合同\"])].copy()\n",
    "\n",
    "def best_fuzzy_key(a_norm, candidates_norm):\n",
    "    best_ratio, best_norm = 0.0, \"\"\n",
    "    for cand in candidates_norm:\n",
    "        if not cand:\n",
    "            continue\n",
    "        r = difflib.SequenceMatcher(None, a_norm, cand).ratio()\n",
    "        if r > best_ratio:\n",
    "            best_ratio, best_norm = r, cand\n",
    "    return best_norm, best_ratio\n",
    "\n",
    "# ====== 1) Load quarter sheets ======\n",
    "sheet42 = find_sheet_name(QUARTER_XLSX, [\"42期\", \"マスタ\"])\n",
    "sheet43 = find_sheet_name(QUARTER_XLSX, [\"43期\", \"マスタ\"])\n",
    "q42 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet42, header=None)\n",
    "q43 = pd.read_excel(QUARTER_XLSX, sheet_name=sheet43, header=None)\n",
    "\n",
    "week_order_42, week_index_42 = build_week_order(q42)\n",
    "week_order_43, week_index_43 = build_week_order(q43)\n",
    "\n",
    "b42 = extract_blocks(q42, week_index_42, \"42\")\n",
    "b43 = extract_blocks(q43, week_index_43, \"43\")\n",
    "\n",
    "# ====== 2) region plan (市区分キー & 回数) ======\n",
    "r = pd.read_excel(REGION_XLSX, sheet_name=0, header=None)\n",
    "plan_rows = r[~r[2].isna()].copy()\n",
    "plan_rows = plan_rows[plan_rows[1].notna()]\n",
    "plan_rows[\"pref_parent\"] = plan_rows[0].ffill()          # 県の親（表の構造に依存）\n",
    "plan_rows[\"city_key\"] = plan_rows[1].astype(str)         # 市区分キー\n",
    "plan_rows[\"plan_count\"] = pd.to_numeric(plan_rows[2], errors=\"coerce\").fillna(0).astype(int)\n",
    "region_master = plan_rows[[\"pref_parent\",\"city_key\",\"plan_count\"]].reset_index(drop=True)\n",
    "\n",
    "city_keys = region_master[\"city_key\"].tolist()\n",
    "city_norm_map = {k: norm(k) for k in city_keys}\n",
    "_norm_values = list(city_norm_map.values())\n",
    "_norm_to_key = {city_norm_map[k]: k for k in city_norm_map}\n",
    "\n",
    "def match_city_key(city_name):\n",
    "    if not city_name:\n",
    "        return None, 0.0\n",
    "    if city_name in CONFIG[\"MANUAL_CITY_MAP\"]:\n",
    "        return CONFIG[\"MANUAL_CITY_MAP\"][city_name], 1.0\n",
    "    a = norm(city_name)\n",
    "    if a in _norm_to_key and a:\n",
    "        return _norm_to_key[a], 1.0\n",
    "    # 部分一致\n",
    "    for ck, ckn in city_norm_map.items():\n",
    "        if ckn and (ckn in a or a in ckn):\n",
    "            return ck, 0.95\n",
    "    bn, ratio = best_fuzzy_key(a, _norm_values)\n",
    "    if ratio >= CONFIG[\"FUZZY_CUTOFF\"] and bn:\n",
    "        return _norm_to_key[bn], ratio\n",
    "    return None, ratio\n",
    "\n",
    "def add_city_key(df):\n",
    "    keys, scores = [], []\n",
    "    for x in df[\"city_raw\"].tolist():\n",
    "        k, s = match_city_key(x)\n",
    "        keys.append(k); scores.append(s)\n",
    "    out = df.copy()\n",
    "    out[\"city_key\"] = keys\n",
    "    out[\"match_score\"] = scores\n",
    "    return out\n",
    "\n",
    "EXCLUDE_AJ_BASE_VENUES = (\"AJ日本橋\", \"AJ秋葉原\")\n",
    "EXCLUDE_AJ_COUNT_KEYWORDS = (\"萌え\", \"イラスト\", \"JIF\")\n",
    "\n",
    "def is_excluded_aj_base_venue(venue_raw):\n",
    "    s = \"\" if venue_raw is None else str(venue_raw)\n",
    "    s = re.sub(r\"[\\s　]+\", \"\", s)\n",
    "    for base in EXCLUDE_AJ_BASE_VENUES:\n",
    "        if s == base:\n",
    "            return True\n",
    "        if s.startswith(base):\n",
    "            tail = s[len(base):]\n",
    "            if tail and any(k in tail for k in EXCLUDE_AJ_COUNT_KEYWORDS):\n",
    "                return False\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "scheduled42 = b42[((b42[\"city_raw\"]!=\"\") | (b42[\"venue_raw\"]!=\"\")) & (~b42[\"venue_raw\"].apply(is_excluded_aj_base_venue))].copy()\n",
    "scheduled43 = b43[((b43[\"city_raw\"]!=\"\") | (b43[\"venue_raw\"]!=\"\")) & (~b43[\"venue_raw\"].apply(is_excluded_aj_base_venue))].copy()\n",
    "\n",
    "scheduled42 = add_city_key(scheduled42)\n",
    "scheduled43 = add_city_key(scheduled43)\n",
    "\n",
    "# ★提案対象：43期の「AJ」かつ「市区分(C)と会場(D)が空」のヘッダ行のみ\n",
    "open43_AJ = b43[\n",
    "    (b43[\"kind\"]==\"ＡＪ\") &\n",
    "    (b43[\"city_raw\"]==\"\") &\n",
    "    (b43[\"venue_raw\"]==\"\")\n",
    "].copy().sort_values([\"week_pos\",\"row_header\"]).reset_index(drop=True)\n",
    "\n",
    "# ====== 3) Pref code mapping & gap (pref/city) ======\n",
    "# 県コードは四半期表 colF に入っている（例: 07福島）→ 県名部分を取り出して集客率と合わせる\n",
    "pref_code_set = set([str(x).strip() for x in q43[COL_PREF].dropna().astype(str).unique().tolist()])\n",
    "\n",
    "# 市区分の「親（県）」を pref_code に寄せる（pref_parentの先頭語が県名と一致する想定）\n",
    "pref_name_to_code = {}\n",
    "for pc in pref_code_set:\n",
    "    m = re.match(r\"^(\\d{2})(.+)$\", pc)\n",
    "    if m:\n",
    "        pref_name_to_code[m.group(2)] = pc\n",
    "\n",
    "def parent_to_pref_code(pref_parent):\n",
    "    if pref_parent is None or (isinstance(pref_parent,float) and math.isnan(pref_parent)):\n",
    "        return \"\"\n",
    "    s = str(pref_parent).strip()\n",
    "    # 先頭の県名（数字より前/区切り前）を拾う\n",
    "    m = re.match(r\"^([^\\d]+)\", s)\n",
    "    name = m.group(1).strip() if m else s\n",
    "    return pref_name_to_code.get(name, \"\")\n",
    "\n",
    "region_master[\"pref_code_guess\"] = region_master[\"pref_parent\"].apply(parent_to_pref_code)\n",
    "\n",
    "# gap: 年N回 → 52/N 週\n",
    "pref_plan_count = region_master.groupby(\"pref_code_guess\")[\"plan_count\"].sum().to_dict()\n",
    "pref_gap   = {pc: gap_weeks_from_count(int(cnt)) for pc, cnt in pref_plan_count.items() if pc}\n",
    "city_gap   = {ck: gap_weeks_from_count(int(cnt)) for ck, cnt in region_master.set_index(\"city_key\")[\"plan_count\"].to_dict().items()}\n",
    "\n",
    "# ====== 4) Timeline (42→43連結) & last positions ======\n",
    "OFFSET_43 = len(week_order_42)\n",
    "scheduled42[\"abs_pos\"] = scheduled42[\"week_pos\"]\n",
    "scheduled43[\"abs_pos\"] = scheduled43[\"week_pos\"] + OFFSET_43\n",
    "open43_AJ[\"abs_pos\"]   = open43_AJ[\"week_pos\"] + OFFSET_43\n",
    "scheduled_all = pd.concat([scheduled42, scheduled43], ignore_index=True)\n",
    "\n",
    "last_pos_pref, last_pos_city = {}, {}\n",
    "for _, e in scheduled_all.dropna(subset=[\"abs_pos\"]).iterrows():\n",
    "    ap = int(e[\"abs_pos\"])\n",
    "    pc = e[\"pref_code\"]\n",
    "    ck = e[\"city_key\"]\n",
    "    if pc:\n",
    "        last_pos_pref[pc] = max(last_pos_pref.get(pc, -999), ap)\n",
    "    if ck:\n",
    "        last_pos_city[ck] = max(last_pos_city.get(ck, -999), ap)\n",
    "\n",
    "pref_by_city = region_master.set_index(\"city_key\")[\"pref_code_guess\"].to_dict()\n",
    "plan_count_by_city = region_master.set_index(\"city_key\")[\"plan_count\"].to_dict()\n",
    "\n",
    "# ====== 5) 43期の現状消化（未達/超過の基準） ======\n",
    "scheduled_counts_43 = scheduled43.dropna(subset=[\"city_key\"]).groupby(\"city_key\").size().to_dict()\n",
    "# rem_base = plan - already_scheduled_in_43\n",
    "rem_base = {ck: plan_count_by_city.get(ck,0) - scheduled_counts_43.get(ck,0) for ck in city_keys}\n",
    "\n",
    "# ====== 6) Attraction (集客率) ======\n",
    "def load_attraction(path):\n",
    "    df = pd.read_excel(path, sheet_name=0)\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "    pref_col = next((c for c in df.columns if c in [\"県\",\"都道府県\",\"pref\",\"prefecture\"]), None)\n",
    "    muni_col = next((c for c in df.columns if c in [\"市区町村\",\"市町村\",\"自治体\",\"municipality\",\"市区分\"]), None)\n",
    "    rate_col = next((c for c in df.columns if \"集客率\" in c or \"来場率\" in c or \"動員率\" in c), None)\n",
    "\n",
    "    if pref_col is None or muni_col is None or rate_col is None:\n",
    "        text_cols = [c for c in df.columns if df[c].dtype == object]\n",
    "        if rate_col is None:\n",
    "            for c in df.columns:\n",
    "                if \"率\" in c and df[c].dtype != object:\n",
    "                    rate_col = c; break\n",
    "        if pref_col is None:\n",
    "            for c in text_cols:\n",
    "                if \"県\" in c or \"都道府県\" in c:\n",
    "                    pref_col = c; break\n",
    "        if muni_col is None:\n",
    "            for c in text_cols:\n",
    "                if \"市\" in c or \"町\" in c or \"村\" in c or \"区\" in c:\n",
    "                    muni_col = c; break\n",
    "\n",
    "    d = df.copy()\n",
    "    d[pref_col] = d[pref_col].astype(str).str.strip()\n",
    "    d[muni_col] = d[muni_col].astype(str).str.strip()\n",
    "    d[rate_col] = pd.to_numeric(d[rate_col], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[rate_col])\n",
    "\n",
    "    muni_rate_norm = {norm(row[muni_col]): float(row[rate_col]) for _, row in d.iterrows()}\n",
    "    pref_rate = d.groupby(pref_col)[rate_col].mean().to_dict()\n",
    "\n",
    "    return {\"df\": d, \"pref_col\": pref_col, \"muni_col\": muni_col, \"rate_col\": rate_col,\n",
    "            \"muni_rate_norm\": muni_rate_norm, \"pref_rate\": {str(k).strip(): float(v) for k, v in pref_rate.items()}}\n",
    "\n",
    "attr = load_attraction(ATTRACTION_XLSX)\n",
    "\n",
    "# pref_code(07福島) → \"福島\" の県名で集客率と突合\n",
    "pref_rate_by_code = {}\n",
    "for pc in pref_gap.keys():\n",
    "    m = re.match(r\"^\\d{2}(.+)$\", pc)\n",
    "    if m:\n",
    "        name = m.group(1)\n",
    "        if name in attr[\"pref_rate\"]:\n",
    "            pref_rate_by_code[pc] = attr[\"pref_rate\"][name]\n",
    "\n",
    "# city_key → muni_rate（正規化名で一致）\n",
    "city_rate = {}\n",
    "for ck in city_keys:\n",
    "    cn = norm(ck)\n",
    "    if cn in attr[\"muni_rate_norm\"]:\n",
    "        city_rate[ck] = attr[\"muni_rate_norm\"][cn]\n",
    "\n",
    "def percentile_need(values_dict):\n",
    "    if not values_dict:\n",
    "        return {}, {}\n",
    "    items = [(k, v) for k, v in values_dict.items()\n",
    "             if v is not None and not (isinstance(v, float) and math.isnan(v))]\n",
    "    if not items:\n",
    "        return {}, {}\n",
    "    vals = [v for _, v in items]\n",
    "    s = pd.Series(vals)\n",
    "    pct = s.rank(pct=True, method=\"average\").tolist()      # 小さいほどpct小\n",
    "    keys_ = [k for k, _ in items]\n",
    "    pct_map = {k: p for k, p in zip(keys_, pct)}\n",
    "    need_map = {k: float(1 - pct_map[k]) for k in pct_map} # 低い集客率ほどneed高\n",
    "    return pct_map, need_map\n",
    "\n",
    "pref_pct, pref_need = percentile_need(pref_rate_by_code)\n",
    "city_pct, city_need = percentile_need(city_rate)\n",
    "\n",
    "# ====== 7) External blackout (future) ======\n",
    "external_blackout = {(d.get(\"city_key\"), d.get(\"week_id\")): d.get(\"reason\",\"外部イベント\")\n",
    "                     for d in CONFIG[\"EXTERNAL_EVENT_BLACKOUT\"]}\n",
    "\n",
    "def fmt_pct(p):\n",
    "    if p is None:\n",
    "        return \"NA\"\n",
    "    return f\"{p*100:.0f}%\"\n",
    "\n",
    "def fmt_rate(v):\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)):\n",
    "        return \"NA\"\n",
    "    if v <= 1.0:\n",
    "        return f\"{v*100:.2f}%\"\n",
    "    return f\"{v:.4g}\"\n",
    "\n",
    "def build_reason(variant, relax_mode, need_gap_p, need_gap_c, gp, gc,\n",
    "                 pref_rate, pref_p, city_rate_v, city_p,\n",
    "                 snow_ng, fest_ng, rem_before, rem_after, score):\n",
    "    parts = []\n",
    "    parts.append(f\"案{variant}\")\n",
    "    if relax_mode:\n",
    "        parts.append(f\"制約緩和={relax_mode}\")\n",
    "    parts.append(f\"スパンB(県):必要{need_gap_p}w/実績{gp}w\")\n",
    "    parts.append(f\"スパンA(市区):必要{need_gap_c}w/実績{gc}w\")\n",
    "    parts.append(f\"集客率(県)={fmt_rate(pref_rate)}(下位{fmt_pct(pref_p)})\" if pref_rate is not None else \"集客率(県)=NA\")\n",
    "    parts.append(f\"集客率(市区)={fmt_rate(city_rate_v)}(下位{fmt_pct(city_p)})\" if city_rate_v is not None else \"集客率(市区)=NA\")\n",
    "    parts.append(f\"豪雪={'NG' if snow_ng else 'OK'}\")\n",
    "    parts.append(f\"祭り={'NG' if fest_ng else '未連携'}\")\n",
    "    parts.append(f\"計画残(前)={rem_before}→(後)={rem_after}\")\n",
    "    parts.append(f\"score={score:.2f}\")\n",
    "    return \" / \".join(parts)[:32000]\n",
    "\n",
    "# ====== 8) Plan generation (A/B/C) ======\n",
    "def make_plan(variant):\n",
    "    rng = random.Random(CONFIG[\"SEEDS\"][variant])\n",
    "    W = CONFIG[\"WEIGHTS\"][variant]\n",
    "\n",
    "    # 案ごとの“追加消化”カウンタ（rem_base を更新するため）\n",
    "    used = {ck: 0 for ck in city_keys}\n",
    "\n",
    "    # 案ごとの last_pos（スパンが案内で連鎖する）\n",
    "    lp_p = dict(last_pos_pref)\n",
    "    lp_c = dict(last_pos_city)\n",
    "\n",
    "    assigns = []\n",
    "\n",
    "    def score_candidate(ck, apos, week_id, relax_mode):\n",
    "        pc = pref_by_city.get(ck, \"\")\n",
    "        need_gap_p = pref_gap.get(pc, CONFIG[\"GAP_WEEKS_MIN\"]) if pc else CONFIG[\"GAP_WEEKS_MIN\"]\n",
    "        need_gap_c = city_gap.get(ck, CONFIG[\"GAP_WEEKS_MIN\"])\n",
    "\n",
    "        last_p = lp_p.get(pc, None) if pc else None\n",
    "        last_c = lp_c.get(ck, None)\n",
    "\n",
    "        gp = 999 if last_p is None else (apos - last_p)\n",
    "        gc = 999 if last_c is None else (apos - last_c)\n",
    "\n",
    "        # スパン判定\n",
    "        ok_p = (last_p is None) or (gp >= need_gap_p)\n",
    "        ok_c = (last_c is None) or (gc >= need_gap_c)\n",
    "\n",
    "        # relax_mode:\n",
    "        #  None      : strict (B & A)\n",
    "        #  \"Aのみ\"   : Bは守るがAは緩和\n",
    "        #  \"B+A\"     : Bも緩和（最終手段）\n",
    "        if relax_mode is None:\n",
    "            if not (ok_p and ok_c):\n",
    "                return None\n",
    "        elif relax_mode == \"Aのみ\":\n",
    "            if not ok_p:\n",
    "                return None\n",
    "        elif relax_mode == \"B+A\":\n",
    "            pass\n",
    "\n",
    "        # 豪雪/外部イベントは常に除外\n",
    "        if pc and is_snow_blackout(pc, ck, week_id):\n",
    "            return None\n",
    "        if (ck, week_id) in external_blackout:\n",
    "            return None\n",
    "\n",
    "        slack_p = gp - need_gap_p\n",
    "        slack_c = gc - need_gap_c\n",
    "\n",
    "        # 計画残（43期の現状消化 + この案での追加消化を反映）\n",
    "        rem_before = rem_base.get(ck, 0) - used.get(ck, 0)\n",
    "        unmet = max(rem_before, 0)       # 未達ボーナス\n",
    "        over  = max(-rem_before, 0)      # 超過ペナ\n",
    "\n",
    "        # 集客率need（NAは中立0.5）\n",
    "        pref_rate = pref_rate_by_code.get(pc, None)\n",
    "        pref_need_score = pref_need.get(pc, 0.5)\n",
    "        city_rate_v = city_rate.get(ck, None)\n",
    "        city_need_score = city_need.get(ck, 0.5)\n",
    "\n",
    "        relax_pen = 0.0\n",
    "        if relax_mode == \"Aのみ\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 0.6\n",
    "        elif relax_mode == \"B+A\":\n",
    "            relax_pen = W[\"relax_penalty\"] * 1.0\n",
    "\n",
    "        score = (\n",
    "            slack_p * W[\"pref_slack\"] +\n",
    "            slack_c * W[\"city_slack\"] +\n",
    "            unmet   * W[\"unmet_bonus\"] * 5.0 -\n",
    "            over    * W[\"over_penalty\"] * 5.0 +\n",
    "            (pref_need_score * 10) * W[\"low_attr_pref\"] +\n",
    "            (city_need_score * 10) * W[\"low_attr_city\"] -\n",
    "            relax_pen +\n",
    "            rng.uniform(-0.5, 0.5) * W[\"noise\"]\n",
    "        )\n",
    "        return {\n",
    "            \"ck\": ck, \"pc\": pc, \"score\": score,\n",
    "            \"need_gap_p\": need_gap_p, \"need_gap_c\": need_gap_c,\n",
    "            \"gp\": gp, \"gc\": gc,\n",
    "            \"pref_rate\": pref_rate, \"pref_p\": pref_pct.get(pc, None),\n",
    "            \"city_rate\": city_rate_v, \"city_p\": city_pct.get(ck, None),\n",
    "            \"rem_before\": rem_before,\n",
    "            \"relax_mode\": relax_mode\n",
    "        }\n",
    "\n",
    "    for _, slot in open43_AJ.iterrows():\n",
    "        apos = int(slot[\"abs_pos\"])\n",
    "        week_id = slot[\"week_id\"]\n",
    "\n",
    "        best = None\n",
    "\n",
    "        # まず strict（B+A）\n",
    "        for ck in city_keys:\n",
    "            cand = score_candidate(ck, apos, week_id, relax_mode=None)\n",
    "            if cand is None:\n",
    "                continue\n",
    "            if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                best = cand\n",
    "\n",
    "        # フォールバック：Aだけ緩和（Bは守る）\n",
    "        if best is None:\n",
    "            for ck in city_keys:\n",
    "                cand = score_candidate(ck, apos, week_id, relax_mode=\"Aのみ\")\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "\n",
    "        # 最終手段：Bも緩和（要確認だが「全部埋める」ため）\n",
    "        if best is None:\n",
    "            for ck in city_keys:\n",
    "                cand = score_candidate(ck, apos, week_id, relax_mode=\"B+A\")\n",
    "                if cand is None:\n",
    "                    continue\n",
    "                if best is None or cand[\"score\"] > best[\"score\"]:\n",
    "                    best = cand\n",
    "\n",
    "        if best is None:\n",
    "            # ここに来るのは（豪雪や外部イベントで全候補除外など）かなりレア\n",
    "            continue\n",
    "\n",
    "        ck = best[\"ck\"]; pc = best[\"pc\"]\n",
    "\n",
    "        # 消化更新\n",
    "        used[ck] += 1\n",
    "        lp_c[ck] = apos\n",
    "        if pc:\n",
    "            lp_p[pc] = apos\n",
    "\n",
    "        rem_after = best[\"rem_before\"] - 1\n",
    "\n",
    "        reason = build_reason(\n",
    "            variant=variant,\n",
    "            relax_mode=best[\"relax_mode\"],\n",
    "            need_gap_p=best[\"need_gap_p\"],\n",
    "            need_gap_c=best[\"need_gap_c\"],\n",
    "            gp=best[\"gp\"],\n",
    "            gc=best[\"gc\"],\n",
    "            pref_rate=best[\"pref_rate\"],\n",
    "            pref_p=best[\"pref_p\"],\n",
    "            city_rate_v=best[\"city_rate\"],\n",
    "            city_p=best[\"city_p\"],\n",
    "            snow_ng=False,\n",
    "            fest_ng=False,\n",
    "            rem_before=best[\"rem_before\"],\n",
    "            rem_after=rem_after,\n",
    "            score=best[\"score\"]\n",
    "        )\n",
    "\n",
    "        assigns.append({\n",
    "            \"variant\": variant,\n",
    "            \"week_id_43\": week_id,\n",
    "            \"week_pos_43\": int(slot[\"week_pos\"]),\n",
    "            \"abs_pos\": apos,\n",
    "            \"row_header\": int(slot[\"row_header\"]),\n",
    "            \"row_detail\": int(slot[\"row_detail\"]),\n",
    "            \"assign_city_key\": ck,\n",
    "            \"pref_code_guess\": pc,\n",
    "            \"need_gap_pref\": best[\"need_gap_p\"],\n",
    "            \"need_gap_city\": best[\"need_gap_c\"],\n",
    "            \"actual_pref_gap\": best[\"gp\"],\n",
    "            \"actual_city_gap\": best[\"gc\"],\n",
    "            \"attr_pref_rate\": best[\"pref_rate\"],\n",
    "            \"attr_city_rate\": best[\"city_rate\"],\n",
    "            \"score\": round(best[\"score\"], 2),\n",
    "            \"reason_BT\": reason\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(assigns)\n",
    "\n",
    "planA = make_plan(\"A\")\n",
    "planB = make_plan(\"B\")\n",
    "planC = make_plan(\"C\")\n",
    "\n",
    "# ====== 9) Write-back (43期マスタのみ) ======\n",
    "def write_back(out_path, plan_df):\n",
    "    wb = openpyxl.load_workbook(QUARTER_XLSX)\n",
    "    ws = wb[sheet43]\n",
    "\n",
    "    written = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for _, a in plan_df.iterrows():\n",
    "        r = int(a[\"row_header\"]) + 1  # 0-based -> 1-based\n",
    "\n",
    "        # ★上書き事故防止：C(市区分) と D(会場) が空欄のときだけ書く\n",
    "        c_val = ws.cell(r, COL_CITY+1).value\n",
    "        d_val = ws.cell(r, COL_VENUE+1).value\n",
    "        if (c_val is not None and str(c_val).strip() != \"\") or (d_val is not None and str(d_val).strip() != \"\"):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        ws.cell(r, COL_CITY+1).value = str(a[\"assign_city_key\"])\n",
    "        ws.cell(r, COL_VENUE+1).value = VENUE_PLACEHOLDER\n",
    "        ws.cell(r, COL_REASON_BT).value = str(a[\"reason_BT\"])\n",
    "        written += 1\n",
    "\n",
    "    wb.save(out_path)\n",
    "    return written, skipped\n",
    "\n",
    "wA, sA = write_back(OUT_QUARTER_A, planA)\n",
    "wB, sB = write_back(OUT_QUARTER_B, planB)\n",
    "wC, sC = write_back(OUT_QUARTER_C, planC)\n",
    "\n",
    "# ====== 10) Analysis workbook ======\n",
    "with pd.ExcelWriter(OUT_ANALYSIS, engine=\"openpyxl\") as w:\n",
    "    planA.sort_values([\"week_pos_43\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"提案A\")\n",
    "    planB.sort_values([\"week_pos_43\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"提案B\")\n",
    "    planC.sort_values([\"week_pos_43\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"提案C\")\n",
    "\n",
    "    open43_AJ.to_excel(w, index=False, sheet_name=\"空欄_AJヘッダ\")\n",
    "    scheduled42.sort_values([\"week_pos\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"既存_42\")\n",
    "    scheduled43.sort_values([\"week_pos\",\"row_header\"]).to_excel(w, index=False, sheet_name=\"既存_43\")\n",
    "\n",
    "    # 残数の見える化（43期現状）\n",
    "    rem_df = pd.DataFrame([{\n",
    "        \"city_key\": ck,\n",
    "        \"plan_count\": plan_count_by_city.get(ck,0),\n",
    "        \"scheduled_43\": scheduled_counts_43.get(ck,0),\n",
    "        \"rem_base(plan-scheduled43)\": rem_base.get(ck,0)\n",
    "    } for ck in city_keys]).sort_values([\"rem_base(plan-scheduled43)\",\"city_key\"], ascending=[True, True])\n",
    "    rem_df.to_excel(w, index=False, sheet_name=\"計画残_43現状\")\n",
    "\n",
    "    pd.DataFrame([{\"pref_code\":pc,\"pref_attr_rate\":pref_rate_by_code.get(pc), \"need(低いほど高)\":pref_need.get(pc)} for pc in sorted(pref_gap.keys())])\\\n",
    "      .to_excel(w, index=False, sheet_name=\"県_集客率\")\n",
    "    pd.DataFrame([{\"city_key\":ck,\"city_attr_rate\":city_rate.get(ck), \"need(低いほど高)\":city_need.get(ck)} for ck in sorted(city_keys)])\\\n",
    "      .to_excel(w, index=False, sheet_name=\"市区_集客率\")\n",
    "\n",
    "    pd.DataFrame([\n",
    "        {\"info\":\"sheet42\", \"value\": sheet42},\n",
    "        {\"info\":\"sheet43\", \"value\": sheet43},\n",
    "        {\"info\":\"空欄_AJヘッダ数\", \"value\": len(open43_AJ)},\n",
    "        {\"info\":\"提案A数\", \"value\": len(planA)}, {\"info\":\"提案A 書込\", \"value\": wA}, {\"info\":\"提案A スキップ\", \"value\": sA},\n",
    "        {\"info\":\"提案B数\", \"value\": len(planB)}, {\"info\":\"提案B 書込\", \"value\": wB}, {\"info\":\"提案B スキップ\", \"value\": sB},\n",
    "        {\"info\":\"提案C数\", \"value\": len(planC)}, {\"info\":\"提案C 書込\", \"value\": wC}, {\"info\":\"提案C スキップ\", \"value\": sC},\n",
    "        {\"info\":\"集客率列(pref_col)\", \"value\": attr[\"pref_col\"]},\n",
    "        {\"info\":\"集客率列(muni_col)\", \"value\": attr[\"muni_col\"]},\n",
    "        {\"info\":\"集客率列(rate_col)\", \"value\": attr[\"rate_col\"]},\n",
    "        {\"info\":\"豪雪例外pref数\", \"value\": len(SNOW_EXCEPT_PREF_CODES)},\n",
    "        {\"info\":\"豪雪例外city数\", \"value\": len(SNOW_EXCEPT_CITY_KEYS)},\n",
    "        {\"info\":\"BT列index\", \"value\": f\"{COL_REASON_BT}({get_column_letter(COL_REASON_BT)})\"},\n",
    "    ]).to_excel(w, index=False, sheet_name=\"サマリ\")\n",
    "\n",
    "print(\"✅ 空欄(AJヘッダ)数:\", len(open43_AJ))\n",
    "print(\"✅ A:\", f\"提案{len(planA)} / 書込{wA} / スキップ{sA} -> {OUT_QUARTER_A}\")\n",
    "print(\"✅ B:\", f\"提案{len(planB)} / 書込{wB} / スキップ{sB} -> {OUT_QUARTER_B}\")\n",
    "print(\"✅ C:\", f\"提案{len(planC)} / 書込{wC} / スキップ{sC} -> {OUT_QUARTER_C}\")\n",
    "print(\"✅ 分析:\", OUT_ANALYSIS)\n",
    "print(\"✅ 豪雪例外:\", SNOW_EXCEPT_XLSX)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QL_UBneKS4t6",
    "outputId": "fdbd0bd7-301d-453f-fcc6-ddaf39c45176"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 空欄(AJヘッダ)数: 137\n",
      "✅ A: 提案137 / 書込137 / スキップ0 -> SA+AJ+共有用_四半期表20240303_43期提案A_集客率考慮_理由BT書込.xlsx\n",
      "✅ B: 提案137 / 書込137 / スキップ0 -> SA+AJ+共有用_四半期表20240303_43期提案B_集客率考慮_理由BT書込.xlsx\n",
      "✅ C: 提案137 / 書込137 / スキップ0 -> SA+AJ+共有用_四半期表20240303_43期提案C_集客率考慮_理由BT書込.xlsx\n",
      "✅ 分析: 43期_MVP_提案スケジュール案_ABC_集客率_理由BT.xlsx\n",
      "✅ 豪雪例外: 豪雪例外リスト.xlsx\n"
     ]
    }
   ]
  }
 ]
}