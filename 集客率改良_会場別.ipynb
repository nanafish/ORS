{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集客率改良（会場別・作り直し版）\n",
    "\n",
    "このノートブックは `AJ-*.csv` を **1ファイル=1会場** として個別集計します。\n",
    "\n",
    "- 会場ごとに市区町村別の来場者数・集客率を算出\n",
    "- 会場ごとの地図（HTML）を出力\n",
    "- すべての会場の集客率統計量（平均/中央値/四分位など）を算出\n",
    "\n",
    "> 重要: 市区町村列がないAJファイルでも、`郵便番号` があれば `utf_ken_all.csv` から補完します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab想定（ローカルなら必要に応じてコメントアウト）\n",
    "!pip -q install pandas numpy openpyxl folium chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import chardet\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 設定 =====\n",
    "VISITOR_GLOB = \"AJ-*.csv\"\n",
    "KEN_ALL_CSV = \"utf_ken_all.csv\"  # 郵便番号→市区町村の補完に使用\n",
    "POP_XLSX = \"【総計】市区町村別年齢階級別人口(2025.8).xlsx\"\n",
    "POP_SHEET = 0\n",
    "GEOJSON_PATH = \"N03-20240101.geojson\"\n",
    "OUT_DIR = Path(\"out_venue\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# AJ側の列候補\n",
    "MUNI_COL_CANDIDATES = [\"市区町村\", \"居住地_市区町村\", \"住所_市区町村\", \"市区町村名\"]\n",
    "ZIP_COL_CANDIDATES = [\"郵便番号\", \"郵便\", \"zip\", \"Zip\", \"ZIP\"]\n",
    "\n",
    "# 人口側の列候補（見つからなければ自動推定）\n",
    "POP_MUNI_COL_CANDIDATES = [\"市区町村\", \"市区町村名\", \"自治体名\"]\n",
    "POP_TOTAL_COL_CANDIDATES = [\"総数\", \"人口\", \"総人口\", \"人口計\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(path, nbytes=200_000):\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(nbytes)\n",
    "    return chardet.detect(raw).get(\"encoding\") or \"utf-8\"\n",
    "\n",
    "\n",
    "def read_csv_flex(path):\n",
    "    tried = []\n",
    "    for enc in [detect_encoding(path), \"cp932\", \"shift_jis\", \"utf-8-sig\", \"utf-8\"]:\n",
    "        if enc in tried:\n",
    "            continue\n",
    "        tried.append(enc)\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def first_existing_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def first_keyword_col(df, include_keywords, exclude_keywords=None):\n",
    "    exclude_keywords = exclude_keywords or []\n",
    "    for c in df.columns:\n",
    "        cs = str(c)\n",
    "        if all(k in cs for k in include_keywords) and not any(x in cs for x in exclude_keywords):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_muni_name(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.strip()\n",
    "         .str.replace(r\"\\s+\", \"\", regex=True)\n",
    "         .str.replace(\"ヶ\", \"ケ\")\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_zip(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.replace(r\"[^0-9]\", \"\", regex=True)\n",
    "         .str.zfill(7)\n",
    "         .str[:7]\n",
    "    )\n",
    "\n",
    "\n",
    "def to_numeric_soft(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \"\", regex=False), errors=\"coerce\")\n",
    "\n",
    "\n",
    "def extract_venue_name(file_path: str) -> str:\n",
    "    m = re.match(r\"AJ-(.*)\\.csv$\", Path(file_path).name)\n",
    "    return m.group(1) if m else Path(file_path).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_zip_to_muni_map(ken_all_csv: str):\n",
    "    ken = pd.read_csv(ken_all_csv, header=None, dtype=str, encoding=\"utf-8-sig\")\n",
    "    zip_s = normalize_zip(ken.iloc[:, 2])\n",
    "    muni = normalize_muni_name(ken.iloc[:, 6].fillna(\"\") + ken.iloc[:, 7].fillna(\"\"))\n",
    "    m = pd.DataFrame({\"zip\": zip_s, \"市区町村\": muni})\n",
    "    m = m[(m[\"zip\"].str.len() == 7) & (m[\"市区町村\"] != \"\")]\n",
    "    return dict(zip(m[\"zip\"], m[\"市区町村\"]))\n",
    "\n",
    "\n",
    "def load_population_df(path, sheet=0):\n",
    "    header_candidates = [0, 1, 2, 3]\n",
    "    tried_meta = []\n",
    "\n",
    "    for h in header_candidates:\n",
    "        try:\n",
    "            pop = pd.read_excel(path, sheet_name=sheet, header=h)\n",
    "        except Exception as e:\n",
    "            tried_meta.append({\"header\": h, \"error\": str(e)})\n",
    "            continue\n",
    "\n",
    "        pop.columns = [str(c).strip() for c in pop.columns]\n",
    "\n",
    "        muni_col = first_existing_col(pop, POP_MUNI_COL_CANDIDATES)\n",
    "        total_col = first_existing_col(pop, POP_TOTAL_COL_CANDIDATES)\n",
    "\n",
    "        if muni_col is None:\n",
    "            muni_col = first_keyword_col(pop, [\"市区町村\"], exclude_keywords=[\"コード\"])\n",
    "\n",
    "        if total_col is None:\n",
    "            total_col = (\n",
    "                first_keyword_col(pop, [\"総人口\"]) or\n",
    "                first_keyword_col(pop, [\"人口\", \"総数\"]) or\n",
    "                first_keyword_col(pop, [\"人口計\"]) or\n",
    "                first_keyword_col(pop, [\"人口\"], exclude_keywords=[\"率\", \"コード\"])\n",
    "            )\n",
    "\n",
    "        if muni_col is None:\n",
    "            object_cols = [c for c in pop.columns if pop[c].dtype == \"object\"]\n",
    "            muni_col = object_cols[0] if object_cols else pop.columns[0]\n",
    "\n",
    "        if total_col is None:\n",
    "            best_col, best_score = None, -1\n",
    "            for c in pop.columns:\n",
    "                if c == muni_col:\n",
    "                    continue\n",
    "                score = to_numeric_soft(pop[c]).notna().sum()\n",
    "                if score > best_score:\n",
    "                    best_col, best_score = c, score\n",
    "            total_col = best_col\n",
    "\n",
    "        if total_col is None:\n",
    "            tried_meta.append({\"header\": h, \"columns\": list(pop.columns), \"reason\": \"total_col_not_found\"})\n",
    "            continue\n",
    "\n",
    "        out = pop[[muni_col, total_col]].copy()\n",
    "        out.columns = [\"市区町村\", \"人口\"]\n",
    "        out[\"市区町村\"] = normalize_muni_name(out[\"市区町村\"])\n",
    "        out[\"人口\"] = to_numeric_soft(out[\"人口\"])\n",
    "        out = out.dropna(subset=[\"市区町村\", \"人口\"])\n",
    "        out = out[out[\"市区町村\"] != \"\"]\n",
    "\n",
    "        if len(out) > 0:\n",
    "            return out.groupby(\"市区町村\", as_index=False)[\"人口\"].sum(), {\n",
    "                \"header\": h,\n",
    "                \"muni_col\": muni_col,\n",
    "                \"pop_col\": total_col,\n",
    "            }\n",
    "\n",
    "        tried_meta.append({\"header\": h, \"columns\": list(pop.columns), \"reason\": \"empty_after_clean\"})\n",
    "\n",
    "    raise KeyError(f\"人口データの列自動判定に失敗: {tried_meta[:3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 集計実行 =====\n",
    "pop_df, pop_meta = load_population_df(POP_XLSX, sheet=POP_SHEET)\n",
    "print(f\"人口列判定: header={pop_meta['header']} / muni={pop_meta['muni_col']} / pop={pop_meta['pop_col']}\")\n",
    "\n",
    "zip_to_muni = build_zip_to_muni_map(KEN_ALL_CSV)\n",
    "csv_paths = sorted(glob.glob(VISITOR_GLOB))\n",
    "if not csv_paths:\n",
    "    raise FileNotFoundError(f\"{VISITOR_GLOB} が見つかりません\")\n",
    "\n",
    "records = []\n",
    "venue_detail_tables = {}\n",
    "\n",
    "for p in csv_paths:\n",
    "    venue = extract_venue_name(p)\n",
    "    df = read_csv_flex(p)\n",
    "\n",
    "    muni_col = first_existing_col(df, MUNI_COL_CANDIDATES)\n",
    "    zip_col = first_existing_col(df, ZIP_COL_CANDIDATES)\n",
    "\n",
    "    if muni_col:\n",
    "        tmp = pd.DataFrame({\"市区町村\": normalize_muni_name(df[muni_col])})\n",
    "    elif zip_col:\n",
    "        z = normalize_zip(df[zip_col])\n",
    "        tmp = pd.DataFrame({\"市区町村\": z.map(zip_to_muni)})\n",
    "    else:\n",
    "        raise KeyError(f\"{Path(p).name}: 市区町村列も郵便番号列もありません。columns={list(df.columns)[:30]}\")\n",
    "\n",
    "    tmp = tmp[tmp[\"市区町村\"].notna() & (tmp[\"市区町村\"] != \"\")]\n",
    "    visitors = tmp.groupby(\"市区町村\", as_index=False).size().rename(columns={\"size\": \"来場者数\"})\n",
    "\n",
    "    merged = visitors.merge(pop_df, on=\"市区町村\", how=\"left\")\n",
    "    merged[\"集客率(%)\"] = (merged[\"来場者数\"] / merged[\"人口\"]) * 100\n",
    "    merged[\"集客率(1万人あたり)\"] = (merged[\"来場者数\"] / merged[\"人口\"]) * 10000\n",
    "    merged = merged.sort_values(\"集客率(1万人あたり)\", ascending=False)\n",
    "\n",
    "    venue_detail_tables[venue] = merged\n",
    "\n",
    "    valid = merged[\"集客率(1万人あたり)\"].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    records.append({\n",
    "        \"会場\": venue,\n",
    "        \"対象CSV\": Path(p).name,\n",
    "        \"市区町村数\": int(len(merged)),\n",
    "        \"総来場者数\": int(merged[\"来場者数\"].sum()),\n",
    "        \"平均集客率(1万人あたり)\": float(valid.mean()) if len(valid) else np.nan,\n",
    "        \"中央値集客率(1万人あたり)\": float(valid.median()) if len(valid) else np.nan,\n",
    "        \"最大集客率(1万人あたり)\": float(valid.max()) if len(valid) else np.nan,\n",
    "        \"最小集客率(1万人あたり)\": float(valid.min()) if len(valid) else np.nan,\n",
    "    })\n",
    "\n",
    "venue_summary = pd.DataFrame(records).sort_values(\"会場\")\n",
    "venue_summary.to_csv(OUT_DIR / \"会場別サマリー.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "with pd.ExcelWriter(OUT_DIR / \"会場別_市区町村明細.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    for venue, table in venue_detail_tables.items():\n",
    "        table.to_excel(writer, index=False, sheet_name=(venue[:31] if venue else \"venue\"))\n",
    "\n",
    "base = venue_summary[\"平均集客率(1万人あたり)\"]\n",
    "stats_df = pd.DataFrame([{\n",
    "    \"会場数\": int(len(base)),\n",
    "    \"平均\": float(base.mean()),\n",
    "    \"中央値\": float(base.median()),\n",
    "    \"標準偏差\": float(base.std(ddof=1)),\n",
    "    \"最小\": float(base.min()),\n",
    "    \"最大\": float(base.max()),\n",
    "    \"25%点\": float(base.quantile(0.25)),\n",
    "    \"75%点\": float(base.quantile(0.75)),\n",
    "}])\n",
    "stats_df.to_csv(OUT_DIR / \"全会場_統計量.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "venue_summary.head(), stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 会場別マップ出力 =====\n",
    "with open(GEOJSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    gj = json.load(f)\n",
    "\n",
    "prop_candidates = [\"N03_004\", \"市区町村\", \"name\", \"NAME\"]\n",
    "\n",
    "def geojson_muni_name(feat):\n",
    "    props = feat.get(\"properties\", {})\n",
    "    for c in prop_candidates:\n",
    "        if c in props and props[c]:\n",
    "            return str(props[c])\n",
    "    return None\n",
    "\n",
    "for venue, detail in venue_detail_tables.items():\n",
    "    rate_map = dict(zip(detail[\"市区町村\"], detail[\"集客率(1万人あたり)\"]))\n",
    "    m = folium.Map(location=[35.68, 139.76], zoom_start=5, tiles=\"cartodbpositron\")\n",
    "\n",
    "    vals = pd.Series(list(rate_map.values())).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    vmin, vmax = (vals.min(), vals.max()) if len(vals) else (0, 1)\n",
    "    span = (vmax - vmin) if vmax > vmin else 1.0\n",
    "\n",
    "    def style_fn(feature):\n",
    "        muni = normalize_muni_name(pd.Series([geojson_muni_name(feature)])).iloc[0]\n",
    "        v = rate_map.get(muni, np.nan)\n",
    "        if pd.isna(v):\n",
    "            return {\"fillColor\": \"#dddddd\", \"color\": \"#999999\", \"weight\": 0.4, \"fillOpacity\": 0.2}\n",
    "        t = (v - vmin) / span\n",
    "        color = f\"#{int(255*t):02x}40{int(255*(1-t)):02x}\"\n",
    "        return {\"fillColor\": color, \"color\": \"#666666\", \"weight\": 0.4, \"fillOpacity\": 0.7}\n",
    "\n",
    "    folium.GeoJson(gj, style_function=style_fn).add_to(m)\n",
    "    m.save(OUT_DIR / f\"map_{venue}.html\")\n",
    "\n",
    "print(f\"出力完了: {OUT_DIR.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}