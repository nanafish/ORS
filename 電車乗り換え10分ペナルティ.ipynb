{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2KPL8LWlbyKcrid69gWcK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanafish/ORS/blob/main/%E9%9B%BB%E8%BB%8A%E4%B9%97%E3%82%8A%E6%8F%9B%E3%81%8810%E5%88%86%E3%83%9A%E3%83%8A%E3%83%AB%E3%83%86%E3%82%A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1セル：0.5km内“出発駅群”→30分圏（common/union）+ 行政名付与（縮小なし＆sjoin衝突修正）=====\n",
        "!pip -q install geopandas shapely pyproj fiona\n",
        "\n",
        "import os, math, csv, unicodedata, difflib, numpy as np, pandas as pd, geopandas as gpd, logging\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# ---------- 基本 ----------\n",
        "os.environ[\"SHAPE_ENCODING\"] = \"CP932\"\n",
        "logging.getLogger(\"fiona\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"fiona.ogrext\").setLevel(logging.ERROR)\n",
        "def nrm(s): return unicodedata.normalize(\"NFKC\", str(s)).strip()\n",
        "\n",
        "# ---------- 入力 ----------\n",
        "N02_BASE = \"/content/N02-23_Station\"\n",
        "S12_BASE = \"/content/S12-23_NumberOfPassengers\"\n",
        "S12_GEOJSON = \"/content/S12-23_NumberOfPassengers.geojson\"\n",
        "N03_CANDIDATES = [\n",
        "    \"/content/N03-20250101_15.geojson\",\n",
        "    \"/content/N03-20240101.geojson\",\n",
        "    \"/content/N03-20240101_15.geojson\",\n",
        "    \"/content/N03-20240101.gpkg\",\n",
        "]\n",
        "NAME_FIELD_OVERRIDE_N02 = \"N02_駅名\"\n",
        "\n",
        "# ---------- パラメータ（縮小なし） ----------\n",
        "RADIUS_KM_FOR_MULTI_ORIGINS = 0.5\n",
        "BAND_MIN = 30\n",
        "BAND_SPEED_KMH = 32.0\n",
        "SHRINK_RATIO   = 1.00\n",
        "NEAREST_JOIN_M = 300\n",
        "\n",
        "# ---------- 距離/時間 ----------\n",
        "def hav_km(a_lat,a_lon,b_lat,b_lon):\n",
        "    R=6371.0088\n",
        "    A=math.radians(a_lat); B=math.radians(b_lat)\n",
        "    dlat=math.radians(b_lat-a_lat); dlon=math.radians(b_lon-a_lon)\n",
        "    h=math.sin(dlat/2)**2 + math.cos(A)*math.cos(B)*math.sin(dlon/2)**2\n",
        "    return 2*R*math.asin(math.sqrt(h))\n",
        "\n",
        "def band_max_km(minutes=BAND_MIN):\n",
        "    return BAND_SPEED_KMH * minutes / 60.0 * SHRINK_RATIO\n",
        "\n",
        "# ---------- N02（駅） ----------\n",
        "for ext in [\".shp\",\".shx\",\".dbf\"]:\n",
        "    if not os.path.exists(N02_BASE+ext):\n",
        "        raise FileNotFoundError(f\"N02が不足: {N02_BASE+ext}\")\n",
        "\n",
        "try: g = gpd.read_file(N02_BASE + \".shp\")\n",
        "except Exception: g = gpd.read_file(N02_BASE + \".shp\", encoding=\"cp932\")\n",
        "if g.crs is None: g.set_crs(4326, inplace=True)\n",
        "try: g = g.to_crs(4326)\n",
        "except: pass\n",
        "\n",
        "g = g[g.geometry.notnull() & (~g.geometry.is_empty)].copy()\n",
        "if (g.geom_type == \"MultiPoint\").any():\n",
        "    g = g.explode(index_parts=False).reset_index(drop=True)\n",
        "if not (g.geom_type == \"Point\").all():\n",
        "    W = g.to_crs(3857); W[\"geometry\"] = W.geometry.representative_point(); g = W.to_crs(4326)\n",
        "\n",
        "def pick_name_col(df):\n",
        "    if NAME_FIELD_OVERRIDE_N02 and NAME_FIELD_OVERRIDE_N02 in df.columns: return NAME_FIELD_OVERRIDE_N02\n",
        "    cand = [c for c in df.columns if (\"駅\" in str(c)) and pd.api.types.is_string_dtype(df[c])]\n",
        "    if cand: return cand[0]\n",
        "    best,score=None,-1\n",
        "    for c in df.columns:\n",
        "        if not pd.api.types.is_string_dtype(df[c]): continue\n",
        "        s = df[c].astype(str).fillna(\"\")\n",
        "        sc = s.str.contains(\"駅\", na=False).mean() \\\n",
        "             - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
        "             - s.str.fullmatch(r\"\\d+\").fillna(False).mean()*0.5\n",
        "        if sc>score: best,score=c,sc\n",
        "    return best\n",
        "\n",
        "def pick_line_col(df):\n",
        "    for c in [\"N02_路線名\",\"路線名\",\"路線\",\"Line\",\"LINE\"]:\n",
        "        if c in df.columns and pd.api.types.is_string_dtype(df[c]): return c\n",
        "    best,score=None,-1\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_string_dtype(df[c]):\n",
        "            s=df[c].astype(str)\n",
        "            sc=(s.str.contains(\"線\", na=False).mean())+(s.str.len().mean()>1)*0.1\n",
        "            if sc>score: best,score=c,sc\n",
        "    return best\n",
        "\n",
        "def to_lines(val):\n",
        "    if not isinstance(val,str): return set()\n",
        "    for z in [\"／\",\"、\",\"・\",\";\",\"；\",\"/\",\"|\",\",\"]: val = val.replace(z,\" \")\n",
        "    toks=[t.strip() for t in val.split() if t.strip()]\n",
        "    return set([t for t in toks if \"線\" in t])\n",
        "\n",
        "name_col = pick_name_col(g)\n",
        "line_col = pick_line_col(g)\n",
        "if not name_col:\n",
        "    raise RuntimeError(f\"駅名列が特定できません。列例: {list(g.columns)[:12]} ...\")\n",
        "\n",
        "g[\"Name\"] = g[name_col].astype(str).map(nrm)\n",
        "g[\"LineSet\"] = g[line_col].astype(str).map(to_lines) if line_col else [set()]*len(g)\n",
        "g[\"Latitude\"]  = g.geometry.y\n",
        "g[\"Longitude\"] = g.geometry.x\n",
        "\n",
        "tmp = g[[\"Name\",\"Latitude\",\"Longitude\",\"LineSet\"]].copy()\n",
        "tmp[\"LineSetFS\"] = tmp[\"LineSet\"].apply(lambda s: frozenset(s) if isinstance(s, set) else frozenset())\n",
        "st_pts = (\n",
        "    tmp.dropna(subset=[\"Latitude\",\"Longitude\"])\n",
        "       .drop_duplicates(subset=[\"Name\",\"Latitude\",\"Longitude\",\"LineSetFS\"])\n",
        "       .drop(columns=[\"LineSetFS\"])\n",
        "       .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "names_unique = (\n",
        "    st_pts.groupby(\"Name\", as_index=False)[[\"Latitude\",\"Longitude\"]]\n",
        "          .agg({\"Latitude\":\"mean\",\"Longitude\":\"mean\"})\n",
        ")\n",
        "\n",
        "def choose_origin(df_names, q):\n",
        "    qn=nrm(q); base=qn.replace(\"駅\",\"\")\n",
        "    hit = df_names[df_names[\"Name\"]==qn]\n",
        "    if hit.empty: hit = df_names[df_names[\"Name\"].str.replace(\"駅\",\"\",regex=False)==base]\n",
        "    if not hit.empty: return hit.iloc[0]\n",
        "    part = df_names[df_names[\"Name\"].str.contains(base, na=False)]\n",
        "    if part.empty:\n",
        "        names = df_names[\"Name\"].tolist()\n",
        "        scored = [(difflib.SequenceMatcher(None, qn, n).ratio(), n) for n in names]\n",
        "        scored.sort(reverse=True)\n",
        "        cand = df_names[df_names[\"Name\"].isin([n for _,n in scored[:20]])]\n",
        "    else:\n",
        "        cand = part.copy()\n",
        "    print(\"\\n候補（番号選択、Enter=1）:\")\n",
        "    cand = cand.assign(_sim=cand[\"Name\"].apply(lambda n: difflib.SequenceMatcher(None, qn, n).ratio())) \\\n",
        "               .sort_values([\"_sim\",\"Name\"], ascending=[False,True]).head(20).reset_index(drop=True)\n",
        "    for i, r in cand.iterrows():\n",
        "        print(f\"{i+1:2d}: {r['Name']} ({r['Latitude']:.5f},{r['Longitude']:.5f})\")\n",
        "    sel=input(\"番号: \").strip(); idx = 0\n",
        "    if sel.isdigit():\n",
        "        v=int(sel);\n",
        "        if 1<=v<=len(cand): idx=v-1\n",
        "    return cand.iloc[idx]\n",
        "\n",
        "# ---------- S12（乗降人員） ----------\n",
        "def load_s12():\n",
        "    old = gpd.options.io_engine; gpd.options.io_engine = \"fiona\"\n",
        "    try:\n",
        "        if os.path.exists(S12_GEOJSON):\n",
        "            s = gpd.read_file(S12_GEOJSON)\n",
        "        elif all(os.path.exists(S12_BASE+e) for e in [\".shp\",\".shx\",\".dbf\"]):\n",
        "            try: s = gpd.read_file(S12_BASE + \".shp\", encoding=\"cp932\")\n",
        "            except UnicodeDecodeError: s = gpd.read_file(S12_BASE + \".shp\", encoding=\"shift_jis\")\n",
        "        else:\n",
        "            return None\n",
        "    finally:\n",
        "        gpd.options.io_engine = old\n",
        "    if s.crs is None: s.set_crs(4326, inplace=True)\n",
        "    try: s = s.to_crs(4326)\n",
        "    except: pass\n",
        "    s = s[s.geometry.notnull() & (~s.geometry.is_empty)].copy()\n",
        "    if (s.geom_type == \"MultiPoint\").any():\n",
        "        s = s.explode(index_parts=False).reset_index(drop=True)\n",
        "    if not (s.geom_type == \"Point\").all():\n",
        "        W = s.to_crs(3857); W[\"geometry\"]=W.geometry.representative_point(); s=W.to_crs(4326)\n",
        "    return s\n",
        "\n",
        "s12 = load_s12()\n",
        "pass_map = {}\n",
        "if s12 is not None and not s12.empty:\n",
        "    name_cands = [c for c in s12.columns if (\"駅\" in str(c)) and pd.api.types.is_string_dtype(s12[c])] \\\n",
        "                 or [c for c in s12.columns if pd.api.types.is_string_dtype(s12[c])]\n",
        "    pnum_cands = [c for c in s12.columns if pd.api.types.is_numeric_dtype(s12[c])]\n",
        "    s12[\"__name__\"] = s12[name_cands[0]].astype(str).map(nrm) if name_cands else \"\"\n",
        "    best_pcol, best_score = None, -1\n",
        "    for c in pnum_cands:\n",
        "        ser = s12[c]; mv = ser.replace([np.inf,-np.inf], np.nan).dropna().mean()\n",
        "        zr = (ser==0).mean()\n",
        "        sc = float(mv)*(1.0-float(zr))\n",
        "        if sc>best_score: best_pcol, best_score = c, sc\n",
        "    try:\n",
        "        st_g = gpd.GeoDataFrame(st_pts, geometry=gpd.points_from_xy(st_pts[\"Longitude\"], st_pts[\"Latitude\"]), crs=4326).to_crs(3857)\n",
        "        s12m = s12.to_crs(3857)\n",
        "        joined = gpd.sjoin_nearest(st_g, s12m, how=\"left\", max_distance=NEAREST_JOIN_M, lsuffix=\"L\", rsuffix=\"R\")\n",
        "        if best_pcol:\n",
        "            tmp = joined[[\"Name\", best_pcol]].dropna()\n",
        "            pass_map.update(tmp.groupby(\"Name\")[best_pcol].max().to_dict())\n",
        "    except Exception:\n",
        "        pass\n",
        "    if name_cands and best_pcol:\n",
        "        sdict = s12.set_index(\"__name__\")[best_pcol].to_dict()\n",
        "        for nm in st_pts[\"Name\"].unique():\n",
        "            if nm not in pass_map:\n",
        "                v = sdict.get(nm) or sdict.get(nm.replace(\"駅\",\"\"))\n",
        "                if v is not None: pass_map[nm] = v\n",
        "\n",
        "def passengers_label(name):\n",
        "    v = pass_map.get(name) or pass_map.get(name.replace(\"駅\",\"\"))\n",
        "    if v is None: return None\n",
        "    try: return f\"{int(round(float(v))):,}人/日\"\n",
        "    except: return str(v)\n",
        "\n",
        "# ---------- 起点 ----------\n",
        "print(\"（例）座標OK：35.733, 139.710（池袋付近）\")\n",
        "q = input(\"出発駅名 or 'lat,lon'：\").strip()\n",
        "\n",
        "if \",\" in q:\n",
        "    lat0, lon0 = [float(v) for v in q.split(\",\",1)]\n",
        "    origin_name = \"(座標指定)\"\n",
        "else:\n",
        "    chosen = choose_origin(names_unique, q)\n",
        "    origin_name = chosen[\"Name\"]\n",
        "    lat0, lon0 = float(chosen[\"Latitude\"]), float(chosen[\"Longitude\"])\n",
        "\n",
        "print(f\"\\n中心: {origin_name} ({lat0:.6f}, {lon0:.6f})\")\n",
        "\n",
        "# ---------- 0.5km内の“出発駅群” ----------\n",
        "start_mask = st_pts.apply(lambda r: hav_km(lat0, lon0, r[\"Latitude\"], r[\"Longitude\"]) <= RADIUS_KM_FOR_MULTI_ORIGINS, axis=1)\n",
        "starts = st_pts[start_mask].reset_index(drop=True)\n",
        "if starts.empty:\n",
        "    d2 = (st_pts[\"Latitude\"]-lat0)**2 + (st_pts[\"Longitude\"]-lon0)**2\n",
        "    starts = st_pts.loc[[int(d2.idxmin())]].reset_index(drop=True)\n",
        "\n",
        "print(\"出発駅群（0.5km以内）:\")\n",
        "for _, row in starts.iterrows():\n",
        "    print(\" -\", row[\"Name\"], f\"({row['Latitude']:.5f},{row['Longitude']:.5f})\")\n",
        "\n",
        "# ---------- 30分圏：各出発駅から到達可能（直線近似 + 別路線ペナルティ+10分） ----------\n",
        "R30 = band_max_km(BAND_MIN)\n",
        "\n",
        "def adj_time_min_from_any_origin(target_row) -> float:\n",
        "    \"\"\"\n",
        "    出発駅群のいずれかから target_row へ行く時の最小“調整後時間（分）”を返す。\n",
        "    - 直線ベースの所要時間\n",
        "    - origin と target の LineSet が交わらなければ +10 分を加算\n",
        "    \"\"\"\n",
        "    best = float(\"inf\")\n",
        "    t_lat, t_lon = float(target_row[\"Latitude\"]), float(target_row[\"Longitude\"])\n",
        "    t_lines = target_row[\"LineSet\"] if isinstance(target_row[\"LineSet\"], set) else set()\n",
        "    for _, o in starts.iterrows():\n",
        "        olat, olon = float(o[\"Latitude\"]), float(o[\"Longitude\"])\n",
        "        km = hav_km(olat, olon, t_lat, t_lon)\n",
        "        base_min = km / BAND_SPEED_KMH * 60.0\n",
        "        o_lines = o[\"LineSet\"] if isinstance(o[\"LineSet\"], set) else set()\n",
        "        share = (o_lines and t_lines and (not o_lines.isdisjoint(t_lines)))\n",
        "        tmin = base_min if share else (base_min + 10.0)   # ←別路線なら +10 分\n",
        "        if tmin < best:\n",
        "            best = tmin\n",
        "    return best\n",
        "\n",
        "# 各出発駅ごとに「到達可能インデックス」を作るのではなく、\n",
        "# “調整後時間 <= 30” の駅集合を直接求める\n",
        "reachable_idx = set()\n",
        "for i, r in st_pts.iterrows():\n",
        "    # 自駅（完全同一座標の同一レコード）はスキップ\n",
        "    if ((r[\"Name\"] in set(starts[\"Name\"])) and\n",
        "        any(abs(r[\"Latitude\"]-o[\"Latitude\"])<1e-10 and abs(r[\"Longitude\"]-o[\"Longitude\"])<1e-10 for _, o in starts.iterrows())):\n",
        "        continue\n",
        "    tmin = adj_time_min_from_any_origin(r)\n",
        "    if tmin <= BAND_MIN:\n",
        "        reachable_idx.add(i)\n",
        "\n",
        "# “common/union”を維持したい場合：\n",
        "#   - union は reachable_idx そのもの\n",
        "#   - common は「全ての出発駅から tmin<=BAND_MIN になるもの」のみ\n",
        "# ただし +10 分ペナルティ込みで確認\n",
        "common_idx = set()\n",
        "for i in reachable_idx:\n",
        "    r = st_pts.iloc[i]\n",
        "    ok_all = True\n",
        "    for _, o in starts.iterrows():\n",
        "        olat, olon = float(o[\"Latitude\"]), float(o[\"Longitude\"])\n",
        "        km = hav_km(olat, olon, float(r[\"Latitude\"]), float(r[\"Longitude\"]))\n",
        "        base_min = km / BAND_SPEED_KMH * 60.0\n",
        "        o_lines = o[\"LineSet\"] if isinstance(o[\"LineSet\"], set) else set()\n",
        "        r_lines = r[\"LineSet\"] if isinstance(r[\"LineSet\"], set) else set()\n",
        "        share = (o_lines and r_lines and (not o_lines.isdisjoint(r_lines)))\n",
        "        tmin = base_min if share else (base_min + 10.0)\n",
        "        if tmin > BAND_MIN:\n",
        "            ok_all = False; break\n",
        "    if ok_all:\n",
        "        common_idx.add(i)\n",
        "\n",
        "union_idx = reachable_idx\n",
        "\n",
        "\n",
        "# ---------- 行政界ロード ----------\n",
        "N03_PATH = next((p for p in N03_CANDIDATES if os.path.exists(p)), None)\n",
        "admin = None\n",
        "if N03_PATH:\n",
        "    try:\n",
        "        admin = gpd.read_file(N03_PATH)\n",
        "        if admin.crs is None: admin.set_crs(4326, inplace=True)\n",
        "        else: admin = admin.to_crs(4326)\n",
        "        admin = admin[admin.geometry.notnull() & (~admin.geometry.is_empty)].copy()\n",
        "    except Exception as e:\n",
        "        print(\"N03読込に失敗:\", e)\n",
        "        admin = None\n",
        "\n",
        "# === 差し替えセル：行政名付与（index衝突を完全回避する安全版） ===\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "def _drop_indexish_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"sjoin/sjoin_nearest が作る or 衝突しうる列を事前に除去\"\"\"\n",
        "    drop_like = {\"index\", \"index_left\", \"index_right\", \"index_R\", \"index_L\", \"index__adm\"}\n",
        "    cols = [c for c in df.columns if c in drop_like or c.startswith(\"index_\")]\n",
        "    return df.drop(columns=cols, errors=\"ignore\")\n",
        "\n",
        "def attach_admin(gdf_pts4326: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
        "    \"\"\"\n",
        "    within → 最近傍2km → 最近傍10km の順で行政名を付与。\n",
        "    sjoinの 'index_*' 衝突を“事前削除 + 一意suffix”で確実に回避。\n",
        "    \"\"\"\n",
        "    gdf = gdf_pts4326.copy()\n",
        "    gdf = _drop_indexish_cols(gdf)\n",
        "    gdf = gdf.rename_axis(None)              # index名も消しておく\n",
        "\n",
        "    # admin は外側スコープの行政界 GeoDataFrame を想定\n",
        "    global admin\n",
        "    if admin is None or admin.empty:\n",
        "        gdf[\"Pref\"] = \"不明\"; gdf[\"City\"] = \"不明\"\n",
        "        return gdf\n",
        "\n",
        "    adm = _drop_indexish_cols(admin.copy())\n",
        "    adm = adm.rename_axis(None)\n",
        "\n",
        "    # 列名の推定\n",
        "    pref_col = next((c for c in adm.columns if str(c).startswith(\"N03_001\")), None)\n",
        "    city_col = next((c for c in adm.columns if str(c).startswith(\"N03_004\")), None)\n",
        "    if pref_col is None or city_col is None:\n",
        "        str_cols = [c for c in adm.columns if pd.api.types.is_string_dtype(adm[c])]\n",
        "        pref_col = pref_col or (str_cols[0] if str_cols else None)\n",
        "        city_col = city_col or (str_cols[1] if len(str_cols) > 1 else pref_col)\n",
        "\n",
        "    # 1) within\n",
        "    joined = gpd.sjoin(\n",
        "        gdf, adm, how=\"left\", predicate=\"within\",\n",
        "        lsuffix=\"\", rsuffix=\"_adm\"          # “index_adm” を作らせない（index名はNone）\n",
        "    )\n",
        "    joined[\"Pref\"] = joined.get(pref_col, None)\n",
        "    joined[\"City\"] = joined.get(city_col, None)\n",
        "\n",
        "    # 欠損のみ対象を抽出（以後も常に衝突列を除去）\n",
        "    miss = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss.empty:\n",
        "        adm_3857 = adm.to_crs(3857)\n",
        "        miss_3857 = _drop_indexish_cols(miss.to_crs(3857))\n",
        "        nn2 = gpd.sjoin_nearest(\n",
        "            miss_3857, adm_3857, how=\"left\", max_distance=2000,\n",
        "            lsuffix=\"\", rsuffix=\"_adm\"\n",
        "        )\n",
        "        if pref_col in nn2.columns: joined.loc[miss.index, \"Pref\"] = nn2[pref_col].values\n",
        "        if city_col in nn2.columns: joined.loc[miss.index, \"City\"] = nn2[city_col].values\n",
        "\n",
        "    miss2 = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss2.empty:\n",
        "        adm_3857 = adm.to_crs(3857)\n",
        "        miss2_3857 = _drop_indexish_cols(miss2.to_crs(3857))\n",
        "        nn10 = gpd.sjoin_nearest(\n",
        "            miss2_3857, adm_3857, how=\"left\", max_distance=10000,\n",
        "            lsuffix=\"\", rsuffix=\"_adm\"\n",
        "        )\n",
        "        if pref_col in nn10.columns: joined.loc[miss2.index, \"Pref\"] = nn10[pref_col].values\n",
        "        if city_col in nn10.columns: joined.loc[miss2.index, \"City\"] = nn10[city_col].values\n",
        "\n",
        "    joined[\"Pref\"] = joined[\"Pref\"].fillna(\"不明\")\n",
        "    joined[\"City\"] = joined[\"City\"].fillna(\"不明\")\n",
        "    # 最後に衝突し得る列を掃除\n",
        "    joined = _drop_indexish_cols(joined)\n",
        "    return joined\n",
        "\n",
        "\n",
        "    # 列名推定\n",
        "    pref_col = next((c for c in adm.columns if str(c).startswith(\"N03_001\")), None)\n",
        "    city_col = next((c for c in adm.columns if str(c).startswith(\"N03_004\")), None)\n",
        "    if pref_col is None or city_col is None:\n",
        "        str_cols = [c for c in adm.columns if pd.api.types.is_string_dtype(adm[c])]\n",
        "        pref_col = pref_col or (str_cols[0] if str_cols else None)\n",
        "        city_col = city_col or (str_cols[1] if len(str_cols)>1 else pref_col)\n",
        "\n",
        "    joined[\"Pref\"] = joined.get(pref_col, None)\n",
        "    joined[\"City\"] = joined.get(city_col, None)\n",
        "\n",
        "    # 2) 最近傍 2km\n",
        "    miss = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss.empty:\n",
        "        adm_3857 = adm.to_crs(3857)\n",
        "        miss_3857 = miss.to_crs(3857)\n",
        "        for c in [\"index_left\",\"index_right\"]:\n",
        "            if c in miss_3857.columns: miss_3857 = miss_3857.drop(columns=[c])\n",
        "        nn2 = gpd.sjoin_nearest(miss_3857, adm_3857, how=\"left\", max_distance=2000, lsuffix=\"L\", rsuffix=\"R\")\n",
        "        if pref_col in nn2.columns: joined.loc[miss.index, \"Pref\"] = nn2[pref_col].values\n",
        "        if city_col in nn2.columns: joined.loc[miss.index, \"City\"] = nn2[city_col].values\n",
        "\n",
        "    # 3) 最近傍 10km\n",
        "    miss2 = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss2.empty:\n",
        "        adm_3857 = adm.to_crs(3857)\n",
        "        miss2_3857 = miss2.to_crs(3857)\n",
        "        for c in [\"index_left\",\"index_right\"]:\n",
        "            if c in miss2_3857.columns: miss2_3857 = miss2_3857.drop(columns=[c])\n",
        "        nn10 = gpd.sjoin_nearest(miss2_3857, adm_3857, how=\"left\", max_distance=10000, lsuffix=\"L\", rsuffix=\"R\")\n",
        "        if pref_col in nn10.columns: joined.loc[miss2.index, \"Pref\"] = nn10[pref_col].values\n",
        "        if city_col in nn10.columns: joined.loc[miss2.index, \"City\"] = nn10[city_col].values\n",
        "\n",
        "    joined[\"Pref\"] = joined[\"Pref\"].fillna(\"不明\")\n",
        "    joined[\"City\"] = joined[\"City\"].fillna(\"不明\")\n",
        "    # 余分な index_* を除去\n",
        "    drop_cols = [c for c in joined.columns if c.startswith(\"index_\")]\n",
        "    return joined.drop(columns=drop_cols, errors=\"ignore\")\n",
        "\n",
        "# ---------- 出力レコード作成（調整後時間を保存） ----------\n",
        "rows = []\n",
        "\n",
        "def min_adjusted_time_for_row(r) -> float:\n",
        "    return adj_time_min_from_any_origin(r)\n",
        "\n",
        "def add_rows(idx_set, reach_type):\n",
        "    for i in sorted(idx_set):\n",
        "        r = st_pts.iloc[i]\n",
        "        tmin = min_adjusted_time_for_row(r)  # ← 別路線+10分込みの最短時間\n",
        "        lbl = r[\"Name\"]; ppl = passengers_label(r[\"Name\"])\n",
        "        if ppl: lbl = f\"{lbl}（{ppl}）\"\n",
        "        rows.append({\n",
        "            \"Name\": r[\"Name\"],\n",
        "            \"Latitude\": float(r[\"Latitude\"]),\n",
        "            \"Longitude\": float(r[\"Longitude\"]),\n",
        "            \"Time_min_est\": round(tmin, 1),     # 調整後時間\n",
        "            \"Band\": f\"<= {BAND_MIN}分\",\n",
        "            \"ReachType\": reach_type,            # 'common' or 'union'\n",
        "            \"Label\": lbl\n",
        "        })\n",
        "\n",
        "# common → union の順で追加\n",
        "add_rows(common_idx, \"common\")\n",
        "add_rows(union_idx - common_idx, \"union\")\n",
        "\n",
        "\n",
        "# ---------- CSV保存 ----------\n",
        "base_name = \"(座標指定)\" if origin_name == \"(座標指定)\" else origin_name.replace(\"/\", \"_\")\n",
        "out = f\"/content/{base_name}_multiStart_{BAND_MIN}min_admin.csv\"\n",
        "(gdf_out.drop(columns=\"geometry\").to_csv(out, index=False, encoding=\"utf-8-sig\"))\n",
        "\n",
        "# ---------- 結果 ----------\n",
        "cnt_total = len(gdf_out)\n",
        "cnt_none = (gdf_out[\"City\"]==\"不明\").sum()\n",
        "print(\"\\n出力:\", out, f\"件数:{cnt_total} / 出発点数:{len(starts)} / 0.5km内の乗換起点を全採用\")\n",
        "print(f\"30分圏 目安半径(km): {band_max_km():.2f}（速度{BAND_SPEED_KMH}km/h×縮小{SHRINK_RATIO}）\")\n",
        "print(f\"行政名欠損: {cnt_none}件（{100*cnt_none/max(cnt_total,1):.1f}%）  ※within→2km→10kmで補完\")\n",
        "print(\"My Maps：CSVインポート → スタイル: ReachType=カテゴリ（'common'と'union'） → ラベル: LabelFull\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luNafEADXcld",
        "outputId": "19a56c4a-0160-4da9-affd-8df960fd06b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-1176829184.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "（例）座標OK：35.733, 139.710（池袋付近）\n",
            "出発駅名 or 'lat,lon'：35.73154225476511, 139.71132989337033\n",
            "\n",
            "中心: (座標指定) (35.731542, 139.711330)\n",
            "出発駅群（0.5km以内）:\n",
            " - 池袋 (35.72749,139.71075)\n",
            " - 池袋 (35.73061,139.71034)\n",
            " - 池袋 (35.73178,139.70655)\n",
            " - 池袋 (35.72954,139.70980)\n",
            " - 池袋 (35.73152,139.71167)\n",
            " - 池袋 (35.73144,139.71197)\n",
            " - 池袋 (35.73099,139.71106)\n",
            "\n",
            "出力: /content/(座標指定)_multiStart_30min_admin.csv 件数:704 / 出発点数:7 / 0.5km内の乗換起点を全採用\n",
            "30分圏 目安半径(km): 16.00（速度32.0km/h×縮小1.0）\n",
            "行政名欠損: 1件（0.1%）  ※within→2km→10kmで補完\n",
            "My Maps：CSVインポート → スタイル: ReachType=カテゴリ（'common'と'union'） → ラベル: LabelFull\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1セル：0.5km内“出発駅群”→30分圏（common/union）+ 行政名付与 + 「別路線のみ +10分」厳密反映 =====\n",
        "!pip -q install geopandas shapely pyproj fiona\n",
        "\n",
        "import os, math, csv, unicodedata, difflib, numpy as np, pandas as pd, geopandas as gpd, logging\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# ---------- 基本 ----------\n",
        "os.environ[\"SHAPE_ENCODING\"] = \"CP932\"\n",
        "logging.getLogger(\"fiona\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"fiona.ogrext\").setLevel(logging.ERROR)\n",
        "def nrm(s): return unicodedata.normalize(\"NFKC\", str(s)).strip()\n",
        "\n",
        "# ---------- 入力 ----------\n",
        "N02_BASE = \"/content/N02-23_Station\"             # .shp/.shx/.dbf\n",
        "S12_BASE = \"/content/S12-23_NumberOfPassengers\"  # 任意\n",
        "S12_GEOJSON = \"/content/S12-23_NumberOfPassengers.geojson\"\n",
        "N03_CANDIDATES = [\n",
        "    \"/content/N03-20250101_15.geojson\",\n",
        "    \"/content/N03-20240101.geojson\",\n",
        "    \"/content/N03-20240101_15.geojson\",\n",
        "    \"/content/N03-20240101.gpkg\",\n",
        "]\n",
        "NAME_FIELD_OVERRIDE_N02 = \"N02_駅名\"\n",
        "\n",
        "# ---------- パラメータ ----------\n",
        "RADIUS_KM_FOR_MULTI_ORIGINS = 0.5  # 出発点の多重化半径\n",
        "BAND_MIN = 30                      # 分\n",
        "BAND_SPEED_KMH = 32.0              # 速度（直線近似）\n",
        "SHRINK_RATIO   = 1.00              # ユーザー要望：縮小なし\n",
        "NEAREST_JOIN_M = 300               # S12最近傍距離\n",
        "\n",
        "# ---------- 距離/時間 ----------\n",
        "def hav_km(a_lat,a_lon,b_lat,b_lon):\n",
        "    R=6371.0088\n",
        "    A=math.radians(a_lat); B=math.radians(b_lat)\n",
        "    dlat=math.radians(b_lat-a_lat); dlon=math.radians(b_lon-a_lon)\n",
        "    h=math.sin(dlat/2)**2 + math.cos(A)*math.cos(B)*math.sin(dlon/2)**2\n",
        "    return 2*R*math.asin(math.sqrt(h))\n",
        "\n",
        "def band_max_km(minutes=BAND_MIN):\n",
        "    return BAND_SPEED_KMH * minutes / 60.0 * SHRINK_RATIO\n",
        "\n",
        "# ---------- N02 読み込み & 整形 ----------\n",
        "for ext in [\".shp\",\".shx\",\".dbf\"]:\n",
        "    if not os.path.exists(N02_BASE+ext):\n",
        "        raise FileNotFoundError(f\"N02が不足: {N02_BASE+ext}\")\n",
        "\n",
        "try: g = gpd.read_file(N02_BASE + \".shp\")\n",
        "except Exception: g = gpd.read_file(N02_BASE + \".shp\", encoding=\"cp932\")\n",
        "if g.crs is None: g.set_crs(4326, inplace=True)\n",
        "try: g = g.to_crs(4326)\n",
        "except: pass\n",
        "\n",
        "g = g[g.geometry.notnull() & (~g.geometry.is_empty)].copy()\n",
        "if (g.geom_type == \"MultiPoint\").any():\n",
        "    g = g.explode(index_parts=False).reset_index(drop=True)\n",
        "if not (g.geom_type == \"Point\").all():\n",
        "    W = g.to_crs(3857); W[\"geometry\"] = W.geometry.representative_point(); g = W.to_crs(4326)\n",
        "\n",
        "def pick_name_col(df):\n",
        "    if NAME_FIELD_OVERRIDE_N02 and NAME_FIELD_OVERRIDE_N02 in df.columns: return NAME_FIELD_OVERRIDE_N02\n",
        "    cand = [c for c in df.columns if (\"駅\" in str(c)) and pd.api.types.is_string_dtype(df[c])]\n",
        "    if cand: return cand[0]\n",
        "    # フォールバック（駅を重視、路線語尾を減点）\n",
        "    best,score=None,-1\n",
        "    for c in df.columns:\n",
        "        if not pd.api.types.is_string_dtype(df[c]): continue\n",
        "        s=df[c].astype(str).fillna(\"\")\n",
        "        sc = s.str.contains(\"駅\", na=False).mean() \\\n",
        "             - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
        "             - s.str.fullmatch(r\"\\d+\").fillna(False).mean()*0.5\n",
        "        if sc>score: best,score=c,sc\n",
        "    return best\n",
        "\n",
        "def pick_line_col(df):\n",
        "    for c in [\"N02_路線名\",\"路線名\",\"路線\",\"Line\",\"LINE\"]:\n",
        "        if c in df.columns and pd.api.types.is_string_dtype(df[c]): return c\n",
        "    best,score=None,-1\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_string_dtype(df[c]):\n",
        "            s=df[c].astype(str)\n",
        "            sc=(s.str.contains(\"線\", na=False).mean())+(s.str.len().mean()>1)*0.1\n",
        "            if sc>score: best,score=c,sc\n",
        "    return best\n",
        "\n",
        "def to_lines(val):\n",
        "    if not isinstance(val,str): return set()\n",
        "    for z in [\"／\",\"、\",\"・\",\";\",\"；\",\"/\",\"|\",\",\"]: val = val.replace(z,\" \")\n",
        "    toks=[t.strip() for t in val.split() if t.strip()]\n",
        "    return set([t for t in toks if \"線\" in t])\n",
        "\n",
        "name_col = pick_name_col(g)\n",
        "line_col = pick_line_col(g)\n",
        "if not name_col:\n",
        "    raise RuntimeError(f\"駅名列が特定できません。列例: {list(g.columns)[:12]} ...\")\n",
        "\n",
        "g[\"Name\"] = g[name_col].astype(str).map(nrm)\n",
        "g[\"LineSet\"] = g[line_col].astype(str).map(to_lines) if line_col else [set()]*len(g)\n",
        "g[\"Latitude\"]  = g.geometry.y\n",
        "g[\"Longitude\"] = g.geometry.x\n",
        "\n",
        "# LineSet(set)はunhashable → frozensetで重複排除\n",
        "tmp = g[[\"Name\",\"Latitude\",\"Longitude\",\"LineSet\"]].copy()\n",
        "tmp[\"LineSetFS\"] = tmp[\"LineSet\"].apply(lambda s: frozenset(s) if isinstance(s, set) else frozenset())\n",
        "st_pts = (\n",
        "    tmp.dropna(subset=[\"Latitude\",\"Longitude\"])\n",
        "       .drop_duplicates(subset=[\"Name\",\"Latitude\",\"Longitude\",\"LineSetFS\"])\n",
        "       .drop(columns=[\"LineSetFS\"])\n",
        "       .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# 駅名候補（駅優先で表示）\n",
        "names_unique = (\n",
        "    st_pts.groupby(\"Name\", as_index=False)[[\"Latitude\",\"Longitude\"]]\n",
        "          .agg({\"Latitude\":\"mean\",\"Longitude\":\"mean\"})\n",
        ")\n",
        "\n",
        "def choose_origin(df_names, q):\n",
        "    qn=nrm(q); base=qn.replace(\"駅\",\"\")\n",
        "    hit = df_names[df_names[\"Name\"]==qn]\n",
        "    if hit.empty: hit = df_names[df_names[\"Name\"].str.replace(\"駅\",\"\",regex=False)==base]\n",
        "    if not hit.empty: return hit.iloc[0]\n",
        "    part = df_names[df_names[\"Name\"].str.contains(base, na=False)]\n",
        "    if part.empty:\n",
        "        names = df_names[\"Name\"].tolist()\n",
        "        scored = [(difflib.SequenceMatcher(None, qn, n).ratio(), n) for n in names]\n",
        "        scored.sort(reverse=True)\n",
        "        cand = df_names[df_names[\"Name\"].isin([n for _,n in scored[:20]])]\n",
        "    else:\n",
        "        cand = part.copy()\n",
        "    print(\"\\n候補（番号選択、Enter=1）:\")\n",
        "    cand = cand.assign(_sim=cand[\"Name\"].apply(lambda n: difflib.SequenceMatcher(None, qn, n).ratio())) \\\n",
        "               .sort_values([\"_sim\",\"Name\"], ascending=[False,True]).head(20).reset_index(drop=True)\n",
        "    for i, r in cand.iterrows():\n",
        "        print(f\"{i+1:2d}: {r['Name']} ({r['Latitude']:.5f},{r['Longitude']:.5f})\")\n",
        "    sel=input(\"番号: \").strip(); idx = 0\n",
        "    if sel.isdigit():\n",
        "        v=int(sel);\n",
        "        if 1<=v<=len(cand): idx=v-1\n",
        "    return cand.iloc[idx]\n",
        "\n",
        "# ---------- S12（乗降人員：ラベル用） ----------\n",
        "def load_s12():\n",
        "    old = gpd.options.io_engine; gpd.options.io_engine = \"fiona\"\n",
        "    try:\n",
        "        if os.path.exists(S12_GEOJSON):\n",
        "            s = gpd.read_file(S12_GEOJSON)\n",
        "        elif all(os.path.exists(S12_BASE+e) for e in [\".shp\",\".shx\",\".dbf\"]):\n",
        "            try: s = gpd.read_file(S12_BASE + \".shp\", encoding=\"cp932\")\n",
        "            except UnicodeDecodeError: s = gpd.read_file(S12_BASE + \".shp\", encoding=\"shift_jis\")\n",
        "        else:\n",
        "            return None\n",
        "    finally:\n",
        "        gpd.options.io_engine = old\n",
        "    if s.crs is None: s.set_crs(4326, inplace=True)\n",
        "    try: s = s.to_crs(4326)\n",
        "    except: pass\n",
        "    s = s[s.geometry.notnull() & (~s.geometry.is_empty)].copy()\n",
        "    if (s.geom_type == \"MultiPoint\").any():\n",
        "        s = s.explode(index_parts=False).reset_index(drop=True)\n",
        "    if not (s.geom_type == \"Point\").all():\n",
        "        W = s.to_crs(3857); W[\"geometry\"]=W.geometry.representative_point(); s=W.to_crs(4326)\n",
        "    return s\n",
        "\n",
        "s12 = load_s12()\n",
        "pass_map = {}\n",
        "if s12 is not None and not s12.empty:\n",
        "    name_cands = [c for c in s12.columns if (\"駅\" in str(c)) and pd.api.types.is_string_dtype(s12[c])] \\\n",
        "                 or [c for c in s12.columns if pd.api.types.is_string_dtype(s12[c])]\n",
        "    pnum_cands = [c for c in s12.columns if pd.api.types.is_numeric_dtype(s12[c])]\n",
        "    s12[\"__name__\"] = s12[name_cands[0]].astype(str).map(nrm) if name_cands else \"\"\n",
        "    best_pcol, best_score = None, -1\n",
        "    for c in pnum_cands:\n",
        "        ser = s12[c]; mv = ser.replace([np.inf,-np.inf], np.nan).dropna().mean()\n",
        "        zr = (ser==0).mean()\n",
        "        sc = float(mv)*(1.0-float(zr))\n",
        "        if sc>best_score: best_pcol, best_score = c, sc\n",
        "    try:\n",
        "        st_g = gpd.GeoDataFrame(st_pts, geometry=gpd.points_from_xy(st_pts[\"Longitude\"], st_pts[\"Latitude\"]), crs=4326).to_crs(3857)\n",
        "        s12m = s12.to_crs(3857)\n",
        "        joined = gpd.sjoin_nearest(st_g, s12m, how=\"left\", max_distance=NEAREST_JOIN_M)\n",
        "        if best_pcol:\n",
        "            tmp = joined[[\"Name\", best_pcol]].dropna()\n",
        "            pass_map.update(tmp.groupby(\"Name\")[best_pcol].max().to_dict())\n",
        "    except Exception:\n",
        "        pass\n",
        "    if name_cands and best_pcol:\n",
        "        sdict = s12.set_index(\"__name__\")[best_pcol].to_dict()\n",
        "        for nm in st_pts[\"Name\"].unique():\n",
        "            if nm not in pass_map:\n",
        "                v = sdict.get(nm) or sdict.get(nm.replace(\"駅\",\"\"))\n",
        "                if v is not None: pass_map[nm] = v\n",
        "\n",
        "def passengers_label(name):\n",
        "    v = pass_map.get(name) or pass_map.get(name.replace(\"駅\",\"\"))\n",
        "    if v is None: return None\n",
        "    try: return f\"{int(round(float(v))):,}人/日\"\n",
        "    except: return str(v)\n",
        "\n",
        "# ---------- 行政界（N03） ----------\n",
        "N03_PATH = next((p for p in N03_CANDIDATES if os.path.exists(p)), None)\n",
        "admin = None\n",
        "if N03_PATH:\n",
        "    try:\n",
        "        admin = gpd.read_file(N03_PATH)\n",
        "        if admin.crs is None: admin.set_crs(4326, inplace=True)\n",
        "        else: admin = admin.to_crs(4326)\n",
        "        admin = admin[admin.geometry.notnull() & (~admin.geometry.is_empty)].copy()\n",
        "    except Exception as e:\n",
        "        print(\"N03読込に失敗:\", e)\n",
        "        admin = None\n",
        "\n",
        "def _drop_indexish_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    drop_like = {\"index\", \"index_left\", \"index_right\", \"index_R\", \"index_L\", \"index__adm\"}\n",
        "    cols = [c for c in df.columns if c in drop_like or c.startswith(\"index_\")]\n",
        "    return df.drop(columns=cols, errors=\"ignore\")\n",
        "\n",
        "def attach_admin(gdf_pts4326: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
        "    \"\"\" within → 最近傍2km → 最近傍10km。sjoinのindex衝突を完全回避。 \"\"\"\n",
        "    gdf = _drop_indexish_cols(gdf_pts4326.copy()).rename_axis(None)\n",
        "    global admin\n",
        "    if admin is None or admin.empty:\n",
        "        gdf[\"Pref\"] = \"不明\"; gdf[\"City\"] = \"不明\"; return gdf\n",
        "    adm = _drop_indexish_cols(admin.copy()).rename_axis(None)\n",
        "\n",
        "    # 列名推定\n",
        "    pref_col = next((c for c in adm.columns if str(c).startswith(\"N03_001\")), None)\n",
        "    city_col = next((c for c in adm.columns if str(c).startswith(\"N03_004\")), None)\n",
        "    if pref_col is None or city_col is None:\n",
        "        str_cols = [c for c in adm.columns if pd.api.types.is_string_dtype(adm[c])]\n",
        "        pref_col = pref_col or (str_cols[0] if str_cols else None)\n",
        "        city_col = city_col or (str_cols[1] if len(str_cols)>1 else pref_col)\n",
        "\n",
        "    # 1) within\n",
        "    joined = gpd.sjoin(gdf, adm, how=\"left\", predicate=\"within\", lsuffix=\"\", rsuffix=\"_adm\")\n",
        "    joined[\"Pref\"] = joined.get(pref_col, None)\n",
        "    joined[\"City\"] = joined.get(city_col, None)\n",
        "\n",
        "    # 2) 最近傍2km\n",
        "    miss = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss.empty:\n",
        "        adm_3857 = adm.to_crs(3857); miss_3857 = _drop_indexish_cols(miss.to_crs(3857))\n",
        "        nn2 = gpd.sjoin_nearest(miss_3857, adm_3857, how=\"left\", max_distance=2000, lsuffix=\"\", rsuffix=\"_adm\")\n",
        "        if pref_col in nn2.columns: joined.loc[miss.index, \"Pref\"] = nn2[pref_col].values\n",
        "        if city_col in nn2.columns: joined.loc[miss.index, \"City\"] = nn2[city_col].values\n",
        "\n",
        "    # 3) 最近傍10km\n",
        "    miss2 = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss2.empty:\n",
        "        adm_3857 = adm.to_crs(3857); miss2_3857 = _drop_indexish_cols(miss2.to_crs(3857))\n",
        "        nn10 = gpd.sjoin_nearest(miss2_3857, adm_3857, how=\"left\", max_distance=10000, lsuffix=\"\", rsuffix=\"_adm\")\n",
        "        if pref_col in nn10.columns: joined.loc[miss2.index, \"Pref\"] = nn10[pref_col].values\n",
        "        if city_col in nn10.columns: joined.loc[miss2.index, \"City\"] = nn10[city_col].values\n",
        "\n",
        "    joined[\"Pref\"] = joined[\"Pref\"].fillna(\"不明\")\n",
        "    joined[\"City\"] = joined[\"City\"].fillna(\"不明\")\n",
        "    return _drop_indexish_cols(joined)\n",
        "\n",
        "# ---------- 起点入力 ----------\n",
        "print(\"（例）座標OK：35.733, 139.710（池袋付近）\")\n",
        "q = input(\"出発駅名 or 'lat,lon'：\").strip()\n",
        "\n",
        "# 原点座標の決定\n",
        "if \",\" in q:\n",
        "    lat0, lon0 = [float(v) for v in q.split(\",\",1)]\n",
        "    origin_name = \"(座標指定)\"\n",
        "else:\n",
        "    chosen = choose_origin(names_unique, q)\n",
        "    origin_name = chosen[\"Name\"]\n",
        "    lat0, lon0 = float(chosen[\"Latitude\"]), float(chosen[\"Longitude\"])\n",
        "\n",
        "print(f\"\\n中心: {origin_name} ({lat0:.6f}, {lon0:.6f})\")\n",
        "\n",
        "# ---------- 0.5km圏の“出発駅群” ----------\n",
        "start_mask = st_pts.apply(lambda r: hav_km(lat0, lon0, r[\"Latitude\"], r[\"Longitude\"]) <= RADIUS_KM_FOR_MULTI_ORIGINS, axis=1)\n",
        "starts = st_pts[start_mask].reset_index(drop=True)\n",
        "if starts.empty:\n",
        "    d2 = (st_pts[\"Latitude\"]-lat0)**2 + (st_pts[\"Longitude\"]-lon0)**2\n",
        "    starts = st_pts.loc[[int(d2.idxmin())]].reset_index(drop=True)\n",
        "\n",
        "print(\"出発駅群（0.5km以内）:\")\n",
        "for _, row in starts.iterrows():\n",
        "    print(\" -\", row[\"Name\"], f\"({row['Latitude']:.5f},{row['Longitude']:.5f})  路線:\", \"・\".join(sorted(row[\"LineSet\"])) if row[\"LineSet\"] else \"(不明)\")\n",
        "\n",
        "# ---------- 30分圏：ペナルティの有無で2パターン ----------\n",
        "R30 = band_max_km(BAND_MIN)\n",
        "\n",
        "# 出発群の路線ユニオン（同一路線チェック用）\n",
        "start_lines_union = set().union(*[ls if isinstance(ls,set) else set() for ls in starts[\"LineSet\"]]) if len(starts)>0 else set()\n",
        "\n",
        "def compute_rows(penalty_when_no_shared_line_min: int) -> list:\n",
        "    \"\"\"\n",
        "    各候補駅について、任意の出発駅 o との時間\n",
        "      t = (距離km / 速度) * 60 + (共有路線が1つも無いときのみ penalty)\n",
        "    の最小値で30分以内か判定。'common/union' は出発駅群ごとの包含関係で色分け。\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    reach_sets = []  # originごとの到達インデックス集合（union/common判定用）\n",
        "    # あらかじめ union/common 用に originごとの到達集合を作る\n",
        "    for _, o in starts.iterrows():\n",
        "        olat, olon = float(o[\"Latitude\"]), float(o[\"Longitude\"])\n",
        "        reach_idx = []\n",
        "        for i, r in st_pts.iterrows():\n",
        "            # 同一点の自駅は除外\n",
        "            if r[\"Name\"]==o[\"Name\"] and abs(r[\"Latitude\"]-olat)<1e-10 and abs(r[\"Longitude\"]-olon)<1e-10:\n",
        "                continue\n",
        "            km = hav_km(olat, olon, float(r[\"Latitude\"]), float(r[\"Longitude\"]))\n",
        "            # このoriginとdestで路線共有？\n",
        "            share = False\n",
        "            if isinstance(o[\"LineSet\"], set) and isinstance(r[\"LineSet\"], set):\n",
        "                share = not o[\"LineSet\"].isdisjoint(r[\"LineSet\"])\n",
        "            # 時間の計算（ペナルティは“共有がないときだけ”加算）\n",
        "            tmin = km / BAND_SPEED_KMH * 60.0 + (0 if share else penalty_when_no_shared_line_min)\n",
        "            if tmin <= BAND_MIN and km <= R30*1.05:  # ほんの少し余裕\n",
        "                reach_idx.append(i)\n",
        "        reach_sets.append(set(reach_idx))\n",
        "\n",
        "    union_idx = set().union(*reach_sets) if reach_sets else set()\n",
        "    common_idx = set.intersection(*reach_sets) if reach_sets else set()\n",
        "\n",
        "    def add_rows(idx_set, reach_type):\n",
        "        for i in sorted(idx_set):\n",
        "            r = st_pts.iloc[i]\n",
        "            # 出発群の中で最短時間（※ここでもペナルティ適用ロジックを同じに）\n",
        "            best_t = 1e9\n",
        "            for _, o in starts.iterrows():\n",
        "                km = hav_km(float(o[\"Latitude\"]), float(o[\"Longitude\"]), float(r[\"Latitude\"]), float(r[\"Longitude\"]))\n",
        "                share = False\n",
        "                if isinstance(o[\"LineSet\"], set) and isinstance(r[\"LineSet\"], set):\n",
        "                    share = not o[\"LineSet\"].isdisjoint(r[\"LineSet\"])\n",
        "                t = km / BAND_SPEED_KMH * 60.0 + (0 if share else penalty_when_no_shared_line_min)\n",
        "                if t < best_t: best_t = t\n",
        "            lbl = r[\"Name\"]; ppl = passengers_label(r[\"Name\"])\n",
        "            if ppl: lbl = f\"{lbl}（{ppl}）\"\n",
        "            rows.append({\n",
        "                \"Name\": r[\"Name\"],\n",
        "                \"Latitude\": float(r[\"Latitude\"]),\n",
        "                \"Longitude\": float(r[\"Longitude\"]),\n",
        "                \"Time_min_est\": round(best_t,1),\n",
        "                \"Band\": f\"<= {BAND_MIN}分\",\n",
        "                \"ReachType\": reach_type,\n",
        "                \"Label\": lbl\n",
        "            })\n",
        "\n",
        "    add_rows(common_idx, \"common\")\n",
        "    add_rows(union_idx - common_idx, \"union\")\n",
        "    return rows\n",
        "\n",
        "# ① ペナルティなし（0分） / ② 別路線のみ +10分\n",
        "rows_no_pen = compute_rows(0)\n",
        "rows_pen10 = compute_rows(10)\n",
        "\n",
        "# ---------- 行政名付与 & CSV ----------\n",
        "def to_gdf(rows):\n",
        "    return gpd.GeoDataFrame(\n",
        "        pd.DataFrame(rows),\n",
        "        geometry=gpd.points_from_xy([r[\"Longitude\"] for r in rows], [r[\"Latitude\"] for r in rows]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "\n",
        "gdf_no_pen = attach_admin(to_gdf(rows_no_pen))\n",
        "gdf_pen10  = attach_admin(to_gdf(rows_pen10))\n",
        "\n",
        "for tag, G in [(\"noPenalty\", gdf_no_pen), (\"penalty10\", gdf_pen10)]:\n",
        "    base_name = origin_name if origin_name == \"(座標指定)\" else origin_name.replace(\"/\", \"_\")\n",
        "    out = f\"/content/{base_name}_multiStart_{BAND_MIN}min_{tag}.csv\"\n",
        "    (G.drop(columns=\"geometry\")\n",
        "      .assign(AddrLabel=G[\"Pref\"].astype(str)+G[\"City\"].astype(str),\n",
        "              LabelFull=G[\"Label\"].astype(str)+\"（\"+(G[\"Pref\"].astype(str)+G[\"City\"].astype(str))+\"）\")\n",
        "      .to_csv(out, index=False, encoding=\"utf-8-sig\"))\n",
        "    cnt_total = len(G); cnt_none = (G[\"City\"].fillna(\"不明\")==\"不明\").sum()\n",
        "    print(f\"出力: {out}  件数:{cnt_total}（行政名欠損:{cnt_none}件）\")\n",
        "\n",
        "print(\"\\n※ My Maps インポート時は 'ReachType' をカテゴリで色分け、ラベルは 'LabelFull' 推奨。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u88m2aOmNXB",
        "outputId": "03e69136-7f76-4d1f-c46d-b586dacab5f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-2701191511.py:70: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "（例）座標OK：35.733, 139.710（池袋付近）\n",
            "出発駅名 or 'lat,lon'：35.7324964978089, 139.7100237517183\n",
            "\n",
            "中心: (座標指定) (35.732496, 139.710024)\n",
            "出発駅群（0.5km以内）:\n",
            " - 池袋 (35.73061,139.71034)  路線: 4号線丸ノ内線\n",
            " - 池袋 (35.73178,139.70655)  路線: 13号線副都心線\n",
            " - 池袋 (35.72954,139.70980)  路線: 8号線有楽町線\n",
            " - 池袋 (35.73152,139.71167)  路線: 山手線\n",
            " - 池袋 (35.73144,139.71197)  路線: 赤羽線\n",
            " - 池袋 (35.73099,139.71106)  路線: 東上本線\n",
            "出力: /content/(座標指定)_multiStart_30min_noPenalty.csv  件数:701（行政名欠損:1件）\n",
            "出力: /content/(座標指定)_multiStart_30min_penalty10.csv  件数:527（行政名欠損:0件）\n",
            "\n",
            "※ My Maps インポート時は 'ReachType' をカテゴリで色分け、ラベルは 'LabelFull' 推奨。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1セル：0.5km内“出発駅群”→30分圏（common/union）+ 行政名付与\n",
        "#            同一路線は高速(例55km/h)、別路線のみ +10分 を厳密反映 =====\n",
        "!pip -q install geopandas shapely pyproj fiona\n",
        "\n",
        "import os, math, csv, unicodedata, difflib, numpy as np, pandas as pd, geopandas as gpd, logging\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# ---------- 基本 ----------\n",
        "os.environ[\"SHAPE_ENCODING\"] = \"CP932\"\n",
        "logging.getLogger(\"fiona\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"fiona.ogrext\").setLevel(logging.ERROR)\n",
        "def nrm(s): return unicodedata.normalize(\"NFKC\", str(s)).strip()\n",
        "\n",
        "# ---------- 入力 ----------\n",
        "N02_BASE = \"/content/N02-23_Station\"             # .shp/.shx/.dbf\n",
        "S12_BASE = \"/content/S12-23_NumberOfPassengers\"  # 任意\n",
        "S12_GEOJSON = \"/content/S12-23_NumberOfPassengers.geojson\"\n",
        "N03_CANDIDATES = [\n",
        "    \"/content/N03-20250101_15.geojson\",\n",
        "    \"/content/N03-20240101.geojson\",\n",
        "    \"/content/N03-20240101_15.geojson\",\n",
        "    \"/content/N03-20240101.gpkg\",\n",
        "]\n",
        "NAME_FIELD_OVERRIDE_N02 = \"N02_駅名\"\n",
        "\n",
        "# ---------- パラメータ ----------\n",
        "RADIUS_KM_FOR_MULTI_ORIGINS = 0.5   # 出発点の多重化半径\n",
        "BAND_MIN = 30                       # 分\n",
        "BASE_SPEED_KMH = 28.0               # 乗換あり/別路線のときの基準速度（直線近似）\n",
        "SAME_LINE_SPEED_KMH = 48.0          # ★同一路線のときの高速（例: 55km/h）\n",
        "NEAREST_JOIN_M = 300                # S12最近傍距離[m]\n",
        "# ※縮小はしません（ユーザー要望）\n",
        "\n",
        "# ---------- 距離/時間 ----------\n",
        "def hav_km(a_lat,a_lon,b_lat,b_lon):\n",
        "    R=6371.0088\n",
        "    A=math.radians(a_lat); B=math.radians(b_lat)\n",
        "    dlat=math.radians(b_lat-a_lat); dlon=math.radians(b_lon-a_lon)\n",
        "    h=math.sin(dlat/2)**2 + math.cos(A)*math.cos(B)*math.sin(dlon/2)**2\n",
        "    return 2*R*math.asin(math.sqrt(h))\n",
        "\n",
        "# ---------- N02 読み込み & 整形 ----------\n",
        "for ext in [\".shp\",\".shx\",\".dbf\"]:\n",
        "    if not os.path.exists(N02_BASE+ext):\n",
        "        raise FileNotFoundError(f\"N02が不足: {N02_BASE+ext}\")\n",
        "\n",
        "try: g = gpd.read_file(N02_BASE + \".shp\")\n",
        "except Exception: g = gpd.read_file(N02_BASE + \".shp\", encoding=\"cp932\")\n",
        "if g.crs is None: g.set_crs(4326, inplace=True)\n",
        "try: g = g.to_crs(4326)\n",
        "except: pass\n",
        "\n",
        "g = g[g.geometry.notnull() & (~g.geometry.is_empty)].copy()\n",
        "if (g.geom_type == \"MultiPoint\").any():\n",
        "    g = g.explode(index_parts=False).reset_index(drop=True)\n",
        "if not (g.geom_type == \"Point\").all():\n",
        "    W = g.to_crs(3857); W[\"geometry\"] = W.geometry.representative_point(); g = W.to_crs(4326)\n",
        "\n",
        "def pick_name_col(df):\n",
        "    if NAME_FIELD_OVERRIDE_N02 and NAME_FIELD_OVERRIDE_N02 in df.columns: return NAME_FIELD_OVERRIDE_N02\n",
        "    cand = [c for c in df.columns if (\"駅\" in str(c)) and pd.api.types.is_string_dtype(df[c])]\n",
        "    if cand: return cand[0]\n",
        "    best,score=None,-1\n",
        "    for c in df.columns:\n",
        "        if not pd.api.types.is_string_dtype(df[c]): continue\n",
        "        s=df[c].astype(str).fillna(\"\")\n",
        "        sc = s.str.contains(\"駅\", na=False).mean() \\\n",
        "           - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
        "           - s.str.fullmatch(r\"\\d+\").fillna(False).mean()*0.5\n",
        "        if sc>score: best,score=c,sc\n",
        "    return best\n",
        "\n",
        "def pick_line_col(df):\n",
        "    for c in [\"N02_路線名\",\"路線名\",\"路線\",\"Line\",\"LINE\"]:\n",
        "        if c in df.columns and pd.api.types.is_string_dtype(df[c]): return c\n",
        "    best,score=None,-1\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_string_dtype(df[c]):\n",
        "            s=df[c].astype(str)\n",
        "            sc=(s.str.contains(\"線\", na=False).mean())+(s.str.len().mean()>1)*0.1\n",
        "            if sc>score: best,score=c,sc\n",
        "    return best\n",
        "\n",
        "def to_lines(val):\n",
        "    if not isinstance(val,str): return set()\n",
        "    for z in [\"／\",\"、\",\"・\",\";\",\"；\",\"/\",\"|\",\",\"]: val = val.replace(z,\" \")\n",
        "    toks=[t.strip() for t in val.split() if t.strip()]\n",
        "    # 正規化（全角→半角、スペース除去）\n",
        "    toks=[nrm(t) for t in toks]\n",
        "    return set([t for t in toks if \"線\" in t])\n",
        "\n",
        "name_col = pick_name_col(g)\n",
        "line_col = pick_line_col(g)\n",
        "if not name_col:\n",
        "    raise RuntimeError(f\"駅名列が特定できません。列例: {list(g.columns)[:12]} ...\")\n",
        "\n",
        "g[\"Name\"] = g[name_col].astype(str).map(nrm)\n",
        "g[\"LineSet\"] = g[line_col].astype(str).map(to_lines) if line_col else [set()]*len(g)\n",
        "g[\"Latitude\"]  = g.geometry.y\n",
        "g[\"Longitude\"] = g.geometry.x\n",
        "\n",
        "# set は unhashable → frozenset で重複排除\n",
        "tmp = g[[\"Name\",\"Latitude\",\"Longitude\",\"LineSet\"]].copy()\n",
        "tmp[\"LineSetFS\"] = tmp[\"LineSet\"].apply(lambda s: frozenset(s) if isinstance(s, set) else frozenset())\n",
        "st_pts = (\n",
        "    tmp.dropna(subset=[\"Latitude\",\"Longitude\"])\n",
        "       .drop_duplicates(subset=[\"Name\",\"Latitude\",\"Longitude\",\"LineSetFS\"])\n",
        "       .drop(columns=[\"LineSetFS\"])\n",
        "       .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# 駅名候補（駅優先で表示）\n",
        "names_unique = (\n",
        "    st_pts.groupby(\"Name\", as_index=False)[[\"Latitude\",\"Longitude\"]]\n",
        "          .agg({\"Latitude\":\"mean\",\"Longitude\":\"mean\"})\n",
        ")\n",
        "\n",
        "def choose_origin(df_names, q):\n",
        "    qn=nrm(q); base=qn.replace(\"駅\",\"\")\n",
        "    hit = df_names[df_names[\"Name\"]==qn]\n",
        "    if hit.empty: hit = df_names[df_names[\"Name\"].str.replace(\"駅\",\"\",regex=False)==base]\n",
        "    if not hit.empty: return hit.iloc[0]\n",
        "    part = df_names[df_names[\"Name\"].str.contains(base, na=False)]\n",
        "    if part.empty:\n",
        "        names = df_names[\"Name\"].tolist()\n",
        "        scored = [(difflib.SequenceMatcher(None, qn, n).ratio(), n) for n in names]\n",
        "        scored.sort(reverse=True)\n",
        "        cand = df_names[df_names[\"Name\"].isin([n for _,n in scored[:20]])]\n",
        "    else:\n",
        "        cand = part.copy()\n",
        "    print(\"\\n候補（番号選択、Enter=1）:\")\n",
        "    cand = cand.assign(_sim=cand[\"Name\"].apply(lambda n: difflib.SequenceMatcher(None, qn, n).ratio())) \\\n",
        "               .sort_values([\"_sim\",\"Name\"], ascending=[False,True]).head(20).reset_index(drop=True)\n",
        "    for i, r in cand.iterrows():\n",
        "        print(f\"{i+1:2d}: {r['Name']} ({r['Latitude']:.5f},{r['Longitude']:.5f})\")\n",
        "    sel=input(\"番号: \").strip(); idx = 0\n",
        "    if sel.isdigit():\n",
        "        v=int(sel);\n",
        "        if 1<=v<=len(cand): idx=v-1\n",
        "    return cand.iloc[idx]\n",
        "\n",
        "# ---------- S12（乗降人員：ラベル用／任意） ----------\n",
        "def load_s12():\n",
        "    old = gpd.options.io_engine; gpd.options.io_engine = \"fiona\"\n",
        "    try:\n",
        "        if os.path.exists(S12_GEOJSON):\n",
        "            s = gpd.read_file(S12_GEOJSON)\n",
        "        elif all(os.path.exists(S12_BASE+e) for e in [\".shp\",\".shx\",\".dbf\"]):\n",
        "            try: s = gpd.read_file(S12_BASE + \".shp\", encoding=\"cp932\")\n",
        "            except UnicodeDecodeError: s = gpd.read_file(S12_BASE + \".shp\", encoding=\"shift_jis\")\n",
        "        else:\n",
        "            return None\n",
        "    finally:\n",
        "        gpd.options.io_engine = old\n",
        "    if s.crs is None: s.set_crs(4326, inplace=True)\n",
        "    try: s = s.to_crs(4326)\n",
        "    except: pass\n",
        "    s = s[s.geometry.notnull() & (~s.geometry.is_empty)].copy()\n",
        "    if (s.geom_type == \"MultiPoint\").any():\n",
        "        s = s.explode(index_parts=False).reset_index(drop=True)\n",
        "    if not (s.geom_type == \"Point\").all():\n",
        "        W = s.to_crs(3857); W[\"geometry\"]=W.geometry.representative_point(); s=W.to_crs(4326)\n",
        "    return s\n",
        "\n",
        "s12 = load_s12()\n",
        "pass_map = {}\n",
        "if s12 is not None and not s12.empty:\n",
        "    name_cands = [c for c in s12.columns if (\"駅\" in str(c)) and pd.api.types.is_string_dtype(s12[c])] \\\n",
        "                 or [c for c in s12.columns if pd.api.types.is_string_dtype(s12[c])]\n",
        "    pnum_cands = [c for c in s12.columns if pd.api.types.is_numeric_dtype(s12[c])]\n",
        "    s12[\"__name__\"] = s12[name_cands[0]].astype(str).map(nrm) if name_cands else \"\"\n",
        "    best_pcol, best_score = None, -1\n",
        "    for c in pnum_cands:\n",
        "        ser = s12[c]; mv = ser.replace([np.inf,-np.inf], np.nan).dropna().mean()\n",
        "        zr = (ser==0).mean()\n",
        "        sc = float(mv)*(1.0-float(zr))\n",
        "        if sc>best_score: best_pcol, best_score = c, sc\n",
        "    try:\n",
        "        st_g = gpd.GeoDataFrame(st_pts, geometry=gpd.points_from_xy(st_pts[\"Longitude\"], st_pts[\"Latitude\"]), crs=4326).to_crs(3857)\n",
        "        s12m = s12.to_crs(3857)\n",
        "        joined = gpd.sjoin_nearest(st_g, s12m, how=\"left\", max_distance=NEAREST_JOIN_M)\n",
        "        if best_pcol:\n",
        "            tmp = joined[[\"Name\", best_pcol]].dropna()\n",
        "            pass_map.update(tmp.groupby(\"Name\")[best_pcol].max().to_dict())\n",
        "    except Exception:\n",
        "        pass\n",
        "    if name_cands and best_pcol:\n",
        "        sdict = s12.set_index(\"__name__\")[best_pcol].to_dict()\n",
        "        for nm in st_pts[\"Name\"].unique():\n",
        "            if nm not in pass_map:\n",
        "                v = sdict.get(nm) or sdict.get(nm.replace(\"駅\",\"\"))\n",
        "                if v is not None: pass_map[nm] = v\n",
        "\n",
        "def passengers_label(name):\n",
        "    v = pass_map.get(name) or pass_map.get(name.replace(\"駅\",\"\"))\n",
        "    if v is None: return None\n",
        "    try: return f\"{int(round(float(v))):,}人/日\"\n",
        "    except: return str(v)\n",
        "\n",
        "# ---------- 行政界（N03） ----------\n",
        "N03_PATH = next((p for p in N03_CANDIDATES if os.path.exists(p)), None)\n",
        "admin = None\n",
        "if N03_PATH:\n",
        "    try:\n",
        "        admin = gpd.read_file(N03_PATH)\n",
        "        if admin.crs is None: admin.set_crs(4326, inplace=True)\n",
        "        else: admin = admin.to_crs(4326)\n",
        "        admin = admin[admin.geometry.notnull() & (~admin.geometry.is_empty)].copy()\n",
        "    except Exception as e:\n",
        "        print(\"N03読込に失敗:\", e)\n",
        "        admin = None\n",
        "\n",
        "def _drop_indexish_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    drop_like = {\"index\", \"index_left\", \"index_right\", \"index_R\", \"index_L\", \"index__adm\"}\n",
        "    cols = [c for c in df.columns if c in drop_like or c.startswith(\"index_\")]\n",
        "    return df.drop(columns=cols, errors=\"ignore\")\n",
        "\n",
        "def attach_admin(gdf_pts4326: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
        "    gdf = _drop_indexish_cols(gdf_pts4326.copy()).rename_axis(None)\n",
        "    global admin\n",
        "    if admin is None or admin.empty:\n",
        "        gdf[\"Pref\"] = \"不明\"; gdf[\"City\"] = \"不明\"; return gdf\n",
        "    adm = _drop_indexish_cols(admin.copy()).rename_axis(None)\n",
        "    pref_col = next((c for c in adm.columns if str(c).startswith(\"N03_001\")), None)\n",
        "    city_col = next((c for c in adm.columns if str(c).startswith(\"N03_004\")), None)\n",
        "    if pref_col is None or city_col is None:\n",
        "        str_cols = [c for c in adm.columns if pd.api.types.is_string_dtype(adm[c])]\n",
        "        pref_col = pref_col or (str_cols[0] if str_cols else None)\n",
        "        city_col = city_col or (str_cols[1] if len(str_cols)>1 else pref_col)\n",
        "    joined = gpd.sjoin(gdf, adm, how=\"left\", predicate=\"within\", lsuffix=\"\", rsuffix=\"_adm\")\n",
        "    joined[\"Pref\"] = joined.get(pref_col, None)\n",
        "    joined[\"City\"] = joined.get(city_col, None)\n",
        "    miss = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss.empty:\n",
        "        adm_3857 = adm.to_crs(3857); miss_3857 = _drop_indexish_cols(miss.to_crs(3857))\n",
        "        nn2 = gpd.sjoin_nearest(miss_3857, adm_3857, how=\"left\", max_distance=2000, lsuffix=\"\", rsuffix=\"_adm\")\n",
        "        if pref_col in nn2.columns: joined.loc[miss.index, \"Pref\"] = nn2[pref_col].values\n",
        "        if city_col in nn2.columns: joined.loc[miss.index, \"City\"] = nn2[city_col].values\n",
        "    miss2 = joined[joined[\"City\"].isna()].copy()\n",
        "    if not miss2.empty:\n",
        "        adm_3857 = adm.to_crs(3857); miss2_3857 = _drop_indexish_cols(miss2.to_crs(3857))\n",
        "        nn10 = gpd.sjoin_nearest(miss2_3857, adm_3857, how=\"left\", max_distance=10000, lsuffix=\"\", rsuffix=\"_adm\")\n",
        "        if pref_col in nn10.columns: joined.loc[miss2.index, \"Pref\"] = nn10[pref_col].values\n",
        "        if city_col in nn10.columns: joined.loc[miss2.index, \"City\"] = nn10[city_col].values\n",
        "    joined[\"Pref\"] = joined[\"Pref\"].fillna(\"不明\")\n",
        "    joined[\"City\"] = joined[\"City\"].fillna(\"不明\")\n",
        "    return _drop_indexish_cols(joined)\n",
        "\n",
        "# ---------- 起点入力 ----------\n",
        "print(\"（例）座標OK：35.733, 139.710（池袋付近）\")\n",
        "q = input(\"出発駅名 or 'lat,lon'：\").strip()\n",
        "\n",
        "# 原点座標の決定\n",
        "if \",\" in q:\n",
        "    lat0, lon0 = [float(v) for v in q.split(\",\",1)]\n",
        "    origin_name = \"(座標指定)\"\n",
        "else:\n",
        "    chosen = choose_origin(names_unique, q)\n",
        "    origin_name = chosen[\"Name\"]\n",
        "    lat0, lon0 = float(chosen[\"Latitude\"]), float(chosen[\"Longitude\"])\n",
        "print(f\"\\n中心: {origin_name} ({lat0:.6f}, {lon0:.6f})\")\n",
        "\n",
        "# ---------- 0.5km圏の“出発駅群” ----------\n",
        "start_mask = st_pts.apply(lambda r: hav_km(lat0, lon0, r[\"Latitude\"], r[\"Longitude\"]) <= RADIUS_KM_FOR_MULTI_ORIGINS, axis=1)\n",
        "starts = st_pts[start_mask].reset_index(drop=True)\n",
        "if starts.empty:\n",
        "    d2 = (st_pts[\"Latitude\"]-lat0)**2 + (st_pts[\"Longitude\"]-lon0)**2\n",
        "    starts = st_pts.loc[[int(d2.idxmin())]].reset_index(drop=True)\n",
        "\n",
        "print(\"出発駅群（0.5km以内）:\")\n",
        "for _, row in starts.iterrows():\n",
        "    print(\" -\", row[\"Name\"], f\"({row['Latitude']:.5f},{row['Longitude']:.5f})  路線:\", \"・\".join(sorted(row[\"LineSet\"])) if row[\"LineSet\"] else \"(不明)\")\n",
        "\n",
        "# ---------- 30分圏：ペナルティの有無で2パターン ----------\n",
        "# 出発群の路線ユニオン（情報確認用。判定自体は起点ごとに最短時間を取る）\n",
        "start_lines_union = set().union(*[ls if isinstance(ls,set) else set() for ls in starts[\"LineSet\"]]) if len(starts)>0 else set()\n",
        "\n",
        "def compute_rows(penalty_when_no_shared_line_min: int) -> list:\n",
        "    \"\"\"\n",
        "    各候補駅 r について、起点 o ごとに\n",
        "      share_o = (oのLineSet ∩ rのLineSet ≠ ∅)\n",
        "      speed   = SAME_LINE_SPEED_KMH if share_o else BASE_SPEED_KMH\n",
        "      t_o     = 距離/速度*60 + (0 if share_o else penalty)\n",
        "    の最小 t_o を採用し、t_o ≤ 30分 なら採用。\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    reach_sets = []\n",
        "    # 起点ごとの到達集合（union/common判定用）\n",
        "    for _, o in starts.iterrows():\n",
        "        olat, olon = float(o[\"Latitude\"]), float(o[\"Longitude\"])\n",
        "        reach_idx = []\n",
        "        for i, r in st_pts.iterrows():\n",
        "            # 自駅は除外\n",
        "            if r[\"Name\"]==o[\"Name\"] and abs(r[\"Latitude\"]-olat)<1e-10 and abs(r[\"Longitude\"]-olon)<1e-10:\n",
        "                continue\n",
        "            km = hav_km(olat, olon, float(r[\"Latitude\"]), float(r[\"Longitude\"]))\n",
        "            share = False\n",
        "            if isinstance(o[\"LineSet\"], set) and isinstance(r[\"LineSet\"], set):\n",
        "                share = not o[\"LineSet\"].isdisjoint(r[\"LineSet\"])\n",
        "            speed = SAME_LINE_SPEED_KMH if share else BASE_SPEED_KMH\n",
        "            tmin  = km / speed * 60.0 + (0 if share else penalty_when_no_shared_line_min)\n",
        "            if tmin <= BAND_MIN:\n",
        "                reach_idx.append(i)\n",
        "        reach_sets.append(set(reach_idx))\n",
        "    union_idx = set().union(*reach_sets) if reach_sets else set()\n",
        "    common_idx = set.intersection(*reach_sets) if reach_sets else set()\n",
        "\n",
        "    def add_rows(idx_set, reach_type):\n",
        "        for i in sorted(idx_set):\n",
        "            r = st_pts.iloc[i]\n",
        "            # 出発群の中での最短時間（←ここでも同ロジックで厳密評価）\n",
        "            best_t = 1e9\n",
        "            for _, o in starts.iterrows():\n",
        "                km = hav_km(float(o[\"Latitude\"]), float(o[\"Longitude\"]), float(r[\"Latitude\"]), float(r[\"Longitude\"]))\n",
        "                share = False\n",
        "                if isinstance(o[\"LineSet\"], set) and isinstance(r[\"LineSet\"], set):\n",
        "                    share = not o[\"LineSet\"].isdisjoint(r[\"LineSet\"])\n",
        "                speed = SAME_LINE_SPEED_KMH if share else BASE_SPEED_KMH\n",
        "                t = km / speed * 60.0 + (0 if share else penalty_when_no_shared_line_min)\n",
        "                if t < best_t: best_t = t\n",
        "            lbl = r[\"Name\"]; ppl = passengers_label(r[\"Name\"])\n",
        "            if ppl: lbl = f\"{lbl}（{ppl}）\"\n",
        "            rows.append({\n",
        "                \"Name\": r[\"Name\"],\n",
        "                \"Latitude\": float(r[\"Latitude\"]),\n",
        "                \"Longitude\": float(r[\"Longitude\"]),\n",
        "                \"Time_min_est\": round(best_t,1),\n",
        "                \"Band\": f\"<= {BAND_MIN}分\",\n",
        "                \"ReachType\": reach_type,\n",
        "                \"Label\": lbl\n",
        "            })\n",
        "    add_rows(common_idx, \"common\")\n",
        "    add_rows(union_idx - common_idx, \"union\")\n",
        "    return rows\n",
        "\n",
        "# ① ペナルティなし / ② 別路線のみ +10分\n",
        "rows_no_pen = compute_rows(0)\n",
        "rows_pen10  = compute_rows(10)\n",
        "\n",
        "# ---------- 行政名付与 & CSV ----------\n",
        "def to_gdf(rows):\n",
        "    return gpd.GeoDataFrame(\n",
        "        pd.DataFrame(rows),\n",
        "        geometry=gpd.points_from_xy([r[\"Longitude\"] for r in rows], [r[\"Latitude\"] for r in rows]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "\n",
        "# 行政名付与\n",
        "gdf_no_pen = attach_admin(to_gdf(rows_no_pen))\n",
        "gdf_pen10  = attach_admin(to_gdf(rows_pen10))\n",
        "\n",
        "# 住所ラベル付与 & 出力\n",
        "for tag, G in [(\"noPenalty\", gdf_no_pen), (\"penalty10\", gdf_pen10)]:\n",
        "    base_name = origin_name if origin_name == \"(座標指定)\" else origin_name.replace(\"/\", \"_\")\n",
        "    out = f\"/content/{base_name}_multiStart_{BAND_MIN}min_{tag}.csv\"\n",
        "    (G.drop(columns=\"geometry\")\n",
        "      .assign(AddrLabel=G[\"Pref\"].astype(str)+G[\"City\"].astype(str),\n",
        "              LabelFull=G[\"Label\"].astype(str)+\"（\"+(G[\"Pref\"].astype(str)+G[\"City\"].astype(str))+\"）\")\n",
        "      .to_csv(out, index=False, encoding=\"utf-8-sig\"))\n",
        "    cnt_total = len(G); cnt_none = (G[\"City\"].fillna(\"不明\")==\"不明\").sum()\n",
        "    print(f\"出力: {out}  件数:{cnt_total}（行政名欠損:{cnt_none}件）\")\n",
        "\n",
        "print(\"\\n※ My Maps: 'ReachType' をカテゴリで色分け、ラベルは 'LabelFull' 推奨。\")\n",
        "print(f\"速度設定: 同一路線 {SAME_LINE_SPEED_KMH} km/h / 別路線 {BASE_SPEED_KMH} km/h、別路線のみ +10分（2本目CSV）\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "3OrK-66hrj9n",
        "outputId": "e58850ea-a71e-45f6-85e9-8ba3dc4bf9c8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n",
            "/tmp/ipython-input-3876585123.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  - s.str.contains(r\"(線|方面|支線|ライン)$\", na=False).mean()*0.9 \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "（例）座標OK：35.733, 139.710（池袋付近）\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3876585123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;31m# ---------- 起点入力 ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"（例）座標OK：35.733, 139.710（池袋付近）\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"出発駅名 or 'lat,lon'：\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# 原点座標の決定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}